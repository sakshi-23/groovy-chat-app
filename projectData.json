[  
   {  
      "link":"/research/labs/design-and-social-interaction-studio",
      "name":"(T)racing Eyes and Hearts: An Installation to Explore the Physiology of Empathy",
      "lab":"Design and Social Interaction Studio",
      "description":"Eyes darting, or maintaining a steady gaze straight ahead. Heartbeat racing, or maintaining a slow, even rhythm. If we encounter these phenomena in another, how do we respond   not just affectively, but physiologically?  Eye movements and heartbeats are among the most intuitively meaningful physiological characteristics that humans observe in one another.  Without necessarily consciously realizing it, we often respond empathetically.  This project brings together humanities scholars and physiology scholars to create an art installation that uses representation, tracking, and visualization to investigate and reflect upon the physiology of empathy.  The installation renders video of eye movements and audio of heartrate of a virtual person, and tracks the eye movements and heartrate of an observing user. We anticipate a mirroring, empathetic physiological response from the user, in which their heartrate also speeds and slows in conjunction with the virtual person.  Immediately after the experience, the user will be provided a visual and auditory representation of the data, in order to see and reflect on this empathetic engagement, and also provided with a link to a copy of the video by email if they so choose.  The playback could be either in real time, or in a time that is set to either the virtual person or the user's heartrate as a metronome, to allow a distinctively human-centered exploration of the data. \n"
   },
   {  
      "link":"/research/labs/gt-bionics",
      "name":"A Multimodal Human Computer Interface Combining Head Movement, Speech and Tongue Motion for the People with Severe Disabilities",
      "lab":"GT-Bionics",
      "description":"Assistive technologies (ATs) play a crucial role in the lives of individuals with severe disabilities by enabling them to have greater autonomy in performing daily tasks. The Tongue Drive System (TDS) developed at the Georgia Tech Bionics Lab is such an AT, empowering people with severe Spinal Cord Injury (SCI) to be more independent. Earlier versions of the TDS have offered tongue motion and speech as means of driving mouse activity and keyboard input. In this project, we introduce a new multi-modal Tongue Drive System (mTDS), which incorporates head tracking to deliver proportional control of a mouse cursor. The mTDS integrates this new capability while preserving tongue motion and speech from previous versions and offers a richer means of driving computing interfaces, than previously available to individuals with severe disabilities.\n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"A Social Q and A System for Young Adults with Autism",
      "lab":"Ubiquitous Computing Group",
      "description":"Users go to social network sites or online forums to get advice from members of their networks. Individuals with autism adopt and use such computer-mediated communication technology differently from typical users. They require advice about everyday situations ranging from very simple operations to complex social activities. We propose to develop a Q&A system with a robust network of people  whom the user is not likely to know but who nonetheless may be willing to provide advice on everyday situations.\n"
   },
   {  
      "link":"/research/labs/gt-bionics",
      "name":"A Wireless Wearable Neckwear System for Health Monitoring",
      "lab":"GT-Bionics",
      "description":"Wearable systems play an important role in continuous health monitoring and can contribute to early detection of abnormal health-related events and facilitate the advancement of personalized healthcare. The neck is a unique sensing location because it provides access to a set of health-related data that other wearable devices simply cannot obtain. Activities including breathing, chewing, clearing the throat, coughing, swallowing, speech and even heartbeat can be recorded from around the neck. Two applications of particular interest for this project include medication adherence monitoring and  food intake monitoring.\nMedication non-compliance, especially for patients with chronic illnesses, is a global issue that has been associated with increased healthcare cost, rehospitalization, complications and disease progression. To address this problem, it is essential to have a portable, wearable health platform that can remind patients of their medication regimen, track medication ingestion, and monitor a patient's overall health status. The proposed system in the form of a necklace will automatically track medication ingestion using the well established radio frequency (RF) technology in very high frequency (13.56MHz) band. For power management purposes, the system will be \u2018asleep' by default except during a swallowing event when there is a possibility of medication ingestion. For this reason automatic swallowing detection is essential; the ability to differentiate swallowing sounds from other tracheal sounds initiated by speaking, coughing, clearing the throat etc. In previous work, we developed a real-time swallowing detection algorithm based on acoustic signals and patterns that combines computationally-inexpensive features to achieve comparable performance with previously proposed offline methods using acoustic and non-acoustic data. With data from four healthy subjects that includes common tracheal events such as speech, chewing, coughing, clearing the throat, and swallowing of different liquids, our results show an overall recall performance of 79.9% and precision of 67.6%, which are slightly better or close to the offline results.\nIn our following work, we expanded our scope and explored tracheal activity recognition using a combination of promising acoustic features from related work and apply simplistic classifiers including K-NN and Naive Bayes. For wearable systems in which low power consumption is of primary concern, we have shown that with a sub-optimal sampling rate of 16 kHz, we achieved average classification results in the range of 86.6% to 87.4% using 1-NN, 3-NN, 5-NN and Naive Bayes. All classifiers obtained the highest recognition rate in the range of 97.2% to 99.4% for speech classification. This is promising to mitigate privacy concerns associated with wearable systems interfering with the user's conversations. \n"
   },
   {  
      "link":"/research/labs/sonification-lab",
      "name":"Accessible Bluetooth Cane",
      "lab":"Sonification Lab",
      "description":"The Accessible Bluetooth Cane project allows visually impaired users to control their iPhone while using the white cane, without having to stop and take out the phone. This is achieved by embedding Bluetooth remote controls with tactile buttons inside the cane handle. \n"
   },
   {  
      "link":"/research/labs/synaesthethic-media-lab",
      "name":"Active Pathways",
      "lab":"Synaesthethic Media Lab",
      "description":"Active Pathways aims to support learning and discovery in systems biology by allowing users to construct and manipulate bio-chemical reaction network simulations using active tangibles on an interactive tabletop display surface. Researchers in systems biology currently run simulation programs that model different experimental parameters such as concentrations inside cells and reaction speeds. Parameters are adjusted algorithmically or by entering numbers into equations. The simulation results are then plotted as graphs in order to discover hidden patterns in the network. Using tangible and tabletop interaction techniques, we provide a direct hands-on way for researchers to construct and manipulate models in order to gain a better understanding of the systems they are studying.\n"
   },
   {  
      "link":"/research/labs/ms-hci-project-lab",
      "name":"Addressing Well-being and Social Support with an Online Platform",
      "lab":"MS-HCI Project Lab",
      "description":"The goal of the research is to identify the ways in which social media could play a role in assisting Georgia Tech students find mental health support.  Mental health disorders are extremely prevalent on college campuses, and anxiety and depression in particular have been shown to have a negative effect on academic success.  Despite the fact that mental health professionals and program are available to students with mental health conditions, many are not seeking help from their campus resources.  Social support is a key component in preventing mental health issues from becoming serious problems, and it has been shown to be a top factor in preventing suicide attempts.  By examining the mental health status of current Georgia Tech students as well as their social media usage and behavior, the proposed project aims to discover how a social platform could be used to provide social support to Tech students facing mental health issues.  \n"
   },
   {  
      "link":"/research/labs/sonification-lab",
      "name":"Advanced Auditory Menus",
      "lab":"Sonification Lab",
      "description":"Many electronic devices, from desktop computers to mobile phones to DVD players, can be thought of as a menu of functions. These functions can be accessible to a blind user if the menus are spoken aloud. However, this is extremely inefficient, so we have been enhancing auditory menus with sophisticated text-to-speech, spearcons, spindex, and other audio extensions. These can also be applied in many different languages and research is ongoing to look at more language applications, including tonal types.\n"
   },
   {  
      "link":"/research/labs/sonification-lab",
      "name":"Air Gesture-Based Systems for Accessible Stem Education",
      "lab":"Sonification Lab",
      "description":"This project is exploring ways of using air gesture technologies, audio and haptic to facilitate exploration of  STEM concepts by blind and low vision learners. Efforts will establish the efficacy of this approach, as well as best practices for creating air gesture interfaces that support exploration of a virtual reality space such as a simulated atom, wind tunnel or electrical system- all without the use of vision.\n"
   },
   {  
      "link":"/research/labs/sonification-lab",
      "name":"Air Gestures in the Vehicle",
      "lab":"Sonification Lab",
      "description":"Modern sensor technology is beginning to allow for cost-effective deployment of air gesture interfaces in the vehicle. Unlike the current standard of direct touch, air gesture interfaces do not require that the driver takes their eyes off the road, especially when coupled with properly applied auditory or tactile feedback.\nWhile emerging systems like Apple Carplay and Android Auto support limited speech commands, the majority of tasks still require visually targeted touch interaction, which poses a safety hazard to drivers.\nResearch in the Sonification Lab centers on developing guidelines for automotive interface designers on how to create air gesture interfaces which provide minimal cognitive, motor and visual demand to drivers. We combine user-centered HCI design with comprehensive engineering psychology evaluation using eye tracking, physiological measures, performance measures and subjective measures to take a data-driven approach to air gesture systems in the vehicle.\n"
   },
   {  
      "link":"/research/labs/subcultures-digital-media",
      "name":"Algorithmic and Historical Detection Patterns of Music Subcultures",
      "lab":"Subcultures & Digital Media",
      "description":"The algorithmic detection of subcultural or niche taste trends is of growing importance in targeted advertising. This demonstration presents research using online music analysis tools from Spotify, Musicbrainz, and Rovi coupled with aggregated music listening behavior from Facebook users to detect individual tastes and emerging taste trends amongst social groups.\nThis research is presented alongside historical signifiers of music taste such as fashion, music collections, and subcultural knowledge.  \nThe goal of the research is to display the growing importance of software based taste detection algorithms in determining niche markets for online content providers, and some of the new methodologies available in to such systems.\n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"Algorithmically Bypassing Censorship on Sina Weibo with Nondeterministic Homophone Substitutions",
      "lab":"Comp.Social Lab",
      "description":"Like traditional media, social media in China is subject to censorship. However, in limited cases, activists have employed homophones of censored keywords to avoid detection by keyword matching algorithms. In this paper, we show that it is possible to scale this idea up in ways that make it difficult to defend against. Specifically, we present a non-deterministic algorithm for generating homophones that create large numbers of false positives for censors, making it difficult to locate banned conversations. In two experiments, we show that 1) homophone-transformed weibos posted to Sina Weibo remain on-site three times longer than their previously censored counterparts, and 2) native Chinese speakers can recover the origi- nal intent behind the homophone-transformed messages, with 99% of our posts understood by the majority of our participants. Finally, we find that coping with homophone transformations is likely to cost the Sina Weibo censorship apparatus an additional 15 hours of human labor per day, per censored keyword. To conclude, we reflect briefly on the opportunities presented by this algorithm to build interactive, client-side tools that promote free speech. \n"
   },
   {  
      "link":"/research/labs/ms-hci-project-lab",
      "name":"AlmaBase - Understanding you Alumni Network",
      "lab":"MS-HCI Project Lab",
      "description":"Networking and peer inspiration from alumni of your program/school is important when making decisions about the next steps in your career. However, schools lose touch with alumni once they graduate and find it difficult to keep a track of where they are. Networking platforms such as Linkedin are helpful but do not provide a big picture of your alumni network. AlmaBase is a Linkedin extension, that shows a visualization of career trajectories of alumni from your program, for you to find the \"right\" alumni to network with and get inspired.\n"
   },
   {  
      "link":"/research/labs/design-and-social-interaction-studio",
      "name":"Ambient Visualization using Interactive Projection Mapping",
      "lab":"Design and Social Interaction Studio",
      "description":"Information visualization can augment human cognition in many ways, and has proved useful in professional application areas such as scientific visualization and business management. But what are the potentials of information visualization in everyday life? Using ambient visualization techniques, the opportunity to co-exist with an embodiment of data in the same physical space, and analyze such a metaphor in relation to the space around us could potentially lead to a greater learning environment. For such environments, how could information exist between\naesthetics and utility to support its cause? The project concerns an interactive weather installation that leverages interactive projection mapping to highlight an aesthetic quality to weather data, and signify its relation to space, movement and time. Working with digital projectors, a coding environment such as OpenCV and Processing, and projection-mapping tools, the project aims to create an interactive projection-mapped experience that provides a platform to analyze weather information in meaningful, aesthetic and engaging ways.\n"
   },
   {  
      "link":"/research/labs/design-and-social-interaction-studio",
      "name":"An Interactive Journey Through Modern Physics",
      "lab":"Design and Social Interaction Studio",
      "description":null
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"Analyzing blocking mechanisms on social media",
      "lab":"Comp.Social Lab",
      "description":"In this project, we analyze blocking mechanisms on social media. We perform a comparative analysis of different technically and socially curated block-lists on Twitter. We also conduct interviews with users who are on such block-lists as well as those who subscribe to them. Our analysis reveals nuances of online harassment and the tactics used by harassers. We discuss the limitations of state of the art moderation used by social media platforms like Facebook, Twitter, etc. We examine how the harassment victims appropriate the online tools and resources available to them to cope with online abuse. We also suggest design implications for improved blocking mechanisms.\n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"Analyzing the Affordances of a Location-Based App to Provide Safety",
      "lab":"Comp.Social Lab",
      "description":"There are not many computing systems available that will help keep individuals safe when meeting up with strangers offline. Therefore, our team has developed an application that will help keep these individuals safe. In order to improve our current system, we will conduct a two-part research experiment: an interactive activity and interviews. This data, along with the data from the activity, will help to address whether or not using a computer system helps people feel safer when traveling alone. The study will be conducted on the campus of the Georgia Institute of Technology.\n \n"
   },
   {  
      "link":"/research/labs/culture-and-technology-lab-cat",
      "name":"Animated Day of the Dead Puppets ",
      "lab":"Culture And Technology Lab (CAT)",
      "description":"Graduate studnets in the Prototyping Interactive Applications class taught by Gregory Abowd worked independently and with high school studnets from Latin American Assoication&#39;s leadership program with&nbsp;Cross Keys High School to create interactive Day of the Dead puppets. This project is part of GoSTEM,&nbsp;a larger effort at Georgia Tech to increase interest in science technology, engineering and mathmatics among Latin youth and to bring Latin culture to Georgia Tech.&nbsp;These&nbsp;animated puppet&nbsp;respond&nbsp;to one or more input(s) and produces visual, audio, and/or kinetic output.\n"
   },
   {  
      "link":"/research/labs/graphics-lab",
      "name":"Animating Human Dressing",
      "lab":"Graphics Lab",
      "description":"Dressing is one of the most common activities in human society. Perfecting the skill of dressing can take an average child three to four years of daily practice. The challenge is primarily due to the combined difficulty of coordinating different body parts and manipulating soft and deformable objects (clothes). We present a technique to synthesize human dressing by controlling a human character to put on an article of simulated clothing. We identify a set of primitive actions which account for the vast majority of motions observed in human dressing. These primitive actions can be assembled into a variety of motion sequences for dressing different garments with different styles. \n"
   },
   {  
      "link":"/research/labs/augmented-environments-lab",
      "name":"Applying Design Studio Pedagogy in STEM  Learning with Novel Presentation and Sensing Technologies",
      "lab":"Augmented Environments Lab",
      "description":"We use Augmented Reality presentation and sensing technologies to integrate design studio learning models into screen-based classrooms. The goal for this approach is to create STEM learning experiences that encourage creativity, innovation and help build strong peer learning environments. To accomplish this goal we implement room-scale augmented reality technology with projection-based presentation and sensing technologies -- projecting on surfaces and using depth sensing for unencumbered interaction (see http://research.microsoft.com/en-us/projects/roomalive/). This approach allows everyone in the space to participate in the experience, and the cost is fixed regardless of the number of participants. \n \nTwo practices from the studio model for learning we build upon are:\n \n  Pinups: In design studios, students will pin their work (completed parts, sketches, parts \nin-development) on a wall, and the teacher and students will walk the walls in order to \ncomment on the pinned-up work. Pinups make both the artifacts and process of design \nwork visible, and make it possible to compare and contrast approaches when all students \nwork is pinned up at once.\n \n  Meetups: Students working together in a design studio can look over to see what others \nare doing. Collaboration is fluid and at multiple levels. Sometimes, two students move \ntheir work near one another to work together (literally, closely). Sometimes, two \nstudents just look at each other's work to share ideas.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"AquaRium Tour: Georgia Aquarium tour experience design",
      "lab":"Experimental Television Lab",
      "description":"This project integrates augmented reality to redesign the Georgia Aquarium tour experience. Based on the existing digital contents from Georgia Aquarium, AquaRium Tour features user-centered interaction to facilitate the aquarium tour experience, incorporating the functions of navigation, providing knowledge about aquatic life as well as sharing and other social features.\n"
   },
   {  
      "link":"/research/labs/interactive-media-architecture-group-education-lab",
      "name":"ARboretum",
      "lab":"Interactive Media Architecture Group in Education Lab",
      "description":"Atlanta has the reputation of being a city in a forest, with a large and varied tree population that provides shade for its residents, a habitat for wildlife, consumes carbon dioxide from the atmosphere, produces life-giving oxygen, in addition to many other benefits. In keeping with its context and commitments to environmental awareness and conservancy, the Georgia Tech campus contains hundreds of species of trees that cover the landscape.\nThe Imagine Lab is building an Augmented Reality application for mobile devices and tablets through which the myriad trees can be viewed interactively. In the app, the user can touch a tree and receive information from a vast database telling the user all the information about it: age, size, species. Not only can the user interact with the visible world, they are also capable of seeing projected tree growth for the next 10, 25, and 50 years, where newly planted trees will grow into shade-giving behemoths, all rendered in 3D on the screen. In addition, the user can experience the subterranean world, with interactive animations for the nearly unprecedented 1.4 million gallon cistern under Tech Green that provides water for the Clough Undergraduate Learning Center and local irrigation. The app allows for someone to receive an augmented view of the world in front of them, enhanced with illustrative educational information that will nurture the environmental consciousness of the user, making them aware of the tremendous benefits of having a green campus, how the systems work, and what it means for the future.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"ARES",
      "lab":"Experimental Television Lab",
      "description":"In a race against the clock, players embark on a dangerous adventure. Within moments, the journey goes haywire. Lost and alone, the player finds themselves stranded. In this VR interactive narrative, players fight to survive the dangerous landscape. Utilizing Oculus Rift, Unity, and unique interaction paradigms, Ares explores a wide range of new techniques in VR storytelling. This distinctive, immersive experience will test user's survival skills and offer an exciting challenge.\n"
   },
   {  
      "link":"/research/labs/augmented-environments-lab",
      "name":"Argon: AR-Enabled Web Browser",
      "lab":"Augmented Environments Lab",
      "description":"Argon is a mobile web browser designed to bridge the gap between Augmented Reality and The Web. Following in the tradition of web browsers like Chrome and Firefox, which differentiate themselves by providing custom functionality that is not yet standardized across all browsers, Argon exposes the core technologies needed to make AR possible.  By making computer vision tracking (via the Qualcomm's Vuforia library) available to web pages, Argon provides a browser-based platform for rapid development of fully-interactive 2D/3D AR content & applications. Come see projects & demos built using the Argon platform.\n"
   },
   {  
      "link":"/research/labs/augmented-environments-lab",
      "name":"ARToss : Networked Argon3 Game Demo",
      "lab":"Augmented Environments Lab",
      "description":"ARToss is a multiplayer game built using Argon using a NodeJS web server with WebSockets.\n"
   },
   {  
      "link":"/research/labs/interactive-products-design-lab",
      "name":"Astro Pup: An interactive, musical, space adventure",
      "lab":"Interactive Products Design Lab",
      "description":"This educational toy concept helps teach children visual-spatial cognitive skills and logical-mathematical reasoning through interactive music creation. Build from LegoMindstorms, the project explores the tool's applications in early stage interactive concept development for designers. \n"
   },
   {  
      "link":"/research/labs/design-and-social-interaction-studio",
      "name":"Atlanta Beltline Exploration App",
      "lab":"Design and Social Interaction Studio",
      "description":"The Beltline Exploration App is a proposed location-based walking tour application aimed at increasing community engagement and participation on the Atlanta Beltline. The existing Atlanta Beltline app provides a wealth of information that can be improved with a more participatory interaction from the user and an element of user content creation. The goal is for the app to bring awareness to art, culture, and events along portions of the Atlanta Beltline that will introduce newcomers to the Beltline and promote repeat visits to the Beltline.\n"
   },
   {  
      "link":"/research/labs/augmented-environments-lab",
      "name":"Auburn Avenue: Augmented Reality for Cultural Heritage",
      "lab":"Augmented Environments Lab",
      "description":"We are developing a suite of media experiences to introduce visitors to the rich cultural and economic history of Auburn Avenue. From about 1900 to 1960, Auburn Avenue was the center of African-American cultural and economic life in the city. The street also played a key role in the civil rights movement. From the 1960s on, the street suffered decline, and the local community disintegrated because of a range of social, economic, and urban planning factors. In recent years, however, the community has been the focus of revival efforts with attractive apartments and homes at its eastern end and increased economic activity along its more blighted corridor. In 2014 or 2015, a new streetcar line promises to bring even more tourists to its main attractions: the Martin Luther King Visitors Center, King's birth home, the Ebenezer Baptist Church, and the King Memorial. Sweet Auburn was designated a National Historic Landmark in 1976. We are working in collaboration with Central Atlanta Progress and the History Preservation Division of the Dept of Natural Resources of the State of Georgia to bring this history to thousands of visitors and residents through an integrated integrated media strategy. Our media strategy centers on a prototype of a mobile app using the Argon browser. This will be supported by web applications that can run on other mobile devices as well as a web site.\nThe content types and features that we will explore include:\na. audio, images and text delivered on location at places of interest along the avenue.\nb. panoramas and historical photographs to depict the visual history of Sweet Auburn.\nc. informative texts to replace or complete existing physical signage;\nd. forms of interaction that trigger the delivery of these images, audio, and text: for example, when users walk down the street, GPS tracking can tell the phone when to play certain audio or show certain images.\ne. links to social media so that visitors can record their experience of the tour of the avenue for friends or for their own later use.\nOur ultimate goal is to ensure the broadest possible class of visitors and web users to have a satisfying and informative experience of Auburn Avenue and make sure that the digital media application is a successful and sustainable informational companion that supports the preservation and revitalization efforts in this area.\n"
   },
   {  
      "link":"/research/labs/sonification-lab",
      "name":"Audio Lemonade Stand Game",
      "lab":"Sonification Lab",
      "description":"This project helps teach STEM concepts with an audio-enabled version of the Lemonade Stand Game, in which visually impaired players (or any player that wants to experience a game that is sound dependent) need to manage their own stand while factoring in weather, local events, advertisement, and pricing in order to maximize profit for their business.\n"
   },
   {  
      "link":"/research/labs/sonification-lab",
      "name":"Auditory STEM: Math and Science Education for Students with Vision Impairment",
      "lab":"Sonification Lab",
      "description":"The graphs and figures that are so prevalent in math and science education make those topics largely inaccessible to blind students. We are working on auditory graphs that can represent equations and data to those who cannot see a visual graph. A number of new areas we're starting research on is looking at teaching astronomy concepts through (like the Solar System) and the teaching and understanding of weather information through a combination of sonification and auditory description. Additionally we are working on making statistical output accessible for blind users to assist with higher level mathematics applications. We have a whole ecosystem of software and hardware solutions, both desktop and mobile, to help in this space. This project is in collaboration with the Georgia Academy for the Blind and the Center for the Visually Impaired of Atlanta.\n"
   },
   {  
      "link":"/research/labs/interactive-media-technology-center-imtc",
      "name":"Augmented Reality experiments on Support for Political Protest vs. Terrorism",
      "lab":"Interactive Media Technology Center (IMTC)",
      "description":"In collaboration with policial science researchers from Georgia State University and University at Albany, we are developing augmented reality-based experiments to examine the impact of grievance, opportunity and risk as motivating factors when choosing to engage in political protest or terrorism.  Study participants assume the role of a fictional ethnic minority in a fictional country and engage in dialogs with virtual characters that attempt to persude the participant to join a peaceful student-led protest or join a violent resistance movement.  Participants wear a head-mounted video display instrumented with cameras that allow them to view computer graphics mixed with the physical space about them.  Sitting at a table, the participant can then see and hear virtual characters that appear to sit across from them, allowing the participant to experience a first-person point of view in dialogs with these virtual characters. \n \n"
   },
   {  
      "link":"/research/labs/sonification-lab",
      "name":"Automated Driving Displays",
      "lab":"Sonification Lab",
      "description":"Automated safety systems, a first step toward autonomous vehicles, are already available in many commercial vehicles. These are systems such as adaptive cruise control, which has the capability to slow down due to traffic, and automatic lane keeping, which maintains position within a lane without driver intervention. In order to ensure that these systems are properly used by drivers it is essential that they understand and appropriately trust the technology. We are currently investigating personal characteristics and driving environments that influence acceptance and use of automated safety systems and developing multimodal displays to increase situation awareness.\n \n"
   },
   {  
      "link":"/research/labs/entertainment-intelligence-lab",
      "name":"Automatically Generating Game Levels from Gameplay Videos",
      "lab":"Entertainment Intelligence Lab",
      "description":"Check out videos of the system: here and here\nIntelligent tools can ease the burden of game development. One approach to easing this burden is the use of co-creative, artificial agents, capable of helping a human developer by making suggestions or extending an initial design. However, agents capable of design have historically required a large amount of hand-authored design information\u2014domain-specific rules, heuristic functions, or formal logic rules. Due to the time it takes to author this knowledge, such approaches do not remove the development burden, but shift it to the author of the agent. To solve this problem we present a demonstration of a level-authoring tool with a co-creative agent informed by knowledge learned from gameplay videos. The technique is demonstrated in the popular game, Super Mario Bros. We offer the experience of co-designing a level with a co-creative agent and then playing through the level yourself or with a friend.\n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"Automod: Machine Learning-Based Approaches Toward Combatting Abusive Behavior in Online Communities",
      "lab":"Comp.Social Lab",
      "description":"Since its earliest days, flaming, trolling, harassment and abuse have plagued the Internet. Our aim is to computationally model abusive online behavior to build tools that help counter it, with the goal of making the Internet a more welcoming place. In particular, we look at a novel approach to identify online verbal abuse using cross-community linguistic similarities between posts on different communities. This work will enable a transformative new class of automated and semi-automated applications that depend on computationally generated abuse predictions. \n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"B.B.C.S. - Bio-Behavioral Capture System",
      "lab":"Ubiquitous Computing Group",
      "description":"B.B.C.S. is a working system that can be easily deployed at homes, clinics, laboratories and therapy centers among others, in order to help its users collecting relevant behaviors of interest over long periods of time to get a deeper understanding of them.  \nThis system captures behaviors of interest using multiple cameras alongside biological signals, such as heart rate, in a synchronized manner, allowing the user to analyze visible and invisible characteristics of behaviors.  B.B.C.S. is intended to be an everywhere / anywhere system, so it allows the user to annotate, comment and control the system in situ.\nSince B.B.C.S. can store weeks of data it was design that allows quickly browsing and filtering week's worth of data to get to specific moments of interest.\nAs an example of a potentially interesting deployment scenario, we could mention the houses of families with individual(s) on the Autism Spectrum. Using this system would enable parents and researchers to obtain lots of data in their natural environment. We would be bringing the Lab home.\n"
   },
   {  
      "link":"/research/labs/interactive-products-design-lab",
      "name":"Ballet Hero: building a garment for memetic embodiment in dance learning",
      "lab":"Interactive Products Design Lab",
      "description":"This project concerns the analysis and design of a wearable technology garment intended to aid with the instruction of ballet technique to adult beginners. A phenomenological framework is developed, and used to assess physiological training tools. Following this, a garment is developed that incorporates visual feedback inspired by animation techniques that more directly convey the essential movements of ballet. The garment design is presented, and a discussion is provided on the challenges in constructing an e-textile garment using contemporary materials and technique\n"
   },
   {  
      "link":"/research/labs/research-network-operations-center-rnoc",
      "name":"Barcode Fitness",
      "lab":"Research Network Operations Center (RNOC)",
      "description":"Barcode Fitness, a fitness application that helps you keep track of the details of your weightlifting workouts at the Campus Recreation Center at Georgia Tech. Ditch your clumsy notebook that you were using to write down all of your sets and repetitions in favor of Barcode Fitness. Barcode Fitness supports over 40 different exercises and allows for nearly instant selection of exercises by allowing you to scan the QR codes located on all supported exercise machines.\n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"Being Nice on the Internet: Designing for the Coexistence of Diverse Opinions Online",
      "lab":"Comp.Social Lab",
      "description":"Exposure to diverse opinions makes us more informed and engages society in a necessary deliberation process. Inwardly focused groups risk tunnel vision and an inability to challenge their own views. Technically, online we can connect to anyone in the world but social network analyses of blogs and Twitter have shown that we stay connected in groups of like-minded others. There is untapped potential here for online environments to go further towards giving more access to diverse views. Incivility has direct consequences for relationships with others of different opinions. It has been shown that in televised political debates, incivility increases negative feelings towards the other side. While disagreement is necessary in a healthy democracy, alienating arguments result in the current culture wars. I will present work I have done on encouraging civility on a platform like Facebook could alleviate frustrations such as the need to tune out when there is overwhelming disagreement.\n"
   },
   {  
      "link":"/research/labs/venture-lab",
      "name":"Better Walk",
      "lab":"Venture Lab",
      "description":"In the U.S. alone, approximately 18 million people use crutches each year. The human body was not designed to bear its weight on the forearms and wrists, but all designs of the crutch force patients to do just this. In just a few steps with the underarm crutch, forearm fatigue sets in resulting in patients resting upon the underarm padding. The upward force from the padding leads to pain, chafing, blood vessel compression, nerve compression, and possible nerve damage. Forearm crutches, while avoiding the underarm area, are difficult to use and direct a large amount of torque to the shoulder, resulting in shoulder injuries, frequent imbalance, and falls. Not including the costs of treatments for the side effects of crutch use, patients spend over $800 million each year on these 5000 year old, inefficient devices. \nThe Better Walk crutch puts a patient's mind at ease. The redesigned support system reduces the risk of underarm nerve damage, reduces forearm fatigue, and improves patient comfort resulting in increased compliance and a safer, more comfortable rehabilitation process.\n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"Bicentric Diagrams: Design and Applications of a Graph-Based Relational Set Visualization Technique",
      "lab":"Computational Enterprise Science Lab",
      "description":"Visualizations can help amplify human cognition. In an era where networks are becoming increasingly complex, the desirability of tools to compare and contrast sets, relationships, and reach is significant. Motivated by a practical need articulated by corporate decision makers, this research presents our journey in designing and implementing bicentric diagrams, a novel graph-based set visualization technique. A bicentric diagram enables simultaneous identification of sets, set relationships, and set member reach in integrated ego networks of two focal entities. Our technique builds on the well-established theory of tie strength to visually group and position nodes. We illustrate the broad applicability of bicentric diagrams with examples from four diverse sample domains: university collaboration, technology co-occurrence, health app purchases, and innovation ecosystems network. We assess the value of our technique using an expert-based value-driven evaluation approach. The paper concludes with implications and a discussion of opportunities for implementation in real-world settings.\n"
   },
   {  
      "link":"/research/labs/graphics-lab",
      "name":"Blending Liquids",
      "lab":"Graphics Lab",
      "description":"We present a method for smoothly blending between existing liquid animations. \nWe introduce a semi-automatic method for matching two existing liquid animations, which we use to create new fluid motion that plausibly interpolates the input.\nOur contributions include a new space-time non-rigid iterative closest point algorithm that incorporates user guidance, a subsampling technique for efficient registration of meshes with millions of vertices, and a fast surface extraction algorithm that produces 3D triangle meshes from a 4D space-time surface.\nOur technique can be used to instantly create hundreds of new simulations, or to interactively explore complex parameter spaces.\nOur method is guaranteed to produce output that does not deviate from the input animations, and it generalizes to multiple dimensions. Because our method runs at interactive rates after the initial precomputation step, it has potential applications in games and training simulations.\n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"BlockParty: A Platform for Building Hyper-local Social Computing Applications on Residential Mesh Networks",
      "lab":"Comp.Social Lab",
      "description":"Modern social media do a remarkable job of keeping friends and families connected\u2014often across the globe. Yet, these same systems also overlook the communities and neighborhoods where we live our daily lives. In this paper, we present BlockParty, a platform for building hyper-local social computing applications aimed at neighborhoods. A key feature of our platform is that it runs on top of residential wireless routers via an underlying mesh network. Using BlockParty, people can socialize with their neighbors and share resources, without their data ever leaving their local community. The goal of BlockParty is to enable new forms of neighborhood-oriented social computing applications that encourage the creation of local ties and local social capital.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Bridging Cultural Differences",
      "lab":"Experimental Television Lab",
      "description":"In the era of globalization, the ordinary viewer is exposed to cinematography from different countries and cultures, but does one understand the cultural context portrayed by the artists?\nIn this project I intend to use interactive television as a medium, that helps the viewer to gain a deeper understanding of a movie, by exposing him/her to its cultural layers.\n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"Building and Testing a Developmental Milestone Tracking App with Parents and Childcare Providers",
      "lab":"Ubiquitous Computing Group",
      "description":"The earlier autism spectrum disorder (ASD) is detected, the earlier children can receive intervention services, resulting in improved social, cognitive, and adaptive skills. Birth to 5 years is an especially critical time for identifying potential signs of delayed or unusual development that may indicate ASD. Tracking children's development can lead to an earlier diagnosis, and the Centers for Disease Control and Prevention (CDC) provides developmental monitoring tools for this through its Learn the Signs. Act Early. program.\nThe goal of this project is to develop and evaluate an Android app that makes CDC's developmental monitoring tools more readily accessible to parents of young children, making it easier for parents to identify early signs of ASD or other developmental delays.\n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"Business Ecosystem Clustering & Simulation",
      "lab":"Computational Enterprise Science Lab",
      "description":null
   },
   {  
      "link":"/research/labs/research-network-operations-center-rnoc",
      "name":"Campus Tour",
      "lab":"Research Network Operations Center (RNOC)",
      "description":"Campus Tour is an augmented reality experience of Georgia Tech's campus. Once the channel is loaded in Argon, a standards-based Augmented Reality (AR) web browser developed by the Augmented Environments Lab.  The tour gives information to users through text, pictures and videos. Stops on the tour are panoramic images.  Within the panoramas are points of interests that once clicked reveal more information about their topic.  Campus Tour allows users to remotely enjoy the beauty of campus or to learn more about Tech while on campus. Campus Tour also lets you build your own expierences and tours.  Using our own custom web based editor you can choose which curated elements to use and build off of adding your own custom elements to create your own unique experiences.\n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"CampusLife",
      "lab":"Ubiquitous Computing Group",
      "description":"College students encounter many challenges in the pursuit of their educational goals. When these challenges are prolonged, they can have drastic consequences on health and on personal, social, and academic life. Our multi-institution project, called CampusLife, conceptualizes the student body as a quantified community to quantify, assess, infer, and understand factors that impact well-being. Our goal is to develop privacy-honoring infrastructure and tools that can first sense lifestyle, moods, activities through active and passive techniques, and then utilize that information in the design of self-reflective tools that could make students more self-aware and pro-active toward improving their well-being\n"
   },
   {  
      "link":"/research/labs/contextual-computing-group",
      "name":"Captioning on Glass",
      "lab":"Contextual Computing Group",
      "description":"Captioning on Glass is an on-going project creating an app for Google Glass with a companion Android phone app to assist the hard-of-hearing in everyday conversations. We are also working on another version of this app, \"Translation on Glass\", which will add the ability to translate between English and another language.\n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"Care Process Graphs: Exploring Clinical Care Processes Using Visual and Data Analytics",
      "lab":"Computational Enterprise Science Lab",
      "description":"Healthcare big data is being widely touted as a potential resource for curbing costs and improving outcomes. However, numerous challenges remain for leveraging this data to its full potential. In this position paper we identify the difficulties that characterize clinical data, based on our experiences working with pediatric asthma data from Children's Healthcare of Atlanta. The specific dataset we explored includes administrative items, medications, lab results, clinical respiratory scores (outcome), timestamps, and demographic information from 5,785 emergency department (ED) visits for asthma exacerbations. We argue that new data and visual analytic techniques are needed that are specifically tailored for solving challenges in healthcare, and we propose characteristics that these techniques should have and give our design rationale. To demonstrate how a tool that embodies these desirable features may be designed, we introduce CareProcessVis, a prototype interactive visual analytics tool that helps clinicians explore and understand the processes involved in pediatric asthma emergency department care.\n"
   },
   {  
      "link":"/research/labs/technologies-and-international-development-lab",
      "name":"CASE: Content Aggregation Systems for Elections",
      "lab":"Technologies and International Development Lab",
      "description":"The Content Aggregation System for Election Observation (CASE) will aggregate real-time election observation data from formal observer missions and social media sources. Our new system, combining the power of crowdsourced data from social media with the precision of formal observers in the field, will create a first-ever fully integrated monitoring system. Simple technical interfaces will allow users to share particular information in real-time while still maintaining necessary data security and privacy. An integrated visual dashboard will allow all project participants to view, analyze and understand real-time data from social media fully integrated with real-time data from participating formal observer groups. The system will be test deployed in 2014 and fully deployed during the 2015 Nigerian national election.\n"
   },
   {  
      "link":"/research/labs/contextual-computing-group",
      "name":"CHAT - A Dolphin Interaction Wearable",
      "lab":"Contextual Computing Group",
      "description":"CHAT (Cetacean Hearing Augmentation &amp; Telemetry) is a wearable underwater computer system, engineered to assist researchers in establishing two-way communication with dolphins. The project seeks to facilitate the study of marine mammal cognition by providing a waterproof mobile computing platform. An underwater speaker and keyboard enables the researchers to generate whistles. The system is equipped with a two channel hydrophone array used for localization and recognition of specific responses that are translated into audio feedback. The current system is the result of multiple field tests, guided by the researchers feedback and the environmental constraints.\nhttp://hdl.handle.net/1853/52112\n"
   },
   {  
      "link":"/research/labs/software-engineering-lab",
      "name":"CheckDroid",
      "lab":"Software Engineering Lab",
      "description":"CheckDroid is a service for Android development teams to test and support their applications on different devices. We are creating the next generation testing & debugging tools for mobile developers.\nTesting mobile apps across different platforms is challenging because of the sheer number of device types -- 22 iOS devices & 18K Android devices. This is often referred to as the Fragmentation problem.\nOur demo will present two tools:\n1. App Mirror: This a capture-replay tool that allows a mobile developer to record their interactions with the app in one device and see the results of the same interaction across multiple devices.\nIt allows for both LIVE replay for manual testing and for reporting any differences or issues in an offline report.\n2. Cloud Test: This is a web based environment that allows the developer to interactively write tests for their app and then run these tests on a test-bed of devices.\n"
   },
   {  
      "link":"/research/labs/digital-world-and-image-group",
      "name":"Cinematic Interfaces",
      "lab":"Digital World and Image Group",
      "description":"Digital tools exist for creating practically every type of artistic, creative, or communicative digital artifact, including pictures, music, video, and computer animation. This project explores a combined AI-HCI approach to participatory intelligent agents that help amateurs create digital moving image media, such as machinima.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"ClipLine",
      "lab":"Experimental Television Lab",
      "description":"ClipLine\u2014A social sharing mobile platform that helps users turn their favorite TV scenes into customized GIFs and instantly share them with their friends and the outside world. Voting up the best GIFs, re-clipping, and following other accounts will also be main features of ClipLine.\n"
   },
   {  
      "link":"/research/labs/acme-lab",
      "name":"Clock Reader",
      "lab":"ACME Lab",
      "description":"Early detection of symptoms is of critical importance in diagnosing and treating cognitive dysfunction. One important instrument utilized for detecting early signs of cognitive dysfunction is the Clock-Drawing Test. In this test, patients are asked to draw a clock face at a certain time, and are evaluated on how well they perform this task. At present, analysts must individually administer and assess each test a person completes. Automating the process would grant many advantages: the patients could complete the clock test more often to measure improvement, stabilization or variation over time; the patients would receive immediate feedback on their results; the evaluation structure would become more standardized for broader assessment; and multiple evaluation tools could be utilized simultaneously. Toward these ends, the ClockReader project will seek to automate the administration and evaluation of Clock-Drawing Tests on tablet PCs. The ClockReader project will then be tested on both past Clock-Drawing Tests and new tests performed by new participants.\n"
   },
   {  
      "link":"/research/labs/participatory-publics-lab",
      "name":"Community Historians",
      "lab":"Participatory Publics Lab",
      "description":"This project is developed through an ongoing collaboraton with the Historic Westside Cultural Arts Council. Through a series of design workshops and public events we are co-designing mobile and social technologies to help cultivate a shared community identity to support local civic engagement. By working directly with community members, we are able to build technology platforms suited to their specific needs and which amplify their values and concerns as the community goes through significant changes.\n"
   },
   {  
      "link":"/research/labs/adam-lab",
      "name":"Computational Pretend Play",
      "lab":"ADAM Lab",
      "description":"Pretend play helps children develop a wide range of cognitive skills and is therefore a critically important skill for kids to learn. Some children, such as those on the Autism Spectrum, have difficulties engaging in pretend play. This project seeks to understand and model what constitutes successful pretend play in order to design and implement technologies to support and facilitate highly engaging pretend play. The exact nature of that intervention is an open question, and we are exploring several exciting options including a robotic play partner and an immersive virtual play world. The first step in this initiative is building a cognitive model of play and then developing a computational framework that enables a artificial intelligence system to generate improvisational play behaviors based on our computational model of play. In our demo, we will show some early results from a study observing adult dyads engaged in play behavior as well as the first prototype of the immersive virtual play world.\n"
   },
   {  
      "link":"/research/labs/aware-home-research-initiative",
      "name":"Connected Living Research Initiative",
      "lab":"Aware Home Research Initiative",
      "description":"Connected living is the fast-growing intersection of mobile, wearable, home, community, car and other technologies to assist individuals in accomplishing more seamless interactions and goals in daily life. Mobility and cloud computing are two pillars of growth that has brought about significant changes in industry. Cloud computing, big data, mobility and low-cost sensors are driving the internet of things and connected industries, and the internet of things is forcing transformation and innovation across the connected home, connected workplace and connected city. It is estimated that the Connected Living market will reach 730 Billion USD by 2020.\nWe are in the process of defining the Connected Living Research Initiative (CLRI) to bring together industry stakeholders, academic/research faculty and civic partners in defining the future of the connected life. CLRI is currently on boarding partners to delineate research goals that include (but is not limited to) the future impact of big data, improved user experience in daily activities, and data security and privacy in this ever more connected daily experience.\nFor more information contact: Brian Jones or Siva Jayaraman\n"
   },
   {  
      "link":"/research/labs/research-network-operations-center-rnoc",
      "name":"Convergence Innovation Competition",
      "lab":"Research Network Operations Center (RNOC)",
      "description":"The Convergence Innovation Competition (CIC) is a unique competition open to all Georgia Tech students and is run in both the Fall and Spring semesters. Each year the categories in the CIC are defined by our Industry partners who provide mentorship, judging, and category specific resources which are often available exclusively to CIC competitors. While the competition is not tied to any specific course, competitors are often able to take advantage of class partnerships where lecture and lab content, guest lectures, and projects are aligned with competition categories. CIC Competitors are supported by GT-RNOC research assistants who provide technical support and shepherd teams through the competition process. The overarching goal of the CIC is to create innovative and viable products and experiences including a strong user experience and a business case. Winning entries will include a working end-to-end prototype which operates on converged services, media, networks, services, and platforms. CIC winners go on to commercialization, other competitions, as well as internship and job opportunities strengthened by their competition experience.\n"
   },
   {  
      "link":"/research/labs/design-and-social-interaction-studio",
      "name":"Conversational Media: Designing a Decision Aid for Diabetes Medication Choice",
      "lab":"Design and Social Interaction Studio",
      "description":"Over 29 million people in the U.S. live with type II Diabetes. There are many types of medications available to help manage Diabetes, and these medications impact patients' lives in unique ways. Following tenets of evidence-based medicine, participatory design and shared decision making, design researchers at the Mayo Clinic have created a set of cards for use in patient-physician conversations, to help both parties reach a decision on diabetes medication choice. I'm working on an updated digital version of this decision aid, which offers opportunities for tailored content and easier-to-update information while aiming to maintain the flexible, accessible spirit of the original tool. \n"
   },
   {  
      "link":"/research/labs/contextual-computing-group",
      "name":"CopyCat",
      "lab":"Contextual Computing Group",
      "description":"This project involves the design and evaluation of an interactive computer game that allows deaf children to practice their American Sign Language skills. The game includes an automatic sign language recognition component utilizing computer vision and wireless accelerometers. The project is a collaboration with Dr. Harley Hamilton at the Atlanta Area School for the Deaf.\n"
   },
   {  
      "link":"/research/labs/electronic-learning-communities",
      "name":"Copyright and Social Norms in Online Creative Communities",
      "lab":"Electronic Learning Communities",
      "description":"Every day, ordinary Internet users engage with complex copyright laws. Particularly in the context of creative work and appropriation, they are making decisions related to legal areas that are notoriously gray. Where legal knowledge is imperfect, social norms and ethical intuitions fill in the gaps. This research attempts to understand how these decisions are made, how norms and knowledge differ in different creative communities, and what lessons can be derived for online community management and design.\n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"COSMOS: COmputational Skins for Multi-functional Objects and Systems",
      "lab":"Ubiquitous Computing Group",
      "description":"COSMOS (COmputational Skins for Multi-functional Objects and Systems) is an interdisciplinary collaborative project to design, manufacture, fabricate, and apply \"computational skins\". COSMOS consist of dense, high-performance, seamlessly-networked, ambiently-powered computational nodes in the form of 2D flexible surfaces that can process, store, and communicate sensor data. Achieving this vision will redefine the basis of human-environment interactions by creating a world in which everyday objects and information technology become inextricably entangled. This will also enable alternative and neuromorphic computing that can change the foundation of computing today.\n"
   },
   {  
      "link":"/research/labs/graphics-lab",
      "name":"Coupling Cloth and Rigid Body for Dexterous Manipulation",
      "lab":"Graphics Lab",
      "description":"This project introduces a new simulation technique to enable detailed dexterous manipulation of cloth. Without reimplementation or substantial modification, existing cloth simulators can only be used to approximate limited interaction between cloth and rigid bodies due to the incorrect computation of contact forces. For example, a simple scenario of two fingers pinching a piece of cloth often results in the cloth slipping out of the hand. Our technique provides a simple solution to cloth-rigid coupling using existing cloth and rigid body simulators as-is. We develop a light-weight interface so that the rigid body and cloth simulators communicate on a demand-driven manner to achieve two main goals: allow the rigid bodies to impart friction forces to the cloth and avoid unsolvable collision situations between the rigid bodies and the cloth. We demonstrate a set of basic manipulation skills including gripping, pinching, and pressing, that are frequently seen in daily activities such as dressing and folding clothes.\n \n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"CREDBANK: A Large-scale Social Media Corpus With Associated Credibility Annotations",
      "lab":"Comp.Social Lab",
      "description":"Social media has quickly risen to prominence as a news source, yet lingering doubts remain about its ability to spread rumor and misinformation. Systematically studying this phenomenon, however, has been difficult due to the need to collect large-scale, unbiased data along with in-situ judgements of its accuracy. In this paper we present CREDBANK, a corpus designed to bridge this gap by systematically combining machine and human computation. Specifically, CREDBANK is a corpus of tweets, topics, events and associated human credibility judgements. It is based on the real-time tracking of more than 1 billion streaming tweets over a period of more than three months, computational summarizations of those tweets, and intelligent routings of the tweet streams to human annotators\u2014within a few hours of those events unfolding on Twitter. In total CREDBANK comprises more than 60 million tweets grouped into 1049 real-world events, each annotated by 30 human annotators. As an example, with CREDBANK one can quickly calculate that roughly 24% of the events in the global tweet stream are not perceived as credible. We have made CREDBANK publicly available, and hope it will enable new research questions related to online information credibility in fields such as social science, data mining and health.\n"
   },
   {  
      "link":"/research/labs/technologies-and-international-development-lab",
      "name":"Crowdsourcing UN 2015 Millennium Development Goals",
      "lab":"Technologies and International Development Lab",
      "description":"In 2000 the United Nations announced the Millennium Development Goals, a set of development targets and objectives to reduce poverty and improve health, education, and the environment. These goals are set to be completed by 2015. The system of United Nations organizations is currently formulating a new set of development goals for beyond 2015. To create a more participatory process, the International Telecommunication Union uses an online platform to crowdsource the ideas and comments of youth around the world. The ITU requested the assistance of the TID lab to provide interpretation and textual analysis of the youth's priorities based on the crowdsourced data. We are developing new visualizations and analysis of this unique dataset. This analysis will help inform the post 2015 UN development agenda.\n"
   },
   {  
      "link":"/research/labs/contextualized-support-learning",
      "name":"CSLearning4U: Creating Electronic Books for Teacher CS Learning",
      "lab":"Contextualized Support for Learning",
      "description":"A key idea in CSLearning4U is that we can design CS learning opportunities. Simply wrestling an interpreter or compiler can't be the best way to learn about computer science. Throwing people into the deep end of the pool can teach people to swim, but there are better ways. We want to do better than a book for CS learning, and we want to design the phonics of computing education to integrate with the \"whole language learning\" of programming.\nWe are creating a new distance-learning medium for computing education especially for in-service high school teachers based on ideas from instructional design and educational psychology. In-service high school teachers are particularly time-constrained (and thus need efficiency) and they are more metacognitively aware than other students (and thus able to better inform the project design). The new medium will combine multiple modalities, worked examples, and structure based on cognitive models of designers' knowledge. The research questions are that (1) the teachers will learn CS knowledge in the on-line setting, (2) the teachers will be more efficient at programming tasks, and (3) the teachers will find the materials useful and satisfying. Because of its focus on teachers, the project can potentially have broad impact, in particular on the strategies for training the 10,000 teachers envisioned in the CS 10K Project. The project will establish models and design guidelines that can be used for the creation of other learning materials, including materials for students in, for example, the proposed new CS Principles AP course.\n"
   },
   {  
      "link":"/research/labs/aware-home-research-initiative",
      "name":"Cue - Connecting U Everyday",
      "lab":"Aware Home Research Initiative",
      "description":"No matter what age we are, we have likely forgotten to turn off the stove or oven, iron, heater or even water. Forgetfulness can lead to serious events that may result in costly damage to the home or even injury or death. Older adults are more prone to such forgetfulness. When an older adult forgets to turn off a hazardous appliance, it is often attributed to losing mental capacity and may lead to loss of self-confidence, embarrassment, and judgment from others. Many families turn to monitoring when they discover such hazards, but this can result in their loved one feeling a loss of independence. We feel there is an opportunity before monitoring to use technology to provide gentle reminders or cues that empower the resident to determine for themselves when such appliances should be turn off.  \nIntroducing cue. The system would consist of several ambient and/or wearable reminder products that would integrate with existing connected home systems and provide those gentle reminders both at and away from the primary hazard. We have designed, a couple of example reminder concepts, mainly for the stove, oven, iron, or heater to address this need. The latest consists of a device in proximity of the stove that provides a larger/brighter light than most stovetops with an integrated proximity sensing capability and a smartwatch with ability to vibrate and alert through sound and visuals. If motion is no longer detected in the kitchen, the watch would alert the user of the potential hazard. The user may also choose to snooze the reminder.\nWhile we focused on hazardous appliances, this same system may support cues related to medication taking, water leaks, door lock status, smoke detector battery level, feeding or walking the do, or similar needs.\n"
   },
   {  
      "link":"/research/labs/graphics-lab",
      "name":"Curve Averaging",
      "lab":"Graphics Lab",
      "description":"We present our work on computing an average curve given a set of planar input curves, with select applications. This work, to be soon presented at the Symposium on Geometric and Physical Modeling, provides a mathematical formulation and a fast algorithm for the problem of finding an average curve, given a set of input curves. Applications in the field of animation and statistical analysis are highlighted.\n"
   },
   {  
      "link":"/research/labs/participatory-publics-lab",
      "name":"Cycle Atlanta",
      "lab":"Participatory Publics Lab",
      "description":"Fifty percent of all trips are 3 miles or less, yet only 1.8% of those trips are biked.  Meanwhile, 35.7% of US adults are obese and the transportation sector accounts for 32% of US greenhouse gases.   One of the main reasons citizens do not use the healthier mode of cycling is due to a lack of safe infrastructure\u2014dedicated bicycle routes, roads with bicycle lanes, and other designated bicycle facilities.  The City of Atlanta has a desire to put proper cycling infrastructure in place but needs better information from citizens about where they currently and would like to cycle.  Therefore, the initial goal of the Crowd-sourced Bicycle Route Desirability project is to modify the open-source CycleTracks application (previously adopted in San Francisco, CA, and Austin, TX.) for use in Atlanta.  CycleTracks tracks the existing routes of cyclists using their smart phones and allows comparison of these routes to the quickest path from origin to destination.  This allows us to begin to make appropriate infrastructure improvements to the most traveled routes in a study area by seeing logical paths that cyclists avoid.  A second phase of the project would develop applications allowing riders to express their desired bike routes even if they currently do not cycle because of lack of adequate facilities.\n"
   },
   {  
      "link":"/research/labs/local-data-design-lab",
      "name":"Data Artifacts",
      "lab":"Local Data Design Lab",
      "description":"The term artifact has at least two meanings. From a technical perspective, an artifact is an unintentional pattern in data, arising from processes of collection and management. From a cultural perspective, an artifact is a designed object, with a social and material history. At metaLAB, which is grounded in both technical and cultural methods, we are examining digital artifacts with both meanings in mind. In Data Artifacts, we are developing visual methods of revealing the often-unacknowledged patterns in digital data that speak to the social and material history of its accumulation. Never raw, all data carries traces of human labor, intentions and values. Data Artifacts is an inquiry into the deep history of digital collections. Digital cultures, which devote vast resources to the harvesting and handling of data sets, can be understood in part through the particular ways in which they pattern data. Artists and designers with knowledge of computing are poised to uncover such data artifacts through visualization. However, most formal approaches to visualization call for data to be filtered and standardized at the outset. In contrast, we focus on the heterogeneity inherent in human-made data. The messiness of data sets can tell us much about the history of their production. The ambition of Data Artifacts is to develop new tools to contemplate such large-scale collection processes and enable richer discussions about their technical and cultural significance.\n"
   },
   {  
      "link":"/research/labs/georgia-tech-center-music-technology",
      "name":"DataToMusic Web API",
      "lab":"Georgia Tech Center for Music Technology",
      "description":"DTM API is a musical data sonification toolset for rapid development and experimentation of web-based audio applications. The API offers a data-agnostic, adaptive, and highly interactive real-time system, with reusable and extendable musical structure models to represent data in various ways. The API is being used in several projects, including in Beltline Social Dashboard, Decatur Civic Sonification with Sonic Generator performance, which is presented at Atlanta Science Festival 2015, in collaboration with GTRI Configurable Lab.\n \n"
   },
   {  
      "link":"/research/labs/game-studio",
      "name":"Dear Games ",
      "lab":"Game Studio",
      "description":"Dear Games is an educational program collaboration between Charis Circle, members of the GA Tech Game Studio and Different Games Collective. We offer inclusive events to support diverse participation in videogame developement and culture at the South's oldest independent feminist bookstore, Charis Books and More, with consideration to the ways that longstanding feminist community organizations can inform contemporary efforts to increase diversity in STEM.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Debate Slates",
      "lab":"Experimental Television Lab",
      "description":"Debate Slates is a second screen application experience designed to facilitate discussion of theories and future plot developments of long-form narrative television (e.g. Game of Thrones, True Detective and Fringe); Debate Slates also hopes to facilitate discussions on current events, focusing on televised reportage of ISIS and the developing situation in Iraq and Syria.\n"
   },
   {  
      "link":"/research/labs/everyday-computing-lab",
      "name":"Defining Digital Self Harm",
      "lab":"Everyday Computing Lab",
      "description":"This project aims to define the concpet of digital self-harm for the HCI community. In this project we have explored the limited HCI scholarship related to self-harm within a social computing context. We offer the community an operatlonalized defintion of digital self-harm and propose a theoretical base to orientate related research questions into actionable activities. We also describe a research agenda for digital self-harm, highlighting how the HCI community can contribute to the understanding and designing of technologie sfor self-harm prevention, mitigation, and treatment.\n"
   },
   {  
      "link":"/research/labs/participatory-publics-lab",
      "name":"Design for Mindfulness",
      "lab":"Participatory Publics Lab",
      "description":"We are living in a multitasking society. We are experiencing an unprecedented level of sensory and cognitive overload, in which we have too many things going on at once, making us more likely to be absentminded. How to involve technology in promoting mindfulness and making it part of the process of achieving it is the question we need to answer in this project.\n"
   },
   {  
      "link":"/research/labs/everyday-computing-lab",
      "name":"Designing Adaptive Technology to Provide Personalized Support to Cancer Patients",
      "lab":"Everyday Computing Lab",
      "description":"We design, deploy, and evaluate mobile health tools that support and meet patients needs over time from diagnosis of a chronic disease, through treatment and into survivorship. Our research explores the ability for personalized, adaptable, mobile tools to support patients over the course of their individual breast cancer journeys. Our technology needs to anticipate and recognize barriers to care that occur at various points in a cancer journey, adapt with the patient as they navigate these barriers, and successfully provide patients with the tools and resources they need to manage and mitigate such barriers. The goal of our work is to improve patient health outcomes by supporting patients' outside of the clinic by helping them to learn about, engage with, and manage their disease alongside the demands of daily life.\n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"Designing the front-end of a tool that facilitates bypassing censorship on Sina Weibo",
      "lab":"Comp.Social Lab",
      "description":"Like traditional media, social media in China is subject to censorship. However, in limited cases, activists have employed homophones of censored keywords to avoid detection by keyword matching algorithms. This project focusses on designing an interactive, client-side tool that promotes free speech. An iterative design process, involving the inputs of end-users will deliver a final design. In the evaluation of the design we will target the following research questions:\nRQ 1. Does the UI workflow fit into context of use of the users?RQ 2. What the user preferences in terms of providing input and receiving output?RQ 3. Do users prefer a desktop version or mobile or both?RQ 4. Does the design feel familiar and similar to the UIs in China?RQ 5. Does the UI feel trust-able ( does the UI breed and draw trust from the users? )\nFor the info on the algorithm, see project: Algorithmically Bypassing Censorship on Sina Weibo with Nondeterministic Homophone Substitutions\n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"Designing the front-end of a tool that facilitates bypassing censorship on Sina Weibo",
      "lab":"Comp.Social Lab",
      "description":" \nLike traditional media, social media in China is subject to censorship. However, in limited cases, activists have employed homophones of censored keywords to avoid detection by keyword matching algorithms. This project focusses on designing an interactive, client-side tool that promotes free speech. An iterative design process, involving the inputs of end-users will deliver a final design. In the evaluation of the design we will target the following research questions:\nRQ 1. Does the UI workflow fit into context of use of the users?RQ 2. What the user preferences in terms of providing input and receiving output?RQ 3. Do users prefer a desktop version or mobile or both?RQ 4. Does the design feel familiar and similar to the UIs in China?RQ 5. Does the UI feel trust-able ( does the UI breed and draw trust from the users? )\nFor the info on the algorithm, see project: Algorithmically Bypassing Censorship on Sina Weibo with Nondeterministic Homophone Substitutions\n"
   },
   {  
      "link":"/research/labs/culture-and-technology-lab-cat",
      "name":"Designing Virtual Character Appearance in Informal Learning Environments for Children",
      "lab":"Culture And Technology Lab (CAT)",
      "description":"The rise of ubiquitous technology has resulted in opportunities for the design of new interactive museum exhibits that can be customized to families. Children's museums can be engaging, informal settings in which children learn fundamental science, technology, engineering, and math (STEM) concepts through hands-on experiences. In order to optimize and personalize learning experiences in such informal environments, we propose the concept of a virtual buddy that uses personal, physical, and social context knowledge regarding the child to facilitate new opportunities for STEM learning. To understand how children choose, perceive and interact with a virtual buddy and how that may impact STEM learning, we conducted participatory design activities with 18 children in a local museum. The goal of this project is to inform the design of a Virtual STEM Buddy (VSB) that could provide contextualized explanations, to seed parents contextualized explanations and to bridge the museum experience to other informal learning experiences.\n"
   },
   {  
      "link":"/research/labs/public-design-workshop",
      "name":"Designs for Foraging",
      "lab":"Public Design Workshop",
      "description":" \nDesigns for Foraging is a design project that explores the use of IoT technologies in support of urban foraging. Through this project we are developing use-cases; prototyping hardwares, software and user interfaces; and exploring the use of open technologies for image capture and analysis. The underlying motivation for this project is to use design as a means of investigating future practices and to provide the basis for near-term open innovation with IoT in support of alternative practices of agriculture.\n"
   },
   {  
      "link":"/research/labs/culture-and-technology-lab-cat",
      "name":"design[ED] Lab",
      "lab":"Culture And Technology Lab (CAT)",
      "description":"Students solved these problems in design[ED] Lab (Design Education Lab), a user experience workshop that introduced teenagers and pre-professional adults to design-thinking, to encourage problem solving and critical thinking skill development. This workshop was in partnership with The Bridge Academy (College Park, GA), a full-time High School Diploma and GED Prep program offering a nontraditional path for students. Students used a design-thinking approach to respond to problems based on the College Park Comprehensive Plan (2011   2031), by defining the problem, brainstorming solutions, thinking empathetically, iterating on the prototype, and critiquing the work. design[ED] Lab aims to expose underrepresented minorities to design-thinking as a method to solve important problems within their community. Empowered with the tools to make a difference, we hope to inspire the minds that will change the world.\ndesign[ED] Lab is a research project created and facilitated by Monet Spells, a Master's student at Georgia Institute of Technology studying Human-Computer Interaction.\n \n"
   },
   {  
      "link":"/research/labs/acme-lab",
      "name":"Digital Block and Box Test",
      "lab":"ACME Lab",
      "description":"Technology is changing the scope and quality of healthcare through applications such as telemedicine and home health technology by offering a cost-effective and accessible means to manage chronic disease. People are increasingly taking a proactive role in monitoring and maintaining their health, e.g., monitoring blood pressure to prevent stroke, or measuring blood sugar levels to regulate diabetes. One of the most pressing health issues we face today is stroke. Statistics from Centers for Disease Control and Prevention indicates that stroke is the leading cause of serious, long-term disability in the United States. While more and more stroke rehabilitation therapy are conducted in patient's home, care providers still requires patients to visit the clinic to perform the clinical assessments.\nWe investigate a computational tool   the Digital Box and Block Test (DBBT)   that can help medical professionals record and assess rehabilitation progress of stroke patients with easy setup. Embedding this technology in the residential spaces could also help patients to relearn and recall how to use their arms, hands and fingers. With the system, care providers would be able to more precisely detect, track, and monitor patient's post-stroke functional motor improvements remotely.\n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"Digital Icon-Based Asthma Action Plan",
      "lab":"Ubiquitous Computing Group",
      "description":"Currently 6.8 million children in America have asthma,&nbsp;a disease of the respiratory system that causes inflammation of the airways. An asthma action plan is an individualized health management plan that doctors give to their patients to help control their condition. It functions by illustrating what actions to take at different levels of symptom severity from day-to-day medication use to emergency situations. A problem arises for the caregivers of asthmatic children who may not have the educational background to understand the information in an action plan. These children may be in danger if their caregivers are unsure of the proper actions to take to treat their symptoms. The asthma action plan also serves as&nbsp;a partnership between the caregiver and physician. An action plan that is difficult to understand may degrade this partnership, however,&nbsp;research indicates that better communication between caregivers and physicians can lead to better medication adherence. Our solution is to develop a digital icon-based asthma action plan (I-BAAP) that can be integrated into patient&#39;s electronic medical records. The system is composed of a physician portal in which&nbsp;doctors&nbsp;input&nbsp;information relevant to a patient. The portal outputs a link to a responsive web application consisting of the I-BAAP and other features that augment communication between caregivers and physicians. The caregivers can&nbsp;access the web app on their phone, increasing possession of an action plan as compared to paper-based plans which are often lost or misplaced.\n"
   },
   {  
      "link":"/research/labs/digital-world-and-image-group",
      "name":"Digital Naturalism",
      "lab":"Digital World and Image Group",
      "description":"Digital Naturalism investigates the role that Digital Media can play for Biological Field Work. It looks to uphold the naturalistic values of wilderness exploration, while investigating the new abilities offered by digital technology. Digital Naturalism unites biologists, designers, engineers, and artists to build and analyze new devices. It focuses on crafting DIY technology and interacting with animals in new ways.In particular, Digital Naturalism looks at how digital media can be used to explore animal behaviors situated in their natural context. Most recently, this research has been carried out directly in the field in the form of Hiking Hackathons.This research originally comes from Andrew Quitmeyer\u2018s PhD research at Georgia Institute of Technology. It now forms a lifelong project and multiple cross-disciplinary collaborations all pursuing the many aspects of Digital Naturalism.\n \n"
   },
   {  
      "link":"/research/labs/social-dynamics-and-wellbeing-lab",
      "name":"Discovering Links between Reports of Celebrity Suicides and Suicidal Ideation from Social Media",
      "lab":"Social Dynamics and Wellbeing Lab",
      "description":null
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Don't Open That Door",
      "lab":"Experimental Television Lab",
      "description":"Don't Open That Door is a gesture-based interactive narrative project set in the universe of the TV show Supernatural. This project creates dramatic agency for the interactor by leveraging expec- tations of the horror genre within a seamless scenario that elicits expressive actions and provides a dramatically satisfying response.\nWe match interaction and narrative elements to support the following design goals: Story-driven Physical Reactions, Persistent and Uninterrupted Narrative, Scripting of the Interactor by Narrative.\n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"dotlink360: Visual Business Ecosystem Intelligence",
      "lab":"Computational Enterprise Science Lab",
      "description":"Business ecosystems are characterized by large, complex, and global networks of firms, often from many different market segments, all collaborating, partnering, and competing to create and deliver new products and services. Given the rapidly increasing scale, complexity, and rate of change of business ecosystems, as well as economic and competitive pressures, analysts are faced with the formidable task of quickly understanding the fundamental characteristics of these interfirm networks. Existing tools, however, are predominantly query- or list-centric with limited interactive, exploratory capabilities. We have designed and implemented dotlink360, a web-based interactive visualization system that provides capabilities to gain systemic insight into the compositional, temporal, and connective characteristics of business ecosystems. dotlink360 consists of novel, multiple connected views enabling the analyst to explore, discover, and understand interfirm networks for a focal firm, specific market segments or countries, and the entire business ecosystem.\n"
   },
   {  
      "link":"/research/labs/adam-lab",
      "name":"Drawing Apprentice: Co-Creative Drawing Partner",
      "lab":"ADAM Lab",
      "description":"Collaboration is known to push creative boundaries and help individuals sustain creative engagement, explore a more diverse conceptual space, and synthesize new ideas. While the benefits of human collaboration may seem obvious, the cognitive mechanism and processes involved in open-ended improvisational collaboration are active areas of research. Our research group has developed a co-creative drawing partner called the Drawing Apprentice to investigate creative collaboration in the domain of abstract drawing. The Drawing Apprentice draws with users in real time by analyzing their input lines and responding with lines of its own. With this prototype, we study the interaction dynamics of artistic collaboration and explore how a co-creative agent might be designed to effectively collaborate with both novices and expert artists. The prototype serves as a technical probe to investigate new human-computer interaction concepts in this new domain of human-computer collaboration, such as methods of feedback to facilitate learning and coordination (for both the user and system), turn taking patterns, and the role control and ambiguity plays in effective collaboration.\n"
   },
   {  
      "link":"/research/labs/graphics-lab",
      "name":"Dressing Humans",
      "lab":"Graphics Lab",
      "description":"We propose a general framework for character self-dressing interactions with simulated clothing. We show that by breaking the process of dressing into sub goals, we can design specific action controllers which, when combined allow a character to put on a garment via a user defined style.\n"
   },
   {  
      "link":"/research/labs/sonification-lab",
      "name":"Driving Georgia Tech: Creating a Driving  Simulation of Georgia Tech's Campus",
      "lab":"Sonification Lab",
      "description":"Applying driving simulators for in-vehicle research allows for a wide range of studies to be performed particularly when investigating cognitive demand and distraction caused by devices in the car. By using simulations, researchers can investigate driving behaviors in high-risk situations without putting participants or others in harmful way. Currently being conducted within the School of Psychology at Georgia Tech, in-vehicle research could provide more insight into behavior and increase in applicability if participants were able to drive in areas that they are familiar with. Specifically, research being done in coordination with the Atlanta Shepherd Center investigating the use of in-vehicle technologies to assist individuals who have had a Traumatic Brain Injury could benefit largely through these real location maps. The Georgia Tech School of Architecture coincidentally has already developed a 3D model of the Georgia Tech campus and some of the surrounding areas including the Peachtree corridor (26 miles along Peachtree Street). However, in order to make this model usable within the simulator, it must be optimized and converted in a compatible format. Researchers in the School of Architecture and School of Psychology will be working on creating methods and conversion processes that will allow any 3D model to be integrated into the simulator. Development of this process of conversion will allow Georgia Tech to offer documentation and map-creation services to other researchers around the world assisting in increasing the applicability of in-vehicle research.\n"
   },
   {  
      "link":"/research/labs/entertainment-intelligence-lab",
      "name":"Dynamic Difficulty Adjustment for Computer Games",
      "lab":"Entertainment Intelligence Lab",
      "description":"Part of the fun of computer games is to master the skills necessary to complete the game. Challenge tailoring is the problem of matching the difficulty of skill-based events over the course of a game to a specific player's abilities. We have devised a data-driven approach to predict changes in players' skill mastery over time. By modeling players' skill mastery, we are able to dynamically select game content that challenges individual players at the ideal level, avoiding frustration and boredom.\n"
   },
   {  
      "link":"/research/labs/adam-lab",
      "name":"EarSketch Viz",
      "lab":"ADAM Lab",
      "description":"EarSketch plus visualization and real-time interactivity.\n"
   },
   {  
      "link":"/research/labs/adam-lab",
      "name":"EarSketch: Teaching Computer Science through Music Composition",
      "lab":"ADAM Lab",
      "description":"Computational remixing of hip hop (i.e. using code to control loops and beats to compose music) can be used as a tool for the cultural engagement in computing of underrepresented populations. EarSketch is a digital audio workstation environment, with an accompanying curriculum, that will allow high school and summer workshop students to create their own computational remixes through learning computing principles.\n"
   },
   {  
      "link":"/research/labs/everyday-computing-lab",
      "name":"Eating Disorders and Social Media - Characterizing the Presentation of Eating Disorders Online",
      "lab":"Everyday Computing Lab",
      "description":"Within the computing field, little has been done to systematically analyze online eating disorder (ED) communities. This research project focuses on understanding how individuals use social media platforms to promote and share their eating disorders with their networks and with the world. We use social computing techniques to identify and anzlye content generated across several popular social media platforms. Through this characterization of eating disorder activities online, we draw attention to the increasingly important role that technologists play in understanding how the platforms and technologies that we create are used and misappropriated for negative health purposes. CAUTION: This project includes media that could potentially be a trigger to those dealing with an eating disorder or with other self-injury illnesses. \n"
   },
   {  
      "link":"/research/labs/tandem",
      "name":"Eating Right : Diets for Diabetes In India",
      "lab":"TanDEm",
      "description":null
   },
   {  
      "link":"/research/labs/interactive-media-technology-center-imtc",
      "name":"eCoach: Avatar-Guided Decision Aid for Prostate Cancer",
      "lab":"Interactive Media Technology Center (IMTC)",
      "description":"This study employs gaming technologies and techniques to create an intelligent encapsulated conversational agent (ECA) to act as a virtual coach who will lower the cognitive effort required by prostate cancer patients to understand key aspects of decision-making, provide more appropriate reference points from which patients more accurately interpret personal risk, and frame information to optimize the patient's chances of applying his own preferences and values to the decision at hand. A stylized, animated ECA will have a brief, focused conversation with a patient in order to explain, in layman's terms, the various treatment options and their risks and benefits and ask questions to assess the patient's medical literacy and values preferences, for example, the patient may value interventions with lower risk of side effects over being cancer-free.\nThe eCoach ECA is being developed with the Unity3D game engine and uses gaming AI tools such as behavior trees to model a dialog and ECA behavior. The patient will respond to each ECA question by selecting from among several predetermined answers and the history of patient answers will determine how the conversation unfolds. For example, if the ECA determines that the patient is not sure about the risks and benefits of the various treatment options, it will spend more time explaining what these are as well as ask questions to assess knowledge of them afterward.\nThis study represents a multidisciplinary collaboration between Emory University's School of Medicine, the College of Computing and the Interactive Media Technology Center (IMTC) at the Georgia Institute of Technology.\n"
   },
   {  
      "link":"/research/labs/problem-solving-and-educational-technology-pset",
      "name":"Effects of Multimedia Interactivity on Spatial Task Learning Outcomes",
      "lab":"Problem Solving and Educational Technology (PSET)",
      "description":"Prior research has produced mixed results regarding the usefulness of interactivity in multimedia learning. In this study, participants learned to solve part of a Rubik's Cube using either a tutorial with interactive features or a passive (video-based) tutorial. Participants with low spatial ability benefited more from interactivity than those with high ability, though no performance main effects were found between the tutorials. Targeted use of interactivity could be effective in engaging students and helping them learn.\n"
   },
   {  
      "link":"/research/labs/brainlab",
      "name":"Emotional Prosthetics",
      "lab":"BrainLab",
      "description":"People with severe motor disabilities such as ALS may not be able to move their facial muscles to communicate.  This study is examining the salient features of facial expressions in order to create \"emotional prosthetics\" - ways for people with disabilities to express emotion.  The resulting prosthetics will be controlled by voluntary and involuntary brain signals.\n"
   },
   {  
      "link":"/research/labs/sonification-lab",
      "name":"Enhanced In-Vehicle Technologies: Novel Interfaces and Advanced Auditory Cues to Decrease Driver Distraction",
      "lab":"Sonification Lab",
      "description":"In-vehicle technologies such as modern radios, GPS devices, eco-driving displays, and smartphones require users to interact with multiple types of visual-based menus and lists while driving. Modern technologies require users to navigate these screens using physical buttons and touch screens, although recent advances have included the use of steering wheel buttons, turn wheels, Head Up Displays (HUDs) and others. Through design and prototyping of novel menu system interfaces through innovative visual display methods, interaction techniques, and the application of advanced auditory cues to old designs and these novel interfaces, we can attempt to decrease driver distraction, therefore allowing for better driving performance, while also improving search times and decreasing cognitive load on the driver.\n"
   },
   {  
      "link":"/research/labs/gt-bionics",
      "name":"Enhancements on A Tongue-Operated Robotic Rehabilitation System",
      "lab":"GT-Bionics",
      "description":"Patients suffering from traumatic brain or spinal cord injuries may benefit from neuroplasticity guided and reinforced by motor learning feedback through reorganization of the neural pathways in intact parts of the brain and spinal cord. An enhanced version of a tongue-operated robotic rehabilitation system is presented for accelerating the rate of improvement in the upper extremity motor functions for patients with severe hemiparesis following stroke. A new rehabilitation robot, called Hand Mentor ProTM (HM) was utilized by reading its pressure and joint angle sensors and combining them with control commands from the Tongue Drive System (TDS) to enable both isometric and isotonic target-tracking tasks in a coordinated tongue-hand rehabilitation paradigm.\n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"Enterprise Genome: Visual Sequencing of Relationship Activities of Global Enterprises",
      "lab":"Computational Enterprise Science Lab",
      "description":"In an increasingly global and competitive business landscape, firms must collaborate and partner with other firms to ensure survival, growth, and innovation. Understanding the evolutionary composition of a firm's relationship portfolio and the underlying formation strategy is a difficult task given the multi\u00addimensional, temporal nature of the data. In collaboration with senior executives, we have designed and implemented an interactive visualization system that enables decision makers to gain both systemic (macro) and detailed (micro) insights into a firm's relationship activities and discover patterns of multi\u00addimensional relationship formation. Our system provides sequential/temporal representation modes, a rich set of additive cross\u00adlinked filters, the ability to stack multiple enterprise genomes, and a dynamically updated Markov model visualization to inform decision makers of past and likely future strategy moves.\n"
   },
   {  
      "link":"/research/labs/everyday-computing-lab",
      "name":"Epilepsy - Everyday epilepsy self-management tools for patients and families",
      "lab":"Everyday Computing Lab",
      "description":"Many patients and caregivers struggle to complete everyday epilepsy self-management practices: remembering to take daily medications, reporting seizure events and self-regulating behaviors such as getting enough sleep.\nJon Bidwell and Beth Mynatt are working with adolescents patients (11-18 years old), caregivers and clinicians from the Children's Healthcare of Atlanta (CHOA) to investigate how mobile and wearable health tracking technologies can support these everyday self-management needs.\nIn the coming months we will be providing patients and caregivers with a number of mobile and wearable tools that include:\na mobile phone app for reporting seizures and health information,\na smartphone for detecting medication adherence,\na wristband for measuring seizures and sleep at night and a\na wristband for measuring daily activities and stress throughout the day\nThe research will include four experimental conditions to investigate:\nThe use of mobile phones for collecting twice daily survey information and seizure reports,\nThe impact of \"smart\", context-sensitive reminders for completing daily surveys,\nThe impact of health tracking devices and health dashboards on survey response rates and\nThe impact of goal setting and daily financial rewards on survey response rates\nIf successful this work will contribute to technology design implications for greatly improving upon current epilepsy self-management tools that are available to patients and families.\n \n"
   },
   {  
      "link":"/research/labs/everyday-computing-lab",
      "name":"Epilepsy - Health dashboard for remote patient outreach",
      "lab":"Everyday Computing Lab",
      "description":"Health dashboards stand to help clinicians to identify patient challenges and contact patients between appointments. Many patients and caregivers struggle to complete epilepsy self-management practices: remembering to take daily medications, reporting seizure events and self-regulating behaviors such as getting enough sleep.\nJon Bidwell and Beth Mynatt are working with attendings at the Children's Healthcare of Atlanta (CHOA) to develop a health dashboard for clinicians. The proposed health dashboard aims to help nurse practitioners review patient and caregiver collected health data, evaluate how well patients and families are keeping up with daily self-management practices and prioritize phone call follow-ups.\nIn the coming months, patients and families will be given a range of mobile and wearable health tracking technologies. These technologies include:\na mobile phone app for reporting seizures and health information,\na smartphone for detecting medication adherence,\na wristband for measuring seizures and sleep at night and a\na wristband for measuring daily activities and stress throughout the day\nHealthcare professionals are using technologies to stay increasingly connected with patients and caregivers between appointments. This research seeks to help a small number of clinicians to reach a much larger group of patients.\n"
   },
   {  
      "link":"/research/labs/everyday-computing-lab",
      "name":"Epilepsy - Investigating neurocognitive clinician self-reporting needs",
      "lab":"Everyday Computing Lab",
      "description":"Healthcare professionals rely heavily on patients and caregivers to self-report important health information during treatment. However, in practice, these self-reports are often inaccurate, incomplete and can even be misleading. Mobile and wearable technologies stand to help patients and caregivers to collect more accurate, consistent and reliable data.\nIn this study, we investigated clinical self-reporting needs three neurocognitive fields of medicine: neurology, psychiatry and sleep medicine. In-person expert panel sessions were conducted with 14 clinicians (five epilepsy, four psychiatry, and five sleep medicine specialists) to establish the priority of different types of patient-reported data during diagnosis and treatment, respectively. Then we conducted online surveys with clinicians from the same specialty areas for further assessing the availability and quality of current patient and caregiver self-reporting data being collected.\nThe results highlight several important yet underexplored data collection and design opportunities for supporting diagnoses, treatment and self-management within these three fields as well as expose gaps between clinical data needs and patient practices. The resulting findings stand to benefit from the development of technological tools that support patient data collection activities and shared decision making between patients and providers.\n"
   },
   {  
      "link":"/research/labs/everyday-computing-lab",
      "name":"Epilepsy - Retrospective video review for more accurate wearable seizure reporting",
      "lab":"Everyday Computing Lab",
      "description":"Epilepsy treatment requires accurate seizure accounts between appointments for adjusting medications, however, this information is often either unavailable or inaccurate.\nMost patients are unable to recognize seizures at night and therefore under-report seizures [1] and by contrast\nMobile and wearable seizure detection devices often over-report seizures due to high numbers of false alarms [2].\nIn this study we're investigating patient and caregiver video review as an approach for addressing the shortcomings wearable technologies that may otherwise be applicable for long-term use in the home.\nThe study involves 16 pediatric and 16 adult patients who are being monitored at a hospital Epilepsy Monitoring Unit (EMU).\nThe patients are video recorded and wear a pair of seizure detection wristbands that detect possible seizure events.\nThe patient and caregivers then review video of these events and dismissing false alarms (e.g. video of head scratching or text messaging while in bed)   \nThe results suggest that a video review can indeed improve the performance of current the wearable seizure reporting as a \"second pass\". To date we've seen near perfect agreement between patients/caregiver and electroencephalogram technicians.\nReferences\n1. Hoppe, C., Poepel, A., and Elger, C.E. Epilepsy: accuracy of patient seizure counts. Archives of neurology 64, 11 (2007), 1595 1599.\n2. Van de Vel, Anouk, Kris Cuppens, Bert Bonroy, Milica Milosevic, Katrien Jansen, Sabine Van Huffel, Bart Vanrumste, Lieven Lagae, and Berten Ceulemans. Non-EEG Seizure-Detection Systems and Potential SUDEP Prevention: State of the Art. Seizure 22, no. 5 (June 2013): 345 55. doi:10.1016/j.seizure.2013.02.012.\n \n \n"
   },
   {  
      "link":"/research/labs/everyday-computing-lab",
      "name":"Epilepsy - Reviewing mobile apps for pediatric epilepsy self-management",
      "lab":"Everyday Computing Lab",
      "description":"Health reporting plays an essential role in the diagnosis and treatment of epilepsy. Healthcare professionals currently rely on patients and caregivers to document a range of patient seizure symptoms and health behaviors; however, studies have shown that patients and caregivers struggle with these responsibilities. Inaccurate, incomplete or inconsistent information can impact clinical decision making and increase the time required to find an effective seizure control medication.\nMobile and wearable technologies stand to help address these challenges by helping patients and caregivers with tools for collecting the types of health indicators. In this study, we surveyed clinicians and reviewed and compared the performance of existing seizure detection technologies to current patient self-reporting.\nThe results from our survey showed that\nLow-cost video could help clinicians during initial epilepsy diagnosis\nExisting seizure detection devices work best for GTCs (only 30% of seizures)\nExisting seizure detection devices are best suited for nighttime use when patients are less able to report seizures\nThese findings helped to shape our current research efforts. Bidwell and Mynatt are developing mobile and wearable tools aimed at supporting everyday data collection for patients with epilepsy. \n \nPublications\nBidwell, Jonathan, et al. \"Seizure reporting technologies for epilepsy treatment: A review of clinical information needs and supporting technologies.\" Seizure 32 (2015): 109-117.\n \n"
   },
   {  
      "link":"/research/labs/everyday-computing-lab",
      "name":"Epilepsy - Reviewing mobile apps for pediatric epilepsy self-managment",
      "lab":"Everyday Computing Lab",
      "description":"Mobile apps are available for supporting epilepsy self-management: reminding patients to take medications, reporting seizures and other health indicators and learning to self-regulate behaviors.\nThe study is in the early stages and will review mobile apps on the Android and iOS app stores to investigate\nWhat apps are available?,\nWhat aspects of self-management are addressed? and\nHow are health tracking devices utilized?\nHow are family members involved if at all?\nThe findings are expected to provide us with a starting point for developing a self-management app for pediatric patients with epilepsy this spring.\n \n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Escape Room VR",
      "lab":"Experimental Television Lab",
      "description":"Moving from 2D and digital to 3D and virtual, Escape Room VR explores the opportunities for computers to communicate with humans more effectively in the medium of virtual reality. This is a short demo that will ignite your curiosity of your surroundings and encourage the discovery of playful interactions. Real-time, 3D, and highly interactive, are you ready to escape the room?\n"
   },
   {  
      "link":"/research/labs/ms-hci-project-lab",
      "name":"Evaluating the Effectiveness of a new Lecture Aid",
      "lab":"MS-HCI Project Lab",
      "description":"This research project is a MSCHI 2nd year Masters project that attempts to design a wearable device that will reduce distraction in classrooms by making it easier for professors to deal with technology issues that may occur (e.x. The wifi cutting out) in a way that will help them maintain focus on the subject matter of the class.\n"
   },
   {  
      "link":"/research/labs/ms-hci-project-lab",
      "name":"Evidence-Based vs. Technology-Based Design",
      "lab":"MS-HCI Project Lab",
      "description":null
   },
   {  
      "link":"/research/labs/social-dynamics-and-wellbeing-lab",
      "name":"Examining behavioral markers leading to social media disclosures on schizophrenia",
      "lab":"Social Dynamics and Wellbeing Lab",
      "description":"Mental illness such as psychosis and schizophrenia are serious public health concerns. However, timely detection of an episode of psychosis is often difficult due to several reasons such as social stigma, lack of mental health awareness and literacy, and the retrospective nature of clinical therapy. We examine the potential of leveraging social media disclosures as a new kind of lens in characterizing and predicting experiences leading up to a psychotic episode. In contrast to self-report methodology, where responses typically comprise of recollection of (subjective) health facts, social media captures behavior and language in a naturalistic setting. This gives us access to real-time activity and psychological states that can be analyzed to discover and predict behavioral markers associated with a psychotic episode. With an initial dataset of 11,000 tweets which disclose symptoms of psychosis such as hearing voices, having delusions, schizophrenia etc., we develop a computational method to identify behavioral and linguistic markers that attribute to an episode of psychosis. Further, in collaboration with clinical psychologists, we examine specific user timelines that include mentions of relapse or hospitalization. Based on the data analysis, we aim at building a prediction model to identify prospective behavioral markers leading to an episode. We believe information derived from our prediction model can be valuable to clinical psychiatrists in facilitating timely diagnosis.\n"
   },
   {  
      "link":"/research/labs/human-factors-and-aging-lab",
      "name":"Exergames for Older Adults",
      "lab":"Human Factors and Aging Lab",
      "description":"Exergames -- video games played by engaging in physical activity -- could help older adults become more physically active. However, most exergames on the market are not developed with consideration of older adult users' physical and cognitive abilities. Our current study is evaluating the usability of commercially available exergames for this population by testing two exergames for Microsoft Xbox 360 with Kinect with participants aged 60 to 79. These findings will be leveraged to develop guidelines for designing a tutorial to teach older adults to use exergames.\n"
   },
   {  
      "link":"/research/labs/information-interfaces-group",
      "name":"Facebook Review",
      "lab":"Information Interfaces Group",
      "description":"We have created a visualization that presents one week of a person's Facebook messages and notifications. The focus here is to allow someone to quickly catch up with what has been going on in their feed, which messages were \"hot\", who has been active, etc.  The tool leverages a number of different visualization techniques and can benefit from a very large display.\n"
   },
   {  
      "link":"/research/labs/information-interfaces-group",
      "name":"Faceted Exploration of Large Text Document Collections",
      "lab":"Information Interfaces Group",
      "description":"Analysts routinely encounter large collections of text documents with many accompanying numeric or categorical data fields. For example, consider a collection of wine reviews where the main text part of the document is the actual review narrative, but the accompanying fields are data such as the wine's variety, color, age, rating, producer, region, reviewer, and so on. In this project, we are exploring techniques to allow analysts to investigate the document collection by \"slicing\" it along the different attributes affiliated with each document (we call them \"facets\"). These techniques should allow the analysts to look at common trends, patterns, outliers, and peculiarities of the document collection in order to gain more intelligence about and a better understanding of the collection.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Fan Funhouse",
      "lab":"Experimental Television Lab",
      "description":"Fan Funhouse is a browser-based video remixing application that allows users to edit webcam videos using a palette of effects inspired by a pop culture franchise. The increasing prevalence of user-generated media production in apps and on the web has coincided with pop culture brands, ranging from The Powerpuff Girls to Peanuts, providing fans with opportunities to quickly create and share personalized \"fan media\" in their web browsers. While most of these fan media experiences have involved the production of images or GIFs, Fan Funhouse gives users creative agency to easily remix short video clips in the style of brands they love. The test scenario for Fan Funhouse features the Adult Swim comedy duo Tim & Eric, who are known for their retro, lo-fi aesthetic. In the Tim & Eric Fan Funhouse demo, users can apply whimsical effects to make their own videos look like Tim & Eric sketches.\n"
   },
   {  
      "link":"/research/labs/animal-computer-interaction-lab",
      "name":"FIDO - Facilitating Interactions for Dogs with Occupations",
      "lab":"Animal-Computer Interaction Lab",
      "description":"The FIDO Sensors team is creating wearable technology to allow working dogs to communicate.  Assistance dogs can tell their owners with hearing impairments what sounds they have heard; guide dogs can tell their owners if there is something in their path that must be avoided.  We will be demonstrating a variety of scenarios with five wearable sensors designed for dogs to activate.\n"
   },
   {  
      "link":"/research/labs/venture-lab",
      "name":"Flow Medtech",
      "lab":"Venture Lab",
      "description":"Currently, 4.4 million Americans have been diagnosed with atrial fibrillation (AF), in which the heart beats in an irregular rhythmic pattern. That number is estimated to reach 12-16 million by the year 2050. Patients with atrial fibrillation have over a fivefold increase in the chance of stroke.  Due to complications from the current standard of care, anticoagulants (i.e. blood thinning drugs), to treat resulting thromboembolism (i.e. clotting) from AF, alternative treatments are actively being sought out to decrease complications and risk of stroke. With 90% of clots found in the brain originating from the left atrial appendage (LAA), a fingerlike projection off the heart that rarely contracts in AF patients, LAA closure devices have become an increasingly attractive option, but current options undergoing FDA approval are considered by cardiologists to be first generation devices that need to be improved upon due to limited functionality. Flow Medtech is currently developing occlusal technology that fully blocks the LAA from thromboembolism, features customizability to conform to the unique shapes and sizes of individual LAAs, and uses a secure anchoring system to prevent migration. These features will prohibit thromboembolism in the LAA, and thus, will significantly reduce the risk of stroke in AF patients.\n"
   },
   {  
      "link":"/research/labs/interactive-media-technology-center-imtc",
      "name":"Food For Thought: Developing a Cognitive Training Game for Older Adults",
      "lab":"Interactive Media Technology Center (IMTC)",
      "description":"Over the past 2 years, we have performed experiments to understand what activities within a video game context result in cognitive gains (and which do not). From these findings, we have developed a custom cognitive game called \"Food for Thought.\" \nThe specific goals of this research program are to: understand how video games can contribute to improvements in cognition, what properties of the gaming environment (novelty, active attention, and/or social interaction) are critical for cognitive improvement, create an older adult specific game that leverages the critical properties identified empirically, and test the efficacy of this theoretically designed game to produce the largest gains in the cognitive performance of older adults.\n"
   },
   {  
      "link":"/research/labs/graphics-lab",
      "name":"From Animated Character to Real Robots",
      "lab":"Graphics Lab",
      "description":null
   },
   {  
      "link":"/research/labs/problem-solving-and-educational-technology-pset",
      "name":"Function of Educational Technology",
      "lab":"Problem Solving and Educational Technology (PSET)",
      "description":"Much of the research on educational technology (e.g., MOOCs and adaptive learning systems) has been driven by the capabilities of technology instead of the pedagogy and cognition of learners. Our research takes the opposite approach. A review of the literature on educational technology and instructional methods for teaching STEM courses was used to identify the strengths of technology in education. These findings being used to develop educational technology and provide heuristics and guidelines for developing effective STEM courses that optimally support learning.\n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"G.L.I.M. - Glass Live Interaction Monitor",
      "lab":"Ubiquitous Computing Group",
      "description":"Successful social interactions are essential to enhance our quality of life. Being aware of our own internal emotional state as we interact with other individuals maximizes our chances of effectively co-regulating with them, and therefore enhancing the quality of our interactions. The challenge we face regarding self-regulation lies in the fact that in today's busy world often times we become so overwhelmed that we lose the ability to read our own internal emotional states hindering our ability of self   regulate potentially hurting the quality of our interactions. \nGiven that strong evidence indicates that in successful social interactions, synchrony occurs at the physiological level between individuals as they interact, we are introducing G.L.I.M. (Glass Live Interaction Monitor), a system that helps the user self-regulate in situ by leveraging the combination of 3 comfortable, wireless, non-obtrusive and wearable devices.\nG.L.I.M. components are:  a) Google Glass, b) Electrodermal Activity (EDA) / Galvanic Skin Response (GSR) , c) Heart Rate Monitor, and d)  Laptop application for offline analysis and self-reflection. \nCase Study: Given that interacting with Children with Autism (CWA) can probe to be challenging, and that their primary bridges to the world are their parents and therapists, it is essential for them to be adequately self-regulated in order to maximize the quality of their social interactions. G.L.I.M. offers the possibility of optimizing parental and therapist internal self-awareness while interacting in their natural environment. In a second stage we are also planning to instrument the CWA so we can monitor both the caregiver and CWA internal states in situ, providing a even deeper insight on how the interaction flows. Gaining knowledge of both interacting partners invisible physiological signal can probe to be essential in providing strategies oriented to maximize the quality of their relationship.\n"
   },
   {  
      "link":"/research/labs/entertainment-intelligence-lab",
      "name":"Game Based CAPTCHA",
      "lab":"Entertainment Intelligence Lab",
      "description":"A CAPTCHA is a challenge-response test used on the Internet to prevent bots from accessing web services that are designed for humans. We are investigating Automatic Game based CAPTCHA Generation (AGCG), in which an AI system generates games that, when played, distinguish between humans and bots. The game based CAPTCHA takes advantage of not only the bots' difficulty performing pattern/object recognition, but also their lack of commonsense knowledge. Thus it is more secure but remains easy and fun for humans, compared to traditional visual based CAPTCHAs. Furthermore, our AGCG system is capable of learning new commonsense knowledge based on users' response in the game based CAPTCHAs.\n"
   },
   {  
      "link":"/research/labs/entertainment-intelligence-lab",
      "name":"Game Mechanics for Games With a Purpose",
      "lab":"Entertainment Intelligence Lab",
      "description":"Games with a purpose (GWAPs) have proven to be effective solutions to solving difficult problems, labeling data, and collecting commonsense knowledge. Unlike traditional games, GWAPs must balance between acquiring accurate solutions or data and maintaining player engagement. However, when it comes to designing GWAPs, the effects of different game mechanics on accuracy and engagement are not well understood. We have conducted two studies to understand the way different choices of game mechanics and their affect on player behavior. The first study (Cabbage Quest) compares cooperative and collaborative game mechanics. The second study (Gwappy Bird) compares different difficulty levels.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Game of Game of Thrones",
      "lab":"Experimental Television Lab",
      "description":"The complexity of television shows has been increasing.  In order to follow a story, viewers might be expected to stay abreast of more plot threads, remember more characters, and retain information introduced in earlier seasons.  Media technology has made the job easier by allowing viewers to review in various ways; they may replay a scene or entire episodes, they may visit an online forum for fans, or they may play a video game that is related to that story.\nGame of Game of Thrones is a video game design intended to explore how a video game could enhance the viewing of a television series.  Specifically, what could be accomplished by an episodic game whose episodes are interleaved with series episodes?  Our design was guided by two goals: 1) help viewers cope with increasing information requirements and 2) offer an additional dramatic layer to the series, one that could be harmlessly eschewed by viewers who don't care to play a game.  \n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Game of Thrones Companion",
      "lab":"Experimental Television Lab",
      "description":"The transition from novel to television creates the issue of compressing story into episodes limited by time and budgets. HBO&rsquo;s translation of Game of Thrones is a rich tapestry of characters and narratives; however, the viewer can lack back story, geographic awareness, and an understanding of character relationships. This second-screen companion app orients viewers to the world of Westeros by mapping families throughout episodes. Greater character understanding is achieved by the mapping of character relationships, both during characters present in each scene or within the episode.\n"
   },
   {  
      "link":"/research/labs/interactive-media-technology-center-imtc",
      "name":"Games for Assessment",
      "lab":"Interactive Media Technology Center (IMTC)",
      "description":"We have a multi-year project exploring how game performance and player behavior can be used to perform scientifically valid cognitive, personality, skill, and behavioral measures. This project involves hypothesizing about how game mechanics, levels, situations etc. could assess aspects of player that are currently measured via validated traditional tests/activities/interviews, designing games around these hypotheses, and running user studies. Another aspect of this work is exploring how theming, feedback, game type influence the assessment validity and the players' desire to play the game.\n"
   },
   {  
      "link":"/research/labs/interactive-products-design-lab",
      "name":"Garment Based Body-Position Monitoring ",
      "lab":"Interactive Products Design Lab",
      "description":"Georgia Tech and the Human Interface Branch of NASA partnered together to find a way to detect astronauts' body positions in space. In the zero gravity space environment it becomes difficult to monitor tasks that lead to repetitive stress injuries or fatigue. Monitoring movement would help NASA pinpoint high stress actions and make adjustments to corresponding mission tasks.We developed an unobtrusive, textile based system to monitor astronauts' arm position in real time, in zero gravity, and without the constraints of camera based motion-input devices.\n"
   },
   {  
      "link":"/research/labs/ms-hci-project-lab",
      "name":"Georgia Brew Finder",
      "lab":"MS-HCI Project Lab",
      "description":"A textual visualization that analyzes and presents beer review data to allow users to find beer that meets their tastes.\n"
   },
   {  
      "link":"/research/labs/mobile-robot-laboratory",
      "name":"Getting it Right the First Time - Performance Guarantees for Robot Behavior",
      "lab":"Mobile Robot Laboratory",
      "description":"Robotics has been considered as one of the five key technology areas for defense against attacks with weapons of mass destruction (WMD). However, due to the mass impact nature of WMD, failures of counter-WMD (C-WMD) missions can have catastrophic consequences. To ensure robots' success in carrying out C-WMD missions, we have developed a novel verification framework in providing performance guarantees for behavior-based and probabilistic robot algorithms in complex real-world environments. We cannot assume the luxury of a do-over; we must get it right the first time.\n"
   },
   {  
      "link":"/research/labs/public-design-workshop",
      "name":"Gleaning in Atlanta",
      "lab":"Public Design Workshop",
      "description":"Gleaning is the practice of salvaging food left over from its intended use. Our research delved into the activities of gleaning with an emphasis on the tools used in gleaning. From this research we identified a series of design opportunities. Perhaps the most fertile opportunities are related to socio-technical networking: the processes and infrastructures for providing information about the availability of food for gleaning and access to the actors who can move and store gleaned food. \n"
   },
   {  
      "link":"/research/labs/information-interfaces-group",
      "name":"GLO-STIX",
      "lab":"Information Interfaces Group",
      "description":"Graph-Level Operations (GLOs) are a holistic vocabulary of encapsulated manipulations of graph visualization elements. GLOs allow analysts to explore their network data in new and interesting ways, freeing them from being restricted to predefined graph visualization techniques. GLOs also provide software engineers with an alternative, extensible means of writing extensible graph visualization applications. Finally, GLOs provide an elegant method for generating animated transitions between graph visualization techniques. GLO-STIX is a user-centered application for exploring a network using GLOs.\n"
   },
   {  
      "link":"/research/labs/interactive-products-design-lab",
      "name":"GloHood: An interactive toolkit for dance",
      "lab":"Interactive Products Design Lab",
      "description":"The gloHood is a wearable technology garment that amplifies and augments the expressive movement of a dancer. It provides the novice audience with an available affordance to better appreciate and understand modern dance, and the dancers new tools to better communicate with the audience, with each other, and with themselves. The garment provides the dancer with a gesture control interface through embedded RFID tags, and a motion control interface through accelerometers sewn into the garment.Each of these can trigger playback of animated light patterns on an array for LEDs arranged over the neck and shoulders. This allows the dancer control over the garment while in use, and the ability to enhance his movement.This garment was designed and tested in collaboration with local dance troupe gloATL.\n"
   },
   {  
      "link":"/research/labs/interactive-products-design-lab",
      "name":"GloSkirt: An interactive garment for dance performance ",
      "lab":"Interactive Products Design Lab",
      "description":"The gloSkirt is a wearable technology garment design for Mary Jane Pennington of dance troupe gloATL. The team wanted to give her an experimental tool to challenger her own movement style and better engage audiences new to dance. A base layer of LEDs responds to resistive sensors embedded within layer of the skirt, causing the garment to \u2018pulse' and \u2018breathe' as the dancer crushes and separates with her movements.\n"
   },
   {  
      "link":"/research/labs/tandem",
      "name":"Goodbye Text, Hello Emoji",
      "lab":"TanDEm",
      "description":"This project is a qualitative study of non-textual mobile communication practices in Southern China. Examining the rapid proliferation of emoji in WeChat use, we attend to the lessening dependence on text. We use interview and observation data from 30 participants to investigate how rural, small town, and urban Chinese adults creatively and innovatively balance the use of emoji and text in their communication, as we envision the evolution of emoji into a modality of its own. We look into various possibilities for future work to explore circumventing the prerequisite of print literacy for mobile communication, especially for low-literate populations.\n"
   },
   {  
      "link":"/research/labs/ms-hci-project-lab",
      "name":"Grocery Pool - A ride sharing system to help students in food deserts get better access to food",
      "lab":"MS-HCI Project Lab",
      "description":"Despite growing awareness of the term food desert millions of people still have poor access to healthy food. The focus of the research is to help students living in food deserts get better access to grocery stores. Grocery Pool is a mobile application that students can use to collaborate and plan trips to grocery stores. \n"
   },
   {  
      "link":"/research/labs/research-network-operations-center-rnoc",
      "name":"GT Art Crawl ",
      "lab":"Research Network Operations Center (RNOC)",
      "description":"The annual Clough Commons Art Crawl serves as a unique opportunity for Georgia Tech students to close their books, catch their breath, and enjoy the therapeutic effects of art. The blank walls of the Clough Commons will once again be transformed into a make-shift gallery, all centered around the artistic work of Georgia Tech students.\nThe RNOC has built the companion app for the Art Crawl utilizing Augmented Reality technologies and the RNOC's Dev Hub platform\n"
   },
   {  
      "link":"/research/labs/research-network-operations-center-rnoc",
      "name":"GT Journey",
      "lab":"Research Network Operations Center (RNOC)",
      "description":"GTJourney is an opportunity for all members of the Georgia Tech community to collaborate on applications and solutions that benefit the campus. It is a virtual focal point for students, faculty, and staff to develop ideas and solutions, find technical support and resources, advertise and access campus data, and share applications and experiences.\n"
   },
   {  
      "link":"/research/labs/research-network-operations-center-rnoc",
      "name":"GTMobile",
      "lab":"Research Network Operations Center (RNOC)",
      "description":"GTMobile is a web portal, built and maintained by the GT-RNOC, for the\ndeployment of web applications. GTMobile is meant to be a resource that\nbenefits the Georgia Tech community by providing a place where any\nstudent, staff, alumni & faculty can host their application or service.\nGTMobile features capabilities such as integration with Campus\nauthentication and authorization to ensure applications and services can\nbe differentiated and offered to the active GT community or the public.\nGTMobile is also the showcase for the winning entries of Georgia Tech's\nFall Convergence Innovation Competition (cic.gatech.edu).\nGTMobile is open to the entire GT community and all are encouraged to host\ntheir applications on this portal and ensure that GTMobile is the\ncontinued singular web point of presence for GT based services.\n"
   },
   {  
      "link":"/research/labs/research-network-operations-center-rnoc",
      "name":"GTMobile on Glass",
      "lab":"Research Network Operations Center (RNOC)",
      "description":"This glassware is designed for the Georgia Tech campus community and visitors. It uses your location information to help you know what buildings are nearby as well as find the nearest bus stop. This demos how easy it is to leverage our existing APIs and resources in order to support new platforms and development.\n"
   },
   {  
      "link":"/research/labs/gvu-prototyping-lab",
      "name":"GVU Prototyping Lab",
      "lab":"GVU Prototyping Lab",
      "description":"Come see the tools that we use to create one-of-a-kind research prototypes. We have everything from laser cutters and 3D printers to table saws and soldering irons, and we use them to create many of the custom electronics, cases, and wearable prototypes you see in our demos.\nThe Prototyping Lab is located in the basement of the building, so just look for signs by the elevators to go down there, or meet by the elevators on the 2nd floor every quarter hour on the quarter hour to get a tour.\n"
   },
   {  
      "link":"/research/labs/interactive-products-design-lab",
      "name":"Haptic Mirror Therapy Gloves: Aiding the treatment of a paretic lib after a stroke ",
      "lab":"Interactive Products Design Lab",
      "description":"Haptic Mirror Therapy Glove is an interactive mirror therapy glove for the treatment of a paretic limb following a stroke.  It allows the user to stimulate the fingertips of their effected hand by tapping the fingers of their unaffected hand using force sensing resistors to trigger linear resonance actuators on the corresponding fingers.  The glove may potentially be useful to stroke survivors and their therapists by encouraging the development of new multi-sensory rehabilitation exercises, which might better help recover lost sensation and strength in their fingers.This project was selected as the Best Functional Design at the 2013 International Symposium on Wearable Computing in Zurich, Switzerland.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Harry PottAR",
      "lab":"Experimental Television Lab",
      "description":"An augmented reality mobile application that brings the wizarding world of Harry Potter to the real world for the purpose of answering the following research question: How do the following factors - timers, audio, interacting with virtual objects in the real world, interacting with real objects in the virtual world - increase or decrease a user's motivation to follow an interactive location-based narrative? This project will inform a set of design guidelines for motivating users to follow an interactive location-based narrative.\n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"Hashtag Adoption in the Pro-Eating Disorder Community on Instagram",
      "lab":"Comp.Social Lab",
      "description":"It is true that social networking has been a powerful force for good; however, these sites have also enabled sharing and connectivity for more nefarious purposes. Specifically, the Internet connects people in ways that can enable and amplify the destructive power of eating disorders (EDs). Some pro-ED communities have emerged that support users' choices of self harm as a reasonable lifestyle alternative. These communities are not only dangerous for those with EDs but also for potential contagious effects of these communities on those who don't already have these behaviors. Instagram, the photo and video sharing site, has taken proactive steps to block hashtags associated with eating disorders, yet the pro-ED community works around these bans by create new hashtags with lexical permutations to congrea\nMy research examines the formation of the pro-ED community on Instagram around these hashtags and the life cycles for these hashtags. I hope to examine questions such as: what categories of lexical permutations are created for banned hashtags? What characteristics of a hashtag make it \"stick\" and used around the network? Can we predict what lexical characteristics make a hashtag better or worse at avoiding detection and connecting the pro-ED community together?\n \n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Heads-Up",
      "lab":"Experimental Television Lab",
      "description":"Heads-Up is a Google Glass prototype that functions as a translucent second screen over the television while re-watching a favorite show. Our demo will focus on HBO's highly acclaimed series, Game of Thrones. The intention of the design is to allow the user to continue viewing the TV screen while receiving synchronized commentary through Google Glass rather than be distracted away from the screen by a computer, phone, or tablet. \n"
   },
   {  
      "link":"/research/labs/tandem",
      "name":"Healthcare Access in Marginalized Communities",
      "lab":"TanDEm",
      "description":"Despite repeated efforts by governments, historically, marginalized communities around the world have had limited access to quality healthcare due to the interplay of complex socioeconomic, political, and cultural factors. Our group studies the nature and extent of this \u2018limited access' to healthcare, to construct a nuanced understanding of this phenomenon. Our goal is to extend lessons from our research work to inform the design of not just healthcare interventions, but interventions in the larger field of information and communication technologies for development (ICTD).\n"
   },
   {  
      "link":"/research/labs/interactive-media-technology-center-imtc",
      "name":"HealthSmart: A Mobile Personal Health Record for Behavioral Health Homes",
      "lab":"Interactive Media Technology Center (IMTC)",
      "description":"Poor quality of medical care is a major contributor to excess medical morbidity and premature mortality in persons with serious mental illnesses (SMI). To address this problem, community mental health providers are increasingly partnering with safety net medical providers to develop behavioral health homes, integrated clinics in which persons with SMI receive coordinated medical and mental health care. However, behavioral health homes have faced logistical and privacy challenges in integrating electronic medical records across organizations.\nThis application proposes to develop and test a mobile Personal Health Record (mPHR) to overcome this problem while more fully engaging patients in their health care. The mPHR will have the capability to access medical and mental health medication and lab data in real time; to help clients set and maintain health and lifestyle goals; to provide medication and appointment prompts and reminders; and to facilitate communication with providers via asynchronous communication with the EHRs.\nThis project is a collaboration with Emory University's Center for Behavioral Health Policy Studies.\n"
   },
   {  
      "link":"/research/labs/emergent-game-group",
      "name":"How Cultural Background Influences Western and Eastern MMOG Players in World of Warcraft",
      "lab":"Emergent Game Group",
      "description":"The purpose of this study is to investigate how cultural background influences Western and Eastern MMOG players in the case of WOW.\nThis thesis explores the influence of culture on MMOG players in three different cultural contexts: United States (US) servers, Chinese (CN) servers, and Taiwanese (TW) servers. This comparison will allow a comparison of Western vs. Eastern players as well as two similar Eastern cultures that play slightly different versions of the game. This comparison will also show a distinction among the similarities and differences of culturally-influenced behaviors as well as behaviors that arise out of specific game features. This paper will specifically focus on identifying the differences among these three cultures and the unique aspects of players of different cultural backgrounds that alter the atmosphere of the game. In addition, this study will also examine how Chinese WOW players who have virtually immigrated from Chinese servers to Taiwanese servers have influenced the local game culture on Taiwanese servers. This study will cover the following research questions:\nDoes real world culture influence the form of the virtual world culture?\nSub-questions of this main question are as follows:\nWhat aspects of their cultures do players bring from their own lives and how do they incorporate them into their game behavior?\nDoes the behavior of players in different cultures reveal different values and attitudes in the game?\nWhen players immigrate to other servers, what are some habits and behaviors from their original servers do they bring to the new homeland servers?\n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"Human body mediated sensing",
      "lab":"Ubiquitous Computing Group",
      "description":"We explore how to use human body as a sensing medium and what novel applications can be developed. \n"
   },
   {  
      "link":"/research/labs/visual-analytics-lab",
      "name":"IAL - Interactive Analytics Library",
      "lab":"Visual Analytics Lab",
      "description":"User interaction is central to the data analysis process fostered by interactive visual analytic interfaces. However, in many current systems, user interaction is represented as an ephemeral action taken by a user that moves the system from one state to another. User interactions are quantitative bits of the analytic dialog between people, the system, and the data - and when modeled - can be tactfully integrated into visual analytic systems. We propose a library to help researchers and developers capture, interpret, and model interactions in web-based visual analytic tools. We introduce Interactive Analytics Library, a JavaScript library which enables developers create data models of a user's interest based on their interactions with the system. By encapsulating interaction as an attribute of the data, managing weight vectors, and providing analytical models pre-tuned to generate results tailored to user interest, Interactive Analytics Library offloads responsibilities from developers of visual analytics so that they can focus more on the data representation and other front end system components.\n"
   },
   {  
      "link":"/research/labs/tandem",
      "name":"ICTs for HIV outreach work in India ",
      "lab":"TanDEm",
      "description":null
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"Identifying Human Trafficking Online",
      "lab":"Comp.Social Lab",
      "description":"We are looking at identifying instances of Human Trafficking on online marketplaces and review sites. Using textual and visual cues, we are training a classifier to predict likelihood of being trafficked. \n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"In-context Motion Gesture Design",
      "lab":"Ubiquitous Computing Group",
      "description":"Motion gestures can be expressive, fast to access and perform, and facilitated by ubiquitous inertial sensors. However, implementing a gesture recognizer requires substantial programming and pattern recognition expertise. Although several graphical desktop-based tools lower the threshold of development, they do not support ad-hoc development in naturalistic settings. We present a mobile tool for in-context motion gesture design. Our tool allows interaction designers to create and test motion gestures using inertial sensors in commodity and custom devices. Therefore, our tool encourages development of gestures with common as well as atypical body parts. Moreover, the data collection, design, and evaluation of envisioned gestural interactions can now occur within the context of its use. \n"
   },
   {  
      "link":"/research/labs/sonification-lab",
      "name":"In-Vehicle Assistive Technologies",
      "lab":"Sonification Lab",
      "description":"There are many populations who need assistive technologies while driving such as the millions of Americans suffer traumatic brain injuries each year, and the majority of them return to driving at some point following their recovery. However, the residual effects of TBIs can affect perception, cognition, emotion, and motor abilities. In collaboration with the Shepherd Center we are developing software that can help improve the attention and abilities of drivers post-TBI. The system could help all kinds of drivers who may have attention lapses, cognitive processing issues, or other issues that impact driving. Similar types of applications could be built for many other types of issues as well (e.g., novice drivers, aging adults, & quote stressed out drivers).\n"
   },
   {  
      "link":"/research/labs/emergent-game-group",
      "name":"Incubator",
      "lab":"Emergent Game Group",
      "description":"The {egg} Incubator group focuses on research, analysis, and rapid prototyping of emergent gameplay. Several, exhiting prototypes were build to test the theories of emergent gameplay.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Infinite Programming Guide",
      "lab":"Experimental Television Lab",
      "description":null
   },
   {  
      "link":"/research/labs/culture-and-technology-lab-cat",
      "name":"Information Seeking Practices of Parents: Exploring Social Networks, Fears and Challenges",
      "lab":"Culture And Technology Lab (CAT)",
      "description":"Through findings from over 60 interviews and a national online survey with 978 with diverse groups of parents, we explored parents' ability to find learning opportunities, we identify differences in parents' use of online social networks in finding learning opportunities for their children across different socioeconomics.\n"
   },
   {  
      "link":"/research/labs/information-interfaces-group",
      "name":"Information Visualization on Tablets and Mobile Platforms",
      "lab":"Information Interfaces Group",
      "description":"Visualization has an important role in science and technology. People rely on visualizations to better understand problems they have to solve. Information visualization has recently increased its domain, from being used for representations of business data, to more political and social uses via groups like visualizing.org and infosthetics.com. In parallel with this growth we have seen the widespread acceptance of mobile technology by masses. Mobile phones, today, are being used for everything from email to ticketing and web browsing to watching videos. As society becomes more mobile, it is important to consider the application of information visualization on mobile and other touch based devices. The aim of this project is to understand if and how traditional information visualization techniques like line charts, bar graphs, and treemaps can be useful in a mobile environment and what the best style of interaction with those charts should be.\n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"Input for Virtual Reality Environments",
      "lab":"Ubiquitous Computing Group",
      "description":"A series of demonstrations of novel interactions with virtual reality systems.\n"
   },
   {  
      "link":"/research/labs/social-dynamics-and-wellbeing-lab",
      "name":"Insights into Psychological Wellbeing and Urban Crime Via Social Media",
      "lab":"Social Dynamics and Wellbeing Lab",
      "description":"This ongoing study investigates the effect that proximate criminal activity has on emotional expression in social media. Proximity to crime and well constant fear of crime can have great negative psychological effects on individuals. Social media currently being one of the most popular means of publicly expressing personal opinions and emotions, we expect to find an effect of temporal and spatial proximity to crime on social media mood expression and other patters of online communication. Moreover, we expect that the use of certain terms related to crime will have different emotional connotations that correlate with the baseline criminal level of activity in the area.\n"
   },
   {  
      "link":"/research/labs/social-dynamics-and-wellbeing-lab",
      "name":"Instagram Content Moderation in Pro-Eating Disorder Communities",
      "lab":"Social Dynamics and Wellbeing Lab",
      "description":"The existence of pro-eating disorder (pro-ED) communities has challenged many social media platforms, such as Instagram. These communities promote the adoption and progression of eating disorders, which are known to have negative impacts on health. Instagram has reacted by banning searches on several pro-ED tags as well as issuing content advisories on others. In response, the pro-ED community has adopted non-standard lexical variations of these moderated tags to circumvent restrictions. This research investigates the impacts of Instagram banning tags on the community. Our work analyzes how the pro-ED community changes what tags it uses to avoid detection, what topics are discussed before and after banning, and what intervention and design strategies can be taken to assist these populations.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"InSync - Companion App for Live Sports",
      "lab":"Experimental Television Lab",
      "description":"Exploring experiences for a real-time companion device application to enhance live sports-watching experiences. The application facilitates for active social engagement typically of sports and assists in understanding the dynamics of the match more efficiently.\n"
   },
   {  
      "link":"/research/labs/design-intelligence-laboratory",
      "name":"Intelligent agents, visual perception and cognition",
      "lab":"Design & Intelligence Laboratory",
      "description":null
   },
   {  
      "link":"/research/labs/design-intelligence-laboratory",
      "name":"Intelligent Biologically Inspired Design",
      "lab":"Design & Intelligence Laboratory",
      "description":null
   },
   {  
      "link":"/research/labs/augmented-environments-lab",
      "name":"Interaction Techniques for Children's AR Education",
      "lab":"Augmented Environments Lab",
      "description":"Augmented-reality is a technology that can revolutionize children's education and entertainment. In studies of adolescents and adults, it has been shown to have measurable benefits for advancing STEM education through situated 3D simulations, providing entertainment through whole-body interaction, and enhancing physical & cognitive rehabilitation through motivational engagement. \nWe are interested in bringing such experiences into the hands of elementary-school children. In this project we are studying young children's ability to effectively use various types of handheld-AR interfaces. Handheld-AR interfaces are different from more traditional interfaces, by being small portable windows into physical spaces augmented with digital content, and their use may require more complex motor and cognitive skills than compared to traditional interfaces. Due to the novelty of handheld-AR technology, there are no standard interaction techniques for handheld AR, and little is known about children's ability to use these interfaces. \nThrough this research we are generating guidelines for technology designers, answering questions such as: What kinds of handheld-AR interaction techniques are suitable for young children? To what degree does age influence children's ability to interact with handheld-AR interfaces? What are best practices for designing handheld-AR interfaces for children ?\n"
   },
   {  
      "link":"/research/labs/problem-solving-and-educational-technology-pset",
      "name":"Interesting Details in Science Videos: Seductive Detail or Learning Aid?",
      "lab":"Problem Solving and Educational Technology (PSET)",
      "description":"Scientists disagree about the effect of  adding emotionally interesting details to learning materials. While some argue that interesting information enhances learning, others contend that interesting information is distracting. However, the issue might not be the interestingness of the information, but rather the relevance of the details to the main idea.\n"
   },
   {  
      "link":"/research/labs/venture-lab",
      "name":"Intuitive Pickups",
      "lab":"Venture Lab",
      "description":"We will demonstrate our acoustic guitar pickup system. Our demo will consist live acoustic guitar playing with comparisons of our technology to existing technology.\n"
   },
   {  
      "link":"/research/labs/everyday-computing-lab",
      "name":"Investigating the abandonment of health tracking technologies ",
      "lab":"Everyday Computing Lab",
      "description":"Personal health-tracking technologies have become a part of mainstream culture. Their growing popularity and widespread adoption present an opportunity for the design of new interventions to improve wellness and health. However, there is an increasing concern that these technologies are failing to inspire long-term adoption. In order to understand why users abandon personal health-tracking technologies, we analyzed advertisements of secondary sales of such technologies on Craigslist. We conducted iterative inductive and deductive analyses of approximately 1600 advertisements of personal health-tracking technologies posted over the course of one month across the US. We identify health motivations and rationales for abandonment and present a set of design implications. We call for improved theories that help translate between existing theories designed to explain psychological effects of health behavior change and the technologies that help people make those changes.\n"
   },
   {  
      "link":"/research/labs/interactive-products-design-lab",
      "name":"Jeli: The interactive, wearable pet",
      "lab":"Interactive Products Design Lab",
      "description":"Jeli is a wearable pet with personality. Just pin him to your shirt or jacket and take him along wherever you go! Jeli is the perfect travelling buddy for those who want a little company during their busy day.Pet Jeli on the head, squeeze his head, or scare him with a loud noise to make him come to life.\nJeli served as an exploration in soft circuit design. The product is controlled by a Flora microcontroller, as it is well-suited to sewn circuitry and wearable products. Our system also incorporates homemade sensors, such as a potentiometer and a force sensor. We built these sensors from copper tape, felted conductive fibers, and velostat, and connected them all with conductive thread. In addtion to these soft sensors, Jeli also uses a microphone, neopixels, and a piezo buzzer to give him life and personality during interactions.\n"
   },
   {  
      "link":"/research/labs/information-interfaces-group",
      "name":"Jigsaw: Visual Analytics for Text Document Collections",
      "lab":"Information Interfaces Group",
      "description":"Many types of investigators routinely perform analysis that involves large collections of documents. The Jigsaw system helps investigative analysts with reasoning and sense-making in such scenarios. Jigsaw acts like a visual index\nonto a document collection. It first analyzes the documents, identifies\nentities, clusters related documents, analyzes sentiment, and summarizes each document. Next, it provides multiple visualizations of the documents, entities within, and the analysis results.  We have used Jigsaw to explore a wide variety of domains and document collections including academic papers, grants, product reviews, business press releases, news articles, intelligence and police reports, statutes, and even books such as the Bible.\n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"Knowledge Ecosystem Reaction to Platform Change",
      "lab":"Computational Enterprise Science Lab",
      "description":"Given the importance of developers for the success of mobile platforms, it is critical for vendors to understand how platform innovations impact developer interaction activity and what issues and topics are discussed.  An understanding of these issues can help providers improve their release strategies, manage developer expectations, and avoid negative reputation effects.  To facilitate this understanding, we are analyzing knowledge ecosystem reactions to change in mobile software development platforms.  As part of this work, we have developed a method for gathering information about change events from two sources: endogenous information derived from traces of user interactions within knowledge ecosystems, and exogenous information harvested from official documentation, press releases, and news reports.  The method is being applied to data describing interactions on Stack Overflow, the world's most popular social information seeking community for developers.  By demonstrating how such data can be processed to highlight periods of rapid change, and how this evidence can be combined with external indicators of change events, we are contributing a new technique to supplement approaches based on direct consultation of system participants.\n"
   },
   {  
      "link":"/research/labs/tandem",
      "name":"Learning about Teaching in Low-Resource Environments",
      "lab":"TanDEm",
      "description":"While there is a growing focus on leveraging technology use for learning gains across the world, this focus is yet to extend to infrastructurally limited environments in India, among other countries. We draw on qualitative research conducted in the Indian states of Tamil Nadu, Maharashtra, and West Bengal to highlight the challenges of designing educational technologies for \"low-resource'' contexts, particularly when they are \"low-resource'' along different dimensions. We also present findings from a survey of online educational technology providers in India to highlight the gaps that must be addressed before these can target socioeconomically disadvantaged populations. Taken together, our research provides a deeper understanding of the nuances that accompany \"low-resource'' and how a careful assessment of these might inform appropriate design of educational technology interventions in the field of HCI for Development (HCI4D).\n"
   },
   {  
      "link":"/research/labs/graphics-lab",
      "name":"Learning Bicycle Stunts",
      "lab":"Graphics Lab",
      "description":"We present a general approach to simulate and control a human character riding a bicycle. The rider not only learns to steer and to balance in normal riding situations, but also learns to perform a wide variety of stunts, including wheelie, endo, bunny hop, front wheel pivot and back hop.\n"
   },
   {  
      "link":"/research/labs/entertainment-intelligence-lab",
      "name":"Learning Robot Behavior from Stories",
      "lab":"Entertainment Intelligence Lab",
      "description":"The Quixote system is an artificial intelligence technique for teaching robots and artificial virtual agents how to do things by telling them stories. Stories present a natural means of communicating complicated, tacit procedural knowledge. Quixote thus reads in natural language stories and learns to emulate the behaviors of the characters in the stories. The long term goal of the project is to make AI programming accessible to non-programmers and non-AI experts. \nWe have also shown that stories can be an effective means of demonstrating ethical behavior to robots and AIs.\n"
   },
   {  
      "link":"/research/labs/everyday-computing-lab",
      "name":"Living Online - The Curious Lives of Digitally Connected Teens",
      "lab":"Everyday Computing Lab",
      "description":"This project discuses the findings from a 4-year study of 10-15 year old students from a large Metro-Atlanta school district. Over the course of the project 164 students took surveys and participated in focus groups and interviews regarding the amount of connectivity they experience, where they are going online, and what behavioral issues that are pervasive for this demographic as it relates to their online peer interactions. This work demonstrates how social computing influences communication patterns within this population as well as how social computing influences the everyday behavioral and emotional health and wellness of digitally connected teens.\n"
   },
   {  
      "link":"/research/labs/adam-lab",
      "name":"LuminAI: An Exploration of Human-AI Movement Improvisation",
      "lab":"ADAM Lab",
      "description":"LuminAI is an interactive art installation that explores the improvisation of proto-narrative movement between humans and virtual AI agents using full body, expressive, movement-based interaction. Interactors can co-create movement with an autonomous virtual agent that learns movement, response, and improvisation directly from interacting with human teachers. It analyses their movement using Viewpoints movement theory.\n"
   },
   {  
      "link":"/research/labs/contextual-computing-group",
      "name":"MAGIC Summoning: Towards Automatic Suggesting and Testing of Gestures With Low Probability of False Positives During Use",
      "lab":"Contextual Computing Group",
      "description":"Gestures for interfaces should be short, pleasing, intuitive, and easily recognized by a computer. However, it is a challenge for interface designers to create gestures easily distinguishable from users' normal movements. Our tool MAGIC Summoning addresses this problem. Given a specific platform and task, we gather a large database of unlabeled sensor data captured in the environments in which the system will be used (an \"Everyday Gesture Library\" or EGL).  MAGIC can output synthetic examples of the gesture to train a chosen classifier.\n"
   },
   {  
      "link":"/research/labs/research-network-operations-center-rnoc",
      "name":"Magic Window",
      "lab":"Research Network Operations Center (RNOC)",
      "description":"Magic Window supports immersive augmented video experiences allowing viewers to change perspective, as if they are looking through a real window.\nA rich set of collaborative interactions with live and pre-recorded media content as well as connected devices are possible through gesture-based controls.\n"
   },
   {  
      "link":"/research/labs/culture-and-technology-lab-cat",
      "name":"Makerspaces and Makerplaces: Collaboration, Togetherness, and Learning in Maker Communities",
      "lab":"Culture And Technology Lab (CAT)",
      "description":"Interviews with 61 makers, along with observations in several maker communities, provide empirical insight on the nuances between different types of communities and how these differences are influenced by the space and place of the makerspaces. Our exploration led to the identification of five prototypical maker communities; closed and regulated, open and messy, hybrid, online large-scale, and online small-scale.\n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"Making Smarter Transportation Choices",
      "lab":"Ubiquitous Computing Group",
      "description":"Driving is the second highest expense for the average American household -- more than food or healthcare, and behind only housing. Yet most people do not understand the total cost of owning and operating their vehicles, and they cannot accurately estimate the cost of a common driving trip (such as a commute from home to work). That's because the costs of owning and operating a vehicle are spread over many expenses incurred at different times. For example, you may fill up the gas tank once a week, make a monthly car payment, and pay insurance twice a year. Depreciation is a significant invisible expense of driving.<br><br>\nWe have developed a trip cost meter that makes the total cost of each driving trip visible to the user. We are exploring how this tool can help people make better informed personal transportation decisions, including choice of vehicle and choice of alternate modes of transportation (e.g., Uber, transit, ridesharing, or walking/biking).\n"
   },
   {  
      "link":"/research/labs/participatory-publics-lab",
      "name":"Mapping iThemba",
      "lab":"Participatory Publics Lab",
      "description":"Mapping iThemba draws on ethnographic research that Professor Anne Pollock began in 2010 at iThemba Pharmaceuticals (pronounced ee-TEM-ba), a small start-up pharmaceutical company in the outskirts of Johannesburg that was founded in 2009 with the mission of drug discovery for TB, HIV, and malaria. The synthetic chemistry research that scientists do at iThemba is no different than what might be done in a well-equipped lab anywhere in the world. Yet, place matters. The interactive map is an opportunity to explore how. \nMapping iThemba has been made possible by a grant from the National Science Foundation program for Science, Technology, and Society (Award #1331049). Professor Anne Pollock did the research and wrote the text for this site, new media artist Katherine Behar conceived the interactive map, and Digital Media master's student Russell Huffman designed, illustrated, and programmed it.\nThis site provides only one small window into the project. More is available in an article that Anne Pollock published in Social Studies of Science: \"Places of pharmaceutical knowledge-making: Global health, postcolonial science, and hope in South African drug discovery.\" Email apollock@gatech.edu if you would like to request a copy. Currently, she is writing a book manuscript on the project with the provisional title Synthesizing Hope: Global Health, Postcolonial Science, and South African Drug Discovery. For updates on publications from the project, see her website at Georgia Tech.\n"
   },
   {  
      "link":"/research/labs/synaesthethic-media-lab",
      "name":"Mapping Place",
      "lab":"Synaesthethic Media Lab",
      "description":"As part of the exhibit, Mapping Place: Africa Beyond Paper, which contrasts western concepts of mapping (i.e. Cartesian plots of locations) with other traditional practices, Synlab students created an interactive tabletop installation that lets participants tell their own stories by creating a digital Lukasa, a mnemonic device used by the Luba people of central Africa to record genealogy and history. The exhibition was at the Robert C. Williams Paper Museum from February 27 to June 6, 2014.\n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"MD2K: Keeping Users Engaged Through Mobile Technology",
      "lab":"Ubiquitous Computing Group",
      "description":"HCC professionals, psychologists, and many other researchers are interested in understanding how to better influence participant engagement in interventions that involve technology. This is especially true in instances when researchers are not able to provide monetary incentives over an extended period of time. Georiga Tech along with a team at the University of Michigan (working under an NIH-funded MD2K project) are exploring how to keep individuals motivated in such interventions through mobile technology and gamification.\n"
   },
   {  
      "link":"/research/labs/technologies-and-international-development-lab",
      "name":"Measuring the World's Digital Natives",
      "lab":"Technologies and International Development Lab",
      "description":"We offer a ?rst attempt to measure the global digital native population with a model for calculating the number of digital natives in each country of the world. We have calculated the size of the digital native population by country, by region and by income level and have related the presence of digital natives to education and literacy levels, and ultimately to policy-making. According to the model, in 2012 there were around 363 million digital natives out of a world population of around 7 billion   or 5.2 per cent. De?ning youth as young people aged 15 to 24, this means that 30 per cent of the world's youth have been active online for at least ?ve years. While it follows that fewer than a third of the world's young people today are digital natives, this group nonetheless plays an important role: ?rst, because where the online population is concerned, youth are clearly overrepresented, and second, because digital natives are key drivers when it comes to ICT uptake, innovation and impact.\n"
   },
   {  
      "link":"/research/labs/ms-hci-project-lab",
      "name":"Medication Management Tool Design for Students",
      "lab":"MS-HCI Project Lab",
      "description":"A tool which provide bran-new medication management experience to students as well as consider international students special pain points when using the US. medication system.\n"
   },
   {  
      "link":"/research/labs/culture-and-technology-lab-cat",
      "name":"Medium Probe: A Method for Seeding Dialogue to Explore the Suitable Medium of Communication in Design",
      "lab":"Culture And Technology Lab (CAT)",
      "description":"A method for engaging community members in productive discussions about technology with technology designers.&nbsp;Medium probes offer designers and participants&nbsp;a chance for open-ended exploration of design issues related to participants&rsquo; practices with technology, cultural values, skills, and&nbsp;access level.\n"
   },
   {  
      "link":"/research/labs/emergent-game-group",
      "name":"Mermaids MMOG",
      "lab":"Emergent Game Group",
      "description":"Mermaids is a massively multiplayer online game set in an underwater world in which players take the roles of hatchlings coming to life in the ruins of a long-extinct mermaid culture. The over-arching goal and storyline is to rebuild the lost Mermaid culture and reclaim their various skills and cultural practices, while at the same time trying to avoiding the mistakes that caused the extinction of their ancestors. Mermaids is designed as an experiment in emergent game play, with specific affordances designed to promote social emergence. This presentation will include a live demo of the game, plus a poster on the modular mermaid construction system currently being developed by an undergraduate student research team.\n"
   },
   {  
      "link":"/research/labs/interactive-media-technology-center-imtc",
      "name":"Midtown Buzz",
      "lab":"Interactive Media Technology Center (IMTC)",
      "description":"Midtown Buzz\nMidtown Buzz is an experiment in mobile innovation focused on engaging urban communities. It includes mobile platform and app development, open-source data curation, contextually aware environments, social navigation, developer workshops, hackathons, trials, needs assessments and the creation of a Live-Work-Play Laboratory for exploring the potential of media technologies in creating a climate for innovation.\nBe sure to check out the innovative Buzz projects, such as Storyoke and Auggy! Please visit www.midtownbuzz. org for more information.\n"
   },
   {  
      "link":"/research/labs/everyday-computing-lab",
      "name":"Motivational Glanceable Reminders - Designing a Better Medication Reminder App for Pediatric Asthma",
      "lab":"Everyday Computing Lab",
      "description":"This research aims to explore the use of glanceable reminders with a motivational component to support medication adherence. The healthcare industry has begun to focus on mobile health (mHealth) to improve medication adherence through the use of medication reminders. To date, mHealth apps have provided reminders that are text-based and purely informational in nature. The goal of using motivational glanceable reminders is to provide reminders that appeal to the emotional side of a person's decision making process and can be interpreted at a glance without the need to read, or even be literate. The research focuses on the pediatric asthma population. This research uncovers insights that can inform the design of future medication reminder mHealth apps that seek to integrate motivational glanceable reminders.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"MS Projects",
      "lab":"Experimental Television Lab",
      "description":"A collection of projects that explore the convergence of entertainment formats and computation, with focus on HCI design and research methods.\nSanat Rath: Giggles, an application to help viewers relive moments from their favorite sitcoms.\nSruthi Padala: A second screen application for the popular TV show 'The Voice'.\nVipul Thakur: Talkista, an application that serves as your information resource, companion in conferences, meetups and classrooms.\nAmrutha Krishnan: Newspad, design of a second screen application for news that enables viewers to understand the news better by providing them the required context as well as supplementary information.\n"
   },
   {  
      "link":"/research/labs/information-interfaces-group",
      "name":"Multi-touch Dust and Magnet",
      "lab":"Information Interfaces Group",
      "description":"This demo shows a system called Dust and Magnet (DnM) that is a general purpose data visualization system. DnM represents data items as iron dust. Each attribute of the data then is a magnet. The system is implemented on a large multi-touch display where the analyst can deploy magnets and drag them around the view. Data points will then be attracted more strongly or weakly depending on that data item's value of the attribute represented by each magnet.  This system provides a very hands-on, visceral data exploration experience.\n"
   },
   {  
      "link":"/research/labs/design-intelligence-laboratory",
      "name":"Multifunctionality In Biologically Inspired Design",
      "lab":"Design & Intelligence Laboratory",
      "description":"Biological systems in general are multifunctional and environmentally sustainable.\nThus, biologically inspired design is posited as leading to multifunctional and environmentally\nsustainable designs. Design in general is characterized as a problem-driven process. However,\nbiologically inspired design also entails the twin process of solution-based design. Previous work\nhas postulated that the solution-based design process is prone to design fixation but leads to more\nmultifunctional designs. Design Study Library (DSL) is a digital library of eighty-three cases of\nbiologically inspired design. We present a preliminary analysis of the DSL case studies to examine\ntwo hypotheses. (1) The process of solution-based design results in more multifunctional designs\nthan the problem-driven design process. (2) The process of solution-based design is more prone to\nfixation than the problem-driven design process. We find strong evidence in favor of the first\nhypothesis.\n"
   },
   {  
      "link":"/research/labs/synaesthethic-media-lab",
      "name":"Multisensory Prayer Nuts ",
      "lab":"Synaesthethic Media Lab",
      "description":"We present three prototypes designed for a hypothetical museum exhibit that elicit historical and experiential qualities of early 16th century prayer-nuts. As personal religious experiences included a dependence of spirituality on material objects during the 16th century, we believe that digitally-enhanced multisensory interactions can help situate the artifact in its historical context. The 3D printed interactive prayer nuts augmented with audio-visual effects support the visual voyage, experience of spirituality, and scents of power. The tactile, aural, visual, olfactory sensory interactions are mapped meaningfully to incorporate some of the original sensory aspects of the artifact and related practices. Our research provides insight on how multisensory interactions can provide museum visitors with the opportunity to experientially engage in content related to an artifact's history and original use. \n"
   },
   {  
      "link":"/research/labs/computational-perception-lab",
      "name":"Mutual Gaze Eye Contact",
      "lab":"Computational Perception Lab",
      "description":"Real-Time Eye Contact Using SMI Gaze Tracking Glasses\n"
   },
   {  
      "link":"/research/labs/sonification-lab",
      "name":"Mwangaza Project",
      "lab":"Sonification Lab",
      "description":"The Mwangaza Project is a collaboration among the Sonification Lab, inAble, and Kenyatta University to develop and deploy accessible STEM educational resources to schools for the blind throughout Kenya. Projects that we are working on include accessible weather and climate education, math software for accessing graphing and number lines, and renewable energy as a component of STEM education and support for educational technologies.\n"
   },
   {  
      "link":"/research/labs/everyday-computing-lab",
      "name":"My Journey Compass: Examining PHR Usage Among Breast Cancer Patients",
      "lab":"Everyday Computing Lab",
      "description":"Health information management for cancer care is a challenging and personal process that changes over time based on one's needs, goals, and health status. While technologies supporting health information management appear promising, we do not fully understand how health information tools fit into patients' daily lives. To better understand the opportunities and usage barriers of these tools, we designed and deployed a mobile, tablet-based health management aid: My Journey Compass. We found that developing a tool that was customizable, mobile, and integrated into the patients' healthcare system resulted in a set of surprising uses by breast cancer patients for a wide variety of tasks. Our study demonstrates the potential for health management tools to improve the cancer care experience and for HCI research to influence existing healthcare systems.\n"
   },
   {  
      "link":"/research/labs/ms-hci-project-lab",
      "name":"MyDrinkPal",
      "lab":"MS-HCI Project Lab",
      "description":"A Beginner's Guide Empowering Cocktail Making\n"
   },
   {  
      "link":"/research/labs/emergent-game-group",
      "name":"Navis: A College Orientation Game",
      "lab":"Emergent Game Group",
      "description":"Navis is a college orientation game designed by graduating Digital Media Master's student Laura Schluckebier. Navis is designed as a campus-side scavenger hunt with team building challenges. Upon arriving to campus for their orientation session, first years work with their teammates to discover clues around campus and to compete in team building challenges. Completing these challenges and earns them points.\nNavis' features include 1) a variety of challenges types that teach students through game actions rather than content 2) fluid play groups 3) and an overarching structures that encourages individual intiative.\nThe game also features a Framework that allows university orientation staff from a variety of college campuses to customize and deploy Navis during their orientation session.\n"
   },
   {  
      "link":"/research/labs/information-interfaces-group",
      "name":"NBA Basketball Data Visualization",
      "lab":"Information Interfaces Group",
      "description":"We have developed a system to visualize all the player and game statistics from an entire NBA season.  The system shows all of the players on a team's performance in various statistics for the 2012-13 NBA season.  Through one concise view, a person can explore the dataset to learn more about team and player performance and to perform analysis.\n"
   },
   {  
      "link":"/research/labs/technologies-and-international-development-lab",
      "name":"New Media Nollywood",
      "lab":"Technologies and International Development Lab",
      "description":"The Nigerian film industry   colloquially known as Nollywood   is enormous, innovative, and digital. We are working to extend its capacities with new media technologies such as games, mobile and social media. In addition, we are developing social messaging campaigns within Nollywood films in particular around health issues. Come see emerging technologies and film content, including the feature length Nollywood film we produced and are premiering.\n"
   },
   {  
      "link":"/research/labs/gt-bionics",
      "name":"Non-Invasive Diagnosis of Airway Resistance in Young Children Using Microsoft Kinect",
      "lab":"GT-Bionics",
      "description":"Respiratory syncytial virus (RSV) is a virus that causes respiratory tract nfections especially in young children. This infection increases the airway resistance and makes it harder to breathe because more pressure has to be generated in the lungs to the extent that the respiratory muscles may get so tired that the patient stops breathing. In the U.S., by the end of 2-3 years of age, nearly all of the children are going to be infected with RSV at least once. Among them, 2-3% will develop bronchiolitis and need to be hospitalized. For this disease, similar to the most of the medical complications, the best strategy is prevention. RSV is a virus, thus a vaccine would be the best answer. Unfortunately, at present no RSV vaccine exists. The last attempt was a trial in 1960s that failed! On the other hand, some symptoms (e.g. temporary difficulty in breathing especially in infants) can easily be mistaken with RSV infection and cause a lot of unnecessary visits to the hospitals/emergency rooms (very high false positive rate).\nIn this research, we aim to quantify airway resistance through a simple, non-invasive measurement of the chest volume changes over time that can act as a surrogate measure of chest pressure and volumetric airflow. Our approach uses signal and image processing techniques to infer airway resistance using a commercially available infrared depth-sensor, Microsoft Kinect. We envision in the case of commercialization, at a similar price to baby monitors, this technology would have the potential to greatly improve the management of the infant obstructive pulmonary diseases and reduce unnecessary hospital visits. \n \n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"Novel Interactions with Wearable Devices",
      "lab":"Ubiquitous Computing Group",
      "description":"A series of demonstrations of novel interactions with wearable devices, from smartwatches to head-mounted displays.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Nutshell",
      "lab":"Experimental Television Lab",
      "description":"Nutshell is a video editing tool that allows users to isolate clips from their favorite TV shows and create \"supercuts\" that summarize complex plot arcs and compile recurring inside jokes.\n"
   },
   {  
      "link":"/research/labs/social-dynamics-and-wellbeing-lab",
      "name":"Observing Food Consumption Patterns through Instagram",
      "lab":"Social Dynamics and Wellbeing Lab",
      "description":null
   },
   {  
      "link":"/research/labs/culture-and-technology-lab-cat",
      "name":"One Block: A Local Parent Community Bridging the Gap in Digital Inequality",
      "lab":"Culture And Technology Lab (CAT)",
      "description":"Parents have an important role in improving their children's educational experience by providing them with learning opportunities Free online informal learning resources are available more than ever; however, research shows that people who may need these resources the most, are not able to find them. In this study, we go beyond a binary definition of access to examine technology practices and level of access to information technologies among African-American parents in financially depressed communities in westside Atlanta. We propose a hyper-local community for parents to be able to engage in neighborhood discussions and communicate available learning opportunities within the community.\n"
   },
   {  
      "link":"/research/labs/urban-transportation-information-lab",
      "name":"OneBusAway",
      "lab":"Urban Transportation Information Lab",
      "description":"The OneBusAway transit traveler information system gives users information about transit vehicle arrival times including real-time arrivals and schedule information. It is comprised of multiple interfaces to access information, including a website, a mobile-optimized website, and native applications for iPhone, Android and Windows platforms (see http://onebusaway.org). OneBusAway was developed under multiple federal grants as an open-source system allowing other transit agencies to adapt the code for their own systems. The initial development took place at the University of Washington and the Seattle instance still serves over 100,000 unique weekly users.  The platform is also now used in Tampa and Washington DC and as the backbone of MTA New York's BusTime.\nHere in Atlanta, the Urban Transportation Information Lab (UTIL) has worked to create a local version of OneBusAway using funding from Georgia Tech's GVU Center, the Institute for People and Technology (IPAT) and the National Center for Transportation Systems Productivity and Management (NCTSPM). We have integrated all of MARTA's train and bus real-time information, Georgia Tech's trolley and shuttle real-time information and schedule data from multiple area agencies (see http://atlanta.onebusaway.org).  Additional transit services are being added over time. We are using the platform to conduct an evaluation of its impacts on transit riders, specifically using smartcard data to quantify the increase in trips. Previous studies of real-time transit information have demonstrated a number of user benefits, including decreases in perceived and actual waiting times, as well as increases in frequency of travel and customer satisfaction.\n"
   },
   {  
      "link":"/research/labs/urban-transportation-information-lab",
      "name":"OneBusAway Web App",
      "lab":"Urban Transportation Information Lab",
      "description":null
   },
   {  
      "link":"/research/labs/social-dynamics-and-wellbeing-lab",
      "name":"Online Support for Mental Health",
      "lab":"Social Dynamics and Wellbeing Lab",
      "description":"Mental health issues are considered to be socially stigmatized in the society. Consequently, to many individuals, finding a trusted individual whom they can confide to regarding their mental illness is a grave challenge. It has been established that online communities provide a powerful platform of candid disclosures and support seeking around stigmatized concerns and experiences. Online health support groups in Reddit, in particular, due to their semi-anonymity feature, have established an extensive support platform for people with social inhibitions seeking help. These communities can provide support in various forms, ranging from informational to emotional support.. Informational support may be helpful for short term challenges in contrast to the emotional support. However, information support can also present itself with credibility and trust issues. On the other hand, emotional support is deemed more helpful to people suffering from mental illness. How do these different types of support impact an individual's perceived sense of mental well-being in an online community? How do support types relate to an online community's helpfulness, efficacy, and survival over time? Through this project, we will show some preliminary quantitative findings that addressed these questions.\n"
   },
   {  
      "link":"/research/labs/information-interfaces-group",
      "name":"OnSet: Visualizing Large Sets of Data Elements",
      "lab":"Information Interfaces Group",
      "description":"Visualizing sets to reveal relationships between constituent elements is a complex representational problem. Recent research presents several automated placement and grouping techniques to highlight connections between set elements. However, these techniques do not scale well for sets with cardinality greater than one hundred elements. We present OnSet, an interactive, scalable visualization technique for representing large-scale binary set data. The visualization technique defines a single, combined domain of elements for all sets, and models each set by the elements that it both contains and does not contain. OnSet employs direct manipulation interaction and visual highlighting to support easy identification of commonalities and differences as well as membership patterns across different sets of elements. We present case studies to illustrate how the technique can be successfully applied across different domains such as bio-chemical metabolomics and task & event scheduling.\n"
   },
   {  
      "link":"/research/labs/contextual-computing-group",
      "name":"Order Picking with Wearable Computers",
      "lab":"Contextual Computing Group",
      "description":"Warehouses throughout the world distribute approximately $1 trillion in goods per year from nearly a million warehouses. Order Picking is the process of collecting items from inventory and sorting them into orders for distribution. It represents one of the main activities performed in warehouses. About 60% of the total operational costs of these warehouses is order picking. Most are still picked by hand, often using paper pick lists. Our objective is to implement and compare various order-picking systems, including: \n\u2022 Pick-By-Paper list\n\u2022 Pick-By-Light\n\u2022 Pick-By-Tablet\n\u2022 Pick-By-HUD (Heads-Up Display).\n"
   },
   {  
      "link":"/research/labs/interactive-media-technology-center-imtc",
      "name":"Order Up!: Mobile Gaming To Promote Healthier Diet Choices",
      "lab":"Interactive Media Technology Center (IMTC)",
      "description":"OrderUp! takes health-related gaming in a new direction and seeks to educate players about how to make healthy eating choices in situations nearly everyone encounters regularly in their lives. By casting players as virtual restaurant servers, OrderUp! forces players to make healthy\u2014and fast\u2014menu decisions for a group of demanding, impatient customers. OrderUp! was originally developed as a simple, casual game on Nokia N95 mobile phones. We are building on research findings from testing this first version of the game to develop a new version with higher fidelity graphics and more sophisticated game play. This new version will run on modern, Android smart phones and will incorporate features intended to promote cognitive flow, an increased level of engagement and fun with the game, such as progressive increases in game play difficulty and better performance and scoring feedback. The revised OrderUp! game will be tested with a population of largely African Americans who are being treated for mental health issues. As such, OrderUp! is designed with contextually relevant motifs and with relevant data and personas.\n"
   },
   {  
      "link":"/research/labs/design-and-social-interaction-studio",
      "name":"Our Driverless Futures: Through the Lens of Speculative Moral Algorithms",
      "lab":"Design and Social Interaction Studio",
      "description":"Autonomous vehicles, more popularly known as self-driving cars, have recently entered public imagination as the next frontier in safer and more efficient transportation. With heavy investments from tech companies such as Google, Tesla, and Uber, self-driving cars seem to be inevitable. Yet, the technology is far from perfect. Among unresolved issues are ethical questions of how cars might/must react in situations of an unavoidable accident. Should the car protect its passengers at all costs? Or should it sacrifice the life of one to benefit a few? Proponents argue that these questions will be eventually addressed through the design of moral algorithms, or algorithms that are designed to make ethical decisions.\nIn this project, my goal is to combine speculative design and design research approaches to portray potential scenarios for driverless cars, with artifacts that simulate a driverless future. These artifacts serve two purposes: first, to be presented to potential users with the intent of generating feedback on the implications of moral algorithms; second, to elicit discussion on the role of algorithms and institutions in managing our lives and their \u2018solutionist' strategies for civic problems. Finally, the design of these artifacts will be informed by a literature review of the social properties of algorithms. By combining both speculative design and design research approaches to imagine probable future scenarios, my aim is to further broaden the terms of discourse around moral technologies, their inherent limitations, and palpable consequences. The demo will include my initial sketches and early prototypes in this direction.\n"
   },
   {  
      "link":"/research/labs/ms-hci-project-lab",
      "name":"Packaging a maker based prototyping curriculum for Instructors",
      "lab":"MS-HCI Project Lab",
      "description":null
   },
   {  
      "link":"/research/labs/culture-and-technology-lab-cat",
      "name":"Parent Pedagogical Perspectives: A Framework for Design of Museum Exhibits",
      "lab":"Culture And Technology Lab (CAT)",
      "description":"The rise of ubiquitous technology has resulted in exponential growth in potential options for the design of interactive museum exhibits. We posit that using a framework of parental beliefs about learning and teaching for design can be useful to the HCI community when creating museum exhibits to facilitate learning. Our study builds upon Swartz and Crowley's framework of parental pedagogical approaches through analysis of 118 observations of social interactions between parents and children at museum exhibits. We classify our observations of parent-child interactions into the framework's five categories: Fun Exploration, Individual Discovery, Basic Knowledge, Parent Engaged Learning, and Contextualized Explanations. We identify how these categories can be applied to evaluate and guide design for learning in the context of museums and other informal learning environments.\n"
   },
   {  
      "link":"/research/labs/design-and-social-interaction-studio",
      "name":"Participatory Locative Media: Sweet History of Auburn  ",
      "lab":"Design and Social Interaction Studio",
      "description":"This project is an alternate wayfinding method for the Sweet Auburn district, highlighting key landmarks and businesses that played a pivotal role in Atlanta's history. \n"
   },
   {  
      "link":"/research/labs/design-and-social-interaction-studio",
      "name":"Particle in a Box (An Experiential Approach to Quantum Mechanics Education)",
      "lab":"Design and Social Interaction Studio",
      "description":"Theories of Quantum Mechanics(QM) have been central to the philosophical and technological advances in physics and related fields. Some of the most important aspects of these theories are outside the bounds of human experience, predominantly explained and taught drawing on abstract mathematical formulas. How can we advance experience-based learning of abstract concepts such as QM so students develop the in-depth understanding needed to further advance these theories by generating and testing new hypotheses? This research project addresses this question through a series experimentations with digital media (e.g., by designing interactive games based on the rules of QM) engaging whether and how digital media could serve as the basis for an experiential understanding of QM concepts. For more information and to play the latest version of the game please visit, http://learnqm.gatech.edu \n"
   },
   {  
      "link":"/research/labs/contextual-computing-group",
      "name":"Passive Haptic Learning",
      "lab":"Contextual Computing Group",
      "description":"Passive Haptic Learning (PHL) is the acquisition of sensorimotor skills without active attention to learning.  Vibrations are used to passively \u2018teach' the motor skill and are typically delivered by a wearable, tactile interface.  Our group has previously demonstrated Passive Haptic Learning of piano melodies and of typing skills for text entry on a unique 10-key keyboard.  We now investigate whether Passive Haptic instruction facilitated by wearable computers may be a feasible method of teaching Braille typing.\n"
   },
   {  
      "link":"/research/labs/electronic-learning-communities",
      "name":"Peer Feedback",
      "lab":"Electronic Learning Communities",
      "description":"Peer assessment is a popular approach for grading assignments that cannot be simplified to multiple choice questions in Massive Open Online Courses (MOOCs). How can we take peer assessment and transform it into an engaging and enjoyable experience which enhances the learning outcomes for students?\n"
   },
   {  
      "link":"/research/labs/adam-lab",
      "name":"PeerSketch: A Mobile Platform for Collaborative Coding and Remixing using EarSketch",
      "lab":"ADAM Lab",
      "description":null
   },
   {  
      "link":"/research/labs/interactive-media-technology-center-imtc",
      "name":"Personalized Augmented Reality Lenses for STEM Education",
      "lab":"Interactive Media Technology Center (IMTC)",
      "description":"Augmented reality (AR) has long been explored as a tool for education, from textbooks that come to life, to plant identification training via the augmentation of actual flora, and a tangible molecular modeling tool.  The power of AR (overlaying virtual content on the physical world) is that it can be used to show the unseen and the hidden information in the world. While this can involve showing representations of occluded objects (such as pipes underneath the ground), it can also be used to visually represent data or properties of the physical world that you would not normally see (such as the forces acting on an object). There is considerable research in this area of situated visualization, defined as the visual representation of data presented in its spatial and semantic context. This technique addresses the need in certain contexts to convey to the user the relationships between physical objects and virtual data. \nWe are demoing our initial prototypes that explore how to use AR and the concept of situated visualization to create a combination physical and virtual exploration kit for students that allows them to construct simple static and dynamic systems with physical building components. AR will allow the students to see virtual visualizations of the physics properties and concepts (e.g. velocity, acceleration, forces, friction, elasticity), which control the system, in real-time and overlaid on the real objects.\nFunded by the Verizon Foundation\n"
   },
   {  
      "link":"/research/labs/visual-analytics-lab",
      "name":"Podium: Helping People Rank Their Data Using Mixed-Initiative Visual Analytics",
      "lab":"Visual Analytics Lab",
      "description":"People often rank and order data items as part of making decisions. Multi-attribute ranking systems are a common tool used to make such data-driven decisions. Machine learning approaches can produce rankings based on the weights that users apply to attributes. Users set the weights of attributes according to how important they believe an attribute is to their decision. However, these systems assume that users have an intuitive understanding of what attribute weights mean, and further, they require that users are able to quantify their conceptual understanding of how important particular attributes are. To address these challenges, we present a technique to infer attribute weights based on a user's preferences. To demonstrate the feasibility of the proposed model, we developed a prototype system, Podium, that allows users to drag rows in the table indicating where they think data items belong based on their knowledge or preferences. Our system then infers a weighting model that satisfies the user's preferences as closely as possible. This makes powerful machine learning techniques more usable to those who may not have expertise in these areas.\n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"POSTER -- The Science Behind Getting (and Keeping) Followers on Twitter",
      "lab":"Comp.Social Lab",
      "description":"Followers are Twitter's most basic currency. Building an audience of followers can create access to a network of social ties, resources, and influence. Yet, little is understood about how to grow such an audience. We examine multiple factors that affect tie formation and dissolution over time on the social media service Twitter. We collected behavioral, content, and network data approximately every three months for fifteen months and compared the relative contributions of 22 variables from each perspective for predicting link formations in online social networks.\n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"POSTER presentation -- The Language that gets People to Give - Phrases that Predict Success on Kickstarter",
      "lab":"Comp.Social Lab",
      "description":"Crowdfunding sites like Kickstarter\u2014where entrepreneurs and artists look to the internet for funding\u2014have quickly risen to prominence. However, we know very little about the factors driving the crowd to take projects to their funding goal. In this paper we explore the factors which lead to successfully funding a crowdfunding project. We study a corpus of 45K crowdfunded projects, analyzing 9M phrases and 59 other variables commonly present on crowdfunding sites. The language used in the project has surprising predictive power\u2014 accounting for 58.56% of the variance around successful funding. A closer look at the phrases shows they exhibit general persuasion principles. For example, also receive two reflects the principle of Reciprocity and is one of the top predictors of successful funding. We conclude this paper by announcing the release of the predictive phrases along with the control variables as a public dataset, hoping that our work can enable new features on crowdfunding sites\u2014tools to help both backers and project creators make the best use of their time and money.\n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"Poster: Careflow Analytics and Visualization",
      "lab":"Computational Enterprise Science Lab",
      "description":"Healthcare delivery processes are complex activities that span organizational, spatial, and temporal boundaries. Systemic insights, redesign, and improvements are consequently difficult to achieve. Using existing digital healthcare data, we are developing a data-driven methodology, fusing computational systems modeling, data mining, and interactive visualization, to identify, describe, and visualize healthcare delivery processes. Our system will help providers (e.g. physicians, nurses, etc.) and strategic decision makers (e.g. CIOs, CTOs, CFOs) interactively discover, analyze, and visualize processes, determine variations in care quality, cost, and outcomes stratified by physician and patient population, and provide an important evidence-based foundation for healthcare delivery improvement.\n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"Poster: Computational Analysis and Visualization of Global Supply Network Risks",
      "lab":"Computational Enterprise Science Lab",
      "description":"Management of supply network risks is a critical competency for today's global enterprises. Current practices and tools, however, have limited capabilities and do not allow for systemic exploration of alternate risk strategies. We develop a\ncomputational model of risk diffusion in global supply networks that is grounded in techniques from complex systems, network analysis, and epidemiological risk modeling. We draw on a unique, curated dataset of firms, their supply networks, and financial risk in the global electronics industry. Specifically, we assess and visualize the impact of network structure on risk diffusion and supply network health, and determine the impact of visibility on reduction and potential mitigation of cascading risks. Our approach enables decision makers to identify risks and determine potential paths of their diffusion. In doing so, we advance our understanding of the design and development of computational risk management tools in a global supply network context.\n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"Poster: CSCW in the Healthcare Enterprise: A Knowledge Domain Visualization",
      "lab":"Computational Enterprise Science Lab",
      "description":"Designing effective CSCW systems in healthcare requires a careful consideration of the entire enterprise.  This study uses computational text analysis and network visualization of topical terms and keywords to map the extant knowledge domain of CSCW in healthcare.  The results are framed using a multi-level enterprise model, comprised of people, technology, process, and organization.  Emerging trends and prominent patterns are identified.  The study contributes to a broader understanding of CSCW research in healthcare and demonstrates the value of adapting an enterprise (as a) system lens.\n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"Poster: Health Policy Flight Simulator",
      "lab":"Computational Enterprise Science Lab",
      "description":"Computer simulations are effective tools for addressing enterprise transformation in terms of alternative organizational policies, operating procedures, and allocations of resources. We present a multilevel approach to computationally model health delivery enterprises. This approach is illustrated by its application to an employer-based prevention and wellness program. The decision of interest in this application concerns the design of prevention and wellness programs that are self-sustaining and provide a positive return on investment for the overall enterprise. The nature of this decision is shown to have enormous implications for how delivery services are organized.\n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"Poster: Knowledge Discovery of Competitive Strategies in Converging Ecosystems",
      "lab":"Computational Enterprise Science Lab",
      "description":"With the remarkable increase of data, novel tools and metrics are needed for comprehensive and systemic analyses of converging business ecosystems. Knowledge discovery is the computational process of identifying valid, novel, interesting, potentially useful and ultimately understandable patterns in data. The objective of our study is twofold. First, we introduce the emerging domain of \"big\" business ecosystem data. Second, we describe the success and challenges that we encountered in analyzing this data using state of the art analytics and visualization techniques. Specifically, we illustrate our computational knowledge discovery approach with case studies of innovation, coopetition, and convergence in the mobile ecosystem. We conclude with theoretical and managerial implications and identify opportunities for future research in the emerging domain of computational enterprise science.\n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"Poster: Product Evolution and Platform Strategy: A Study of Smartphones",
      "lab":"Computational Enterprise Science Lab",
      "description":"We study how operation and platform strategy affect product- and firm-level innovativeness in the smartphone industry. Our study is based on the technological evolution of smartphones including physical characteristics, performance characteristics, and features over the past decade. Our longitudinal analysis of a dataset consisting of 1,171 smartphones by 79 device manufacturers and 12 different platforms highlights the significant transformational changes that have occurred. We propose an index to measure innovativeness of a smartphone upon which we test our main hypotheses. Our findings are threefold. First, we find the rate of product launch is negatively associated with product innovativeness. Second, we find the number of product lines is positively associated with product innovativeness. Lastly, we find a nonlinear pattern between platform strategy and product innovativeness in that a mixed platform strategy is associated with higher product innovativeness than a pure platform strategy.\n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"POSTRE: Faces Engage Us: Photos with Faces Attract More Likes and Comments",
      "lab":"Comp.Social Lab",
      "description":"Photos are becoming prominent means of communication online. Despite photos' pervasive presence in social media and online world, we know little about how people interact and engage with their content. Understanding how photo content might signify engagement, can impact both science and design, influencing\nproduction and distribution. One common type of photo content that is shared on social media, is the photos of people.\nFrom studies of offline behavior, we know that human faces are powerful channels of non-verbal communication. In this paper, we study this behavioral phenomena online. We ask how\npresence of a face, it's age and gender might impact social engagement on the\nphoto. We use a corpus of 1 million Instagram images and organize our study around two\nsocial engagement feedback factors, likes and comments. Our results show that photos with faces are 38% more likely to\nreceive likes and 32% more likely to receive comments, even after\ncontrolling for social network reach and activity.  We find, however,\nthat the number of faces, their age and gender do not have an\neffect. This work presents the first results on how photos with human faces relate to engagement on large scale image\nsharing communities.  In addition to contributing to the research\naround online user behavior, our findings offer a new line of future\nwork using visual analysis.\n"
   },
   {  
      "link":"/research/labs/digital-world-and-image-group",
      "name":"Power Puppets",
      "lab":"Digital World and Image Group",
      "description":"The Power Puppet project combines the creation of a mechanical puppet with simple circuit building. Its goal is to teach middle school students basic circuit building in the setting of a puppet building workshop. As students build their puppets, including control mechanisms (like rods and strings) and expressive elements (like joints and materials), they also create basic circuits that operate in combination with the puppet that houses them.\n"
   },
   {  
      "link":"/research/labs/entertainment-intelligence-lab",
      "name":"Procedurally Generated Augmented Reality Games",
      "lab":"Entertainment Intelligence Lab",
      "description":"Augmented Reality gaming promises new ways for humans to engage with their physical environment by overlaying gameplay elements via a head-mounted display. We present an artificial intelligence technique to automatically generate novel gameplay content for mixed-reality environments. We demonstrate the technique with a game we call \"Augmented Reality Lemmings\", a platform game in which the level content was procedurally generated.\n"
   },
   {  
      "link":"/research/labs/augmented-environments-lab",
      "name":"Projet: A Panorama Narrative",
      "lab":"Augmented Environments Lab",
      "description":"This is the first is a series of experiments in locative narrative. In this version Projet is entirely screen-based. Later applications in this series will use Argon to create true location-based narratives. Projet itself can be experienced on a laptop or desktop screen, but there is greater intimacy and effect when experienced on a tablet or phone.  \nA woman finds herself in a village in the French countryside, reflects on her present life, and recalls her past. Projet reduces the viewer's interaction to the barest minimum. The viewer intervenes by touching the screen at various moments to reanimate the narrative\u2014to set a panorama or slideshow in motion like a music box. She can also scroll to explore the panoramas will the audio plays.\nIdea, text and images: Maria Engberg. Experience design and implementation: Maria Engberg and Jay Bolter. Voice Actor: Tess Kincaid.\n"
   },
   {  
      "link":"/research/labs/digital-world-and-image-group",
      "name":"Prototyping Puppets - Teaching Circuitry",
      "lab":"Digital World and Image Group",
      "description":"We combine craft and performance art to teach early middle school students basic prototyping skills. We develop informal STEM workshops for puppetry that combine narrative framing, craft-inspired building, and performance. This key approach combines craft, art, and basic hardware prototyping to attract new audiences to STEM. It is a collaboration between Georgia Tech and at the Center for Puppetry Arts funded by the NSF.\n"
   },
   {  
      "link":"/research/labs/visual-analytics-lab",
      "name":"PUNGA: Provenance-supported Undirected Node Graph Analytics",
      "lab":"Visual Analytics Lab",
      "description":"PUNGA (Provenance-supported Undirected Node Graph Analytics) is a tool for intelligence analysts. PUNGA assists analysts in making sense of a large textual-based dataset by supporting data processing (Named Entity Recognition), data cleaning, data analysis, and analytic provencance.\nPUNGA provides users the ability to combine, format, clean the data as per their convenience before and during analysis with the Entity View. PUNGA also facilitates user interaction with the data sets in a number of linked views. These visualizations include the Document Viewer, the Node Graph View, and the Calendar View. Finally, PUNGA provides a Provenance View that displays quantitative values that summarize the analysis session and more importantly help in analytic provenance.\n"
   },
   {  
      "link":"/research/labs/culture-and-technology-lab-cat",
      "name":"Quick-Cut Video Editor ",
      "lab":"Culture And Technology Lab (CAT)",
      "description":"Videos are great tools for teaching, learning and communication; however, because video editing is time consuming and tedious there are few people who take on the task. Utilizing the advances that have been made in video editing tools and algorithms we could help to ease this burden. Quick-Cut is a video editing tool focused on narration videos. It attempts to cut down the time it takes to edit videos together, while still producing a quality final cut. The tool specifically targets improving the time for: loading videos, aligning videos to specific points in the audio, and creating optimal cuts with optimal video quality.\n"
   },
   {  
      "link":"/research/labs/health-experience-and-applications-lab-hx-lab",
      "name":"Rapport: Pediatric Patient and Family Oriented Radiology Report",
      "lab":"Health Experience and Applications Lab (Hx Lab)",
      "description":"Diagnostic radiology reports are increasingly being made available to patients and their family members. However, these reports are not typically comprehensible to lay recipients, impeding effective communication about report findings. Rapport is a prototype system that aims to facilitate communication about radiology imaging findings among pediatric patients, their family members and clinicians in the clinical setting.\n"
   },
   {  
      "link":"/research/labs/emergent-game-group",
      "name":"Re:Activism Atlanta",
      "lab":"Emergent Game Group",
      "description":"The Pervasive Games Group of the {egg} presents their new design of the big urban game Re:Activism, originally developed by the PETLab at Parsons The New School. This modular design of Re:Activism gives players a condensed experience of activist history in Atlanta. Players travel around to downtown sites that are tied to historical moments of activism and complete challenges related to those events.\n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"Real Time Aggregation of Keywords from Censored Posts on Sina Weibo using Hadoop and Cron",
      "lab":"Comp.Social Lab",
      "description":"With the increasing presence of censorship on Chinese social media, it is imperative to provide the users of platforms such as Sina Weibo a way to freely share information without alerting the censors and systems of surveillance on social media. The aim of this project is to implement a Real-Time Keyword Aggregator that collects keywords that have most likely resulted in censorship of posts from various publicly available archives of censored sina weibo posts. In this work, utilize a Distributed Computing based technique to identify additional possible keywords from the posts using a TF-IDF based technique. The result of this project will be a large, continuously populated and curated homophone dictionary for currently censored keywords on Sina Weibo.\n"
   },
   {  
      "link":"/research/labs/urban-transportation-information-lab",
      "name":"Real-Time Dispatching on Atlanta Streetcar",
      "lab":"Urban Transportation Information Lab",
      "description":"Background\nThe streetcars run in the heart of downtown. They are subject to unstable operating conditions caused by traffic congestion, basketball games, and obstructed right-of-way. These perturbations make the Atlanta Streetcar prone to streetcar-bunching, which causes undue passenger wait and crowding. We have developped a real-time dispatching method that considers every streetcar on the route to dispatch them with even headways, while maintaining a high frequency of service. The dispatching method will replace the current schedule on the Atlanta Streetcar as a case study for several weeks. We will evaluate the impact of real-time dispatching on operations, driver behavior, and passenger waiting time.\n"
   },
   {  
      "link":"/research/labs/computational-perception-lab",
      "name":"Real-time Eye Contact Detection",
      "lab":"Computational Perception Lab",
      "description":"Using Google Glass to detect eye contact in real-time.\n"
   },
   {  
      "link":"/research/labs/participatory-publics-lab",
      "name":"Redesigning the Career Fair Experience",
      "lab":"Participatory Publics Lab",
      "description":"As students, many of us regard career fairs as vital events for securing job and internship opportunities. However, there are several frustrating aspects of career fairs, which can make the experience less enjoyable and less efficient. We aim to improve the overall experience of career fairs while considering the perspectives of multiple stakeholders, through service design.\n"
   },
   {  
      "link":"/research/labs/contextualized-support-learning",
      "name":"Reducing Cognitive Load to Improve Learning to Program",
      "lab":"Contextualized Support for Learning",
      "description":"Cognitive Load is the amount of \"processing\" your brain does when learning something new. This project investigates ways to lower the cognitive load while learning to program.\n"
   },
   {  
      "link":"/research/labs/privacy-engineering",
      "name":"Requirements Engineering for Privacy, Security and Compliance in Data Science Research Projects",
      "lab":"Privacy Engineering",
      "description":"This research addresses the privacy, security, and compliance challenges faced by university researchers and ethics review boards when working on data science projects. Due to the emergent properties of big data, researchers regularly re-evaluate and modify their goals. These changes must be reflected in the project's governing documents, including research protocols, consent forms, privacy and security policies, and data-use agreements. These documents must be consistent, must cater to diverse and sometimes conflicting stakeholder needs, must be compliant in a complex regulatory landscape, and must ensure the privacy and security of research participants. Consistent involvement by a privacy and security expert in every research project, although effective, is not a feasible solution. The goal of this project is to explore whether requirements engineering can be leveraged as a potential solution to these challenges. Requirements engineering can not only help align stakeholder goals with a project's governing documents but can be used to develop tools to enable researchers and ethics review boards to better address privacy, security and compliance in research protocols.\n"
   },
   {  
      "link":"/research/labs/aware-home-research-initiative",
      "name":"RERC TechSAge: A Mobile Application to Measure Gait Speed",
      "lab":"Aware Home Research Initiative",
      "description":"Multiple studies have shown a consistently strong association between gait speed of frail older adults and negative functional (e.g., survival) and activity outcomes. However, health care professionals have been slow to measure this physiologic parameter, largely due to the lack of a simple, standardized way of measuring it. The purpose of this project is to develop a reliable, simple, and cost-effective mobile app to measure gait speed and demonstrate the feasibility of this measure as a predictive tool to identify risk of functional decline and activity limitation in frail elders who are aging with ambulatory disability.\n"
   },
   {  
      "link":"/research/labs/aware-home-research-initiative",
      "name":"RERC TechSAge: SmartBathroom",
      "lab":"Aware Home Research Initiative",
      "description":"The needs and abilities of people who are aging with progressive chronic conditions, such as MS, Parkinson's, ALS and Arthritis fluctuate from day to day. Yet, even when they have supportive AT, such as grab bars, to compensate for functional limitations, those features are fixed, only able to support some abilities, some of the time. The purpose of this project is to develop a SmartBathroom environment capable of assessing an individual's abilities at any point in time and spontaneously adjusting supportive environmental features to accommodate those abilities.\n"
   },
   {  
      "link":"/research/labs/interactive-media-technology-center-imtc",
      "name":"RheumMate",
      "lab":"Interactive Media Technology Center (IMTC)",
      "description":"Juvenile idiopathic arthritis (JIA) is the most common cause of chronic childhood arthritis, affecting ~1 in 1000 children. Patients accurately reporting the number of joints with pain, swelling and limited mobility, and global assessment of their disease, is vital for assessment of affected joints, accurate diagnosis, decision making and management by providers, evaluation of effectiveness of intervention, change or escalate therapy based on the American College of Rheumatology guidelines, outcomes and comparative effectiveness studies and many disease activity scoring systems.\nWe have developed an IOS application to capture joint health information and disease progression with a focus on using game design to promote patient engagement. \nThis project was supported by funding from the 2013-2014 center Grant from Institute for People and Technology (IPAT), cosponsored Children's Healthcare of Atlanta, Emory Department of Pediatrics and Georgia Institute of Technology\n"
   },
   {  
      "link":"/research/labs/mobile-robot-laboratory",
      "name":"Robotic Co-Mediators for Parkinson's Patients ",
      "lab":"Mobile Robot Laboratory",
      "description":"This project aims to ensure that the dignity of a Parkinson's patient is maintained during interactions with caregivers using a robot as a co-mediator. The mediator will hold a mental representation of the patient's and caregiver's emotional state and react accordingly. The co-mediator will express the patient's internal emotional state through spatial and emotive gestures.\n"
   },
   {  
      "link":"/research/labs/augmented-environments-lab",
      "name":"Room-scale Video mixed Augmented Reality",
      "lab":"Augmented Environments Lab",
      "description":"We are creating a platform for experiencing room-scale augmented reality through head-mounted displays. Prototypes will involve various tracking methods to interpret the user's gestures and movements. This project will be a basis for our research in the following topics:- Developing a collaborative workspace- Solving multi-content issues- Creating content for AR\n"
   },
   {  
      "link":"/research/labs/synaesthethic-media-lab",
      "name":"ROSS: Responsive Objects, Surfaces, and Spaces",
      "lab":"Synaesthethic Media Lab",
      "description":"The Responsive Objects, Surfaces, and Spaces (ROSS) API is a way for tangible applications to operate seamlessly across a variety of tangible input devices and platforms. It allows applications to exchange information about the devices they are running on and obtain real-time data about tangible and touch interactions from other devices. In a ROSS world, you can use your mobile phone as a controller to play games on the digital coffee table in your living room; and your guests can join in with their phones too.\n"
   },
   {  
      "link":"/research/labs/research-network-operations-center-rnoc",
      "name":"RPKI",
      "lab":"Research Network Operations Center (RNOC)",
      "description":"In 2008, Pakistan took down YouTube from entire Internet for nearly three hours. They did this using BGP, the border gateway protocol, the IP-to-network address book protocol of the Internet. They announced that they owned  YouTube's IP addresses, even though they did not own them. RPKI, the resource public key infrastructure, is the first step in addressing this issue to only allow owners of IP address to announce where they are located. Unfortunately, implementing RPKI is not a trivial task, and we are working on making a \"cookbook\" on how to properly deploy RPKI on university campus routers.\n"
   },
   {  
      "link":"/research/labs/information-interfaces-group",
      "name":"RSketch: Streamlined Mars Rover Path Planning",
      "lab":"Information Interfaces Group",
      "description":"Large, multisensor datasets are available covering a large portion of Mars. Analysis and display of these datasets are currently in use for path planning tools that provide a precise, low-level visualization that fosters precision planning for Rover Planners at NASA Jet Propulsion Laboratory. However, these visualizations do not foster path planning at a higher level of abstraction. In addition, planning a path uses a non-intuitive process of generating rover commands, simulating them, visualizing the results, and then tweaking the commands until the path looks correct.\nRSketch expedites path planning for JPL Rover Planners  by allowing them to intuitively generate and assess rover paths. The path generation process in RSketch must be influenced by traversability measures, incorporate and visualize multisensor data used for the traversability analysis, enable rapid path generation and comparison between alternatives, and export generated paths to mission operations tools.\nThe prototyped RSketch system aims to provide a streamlined path generation and analysis tool for Rover Planners. The tool uses processed data, raster images, and rover state files as the basic dataset. RSketch uses this dataset to provide the Rover Planner with situational awareness of the rover's state and the surrounding environment in a 2-dimensional map space. The Rover Planner can select and modify the display of the overlaid data on the map, as well as view annotations such as the long-term path.\nIn order to plan out a path, RSketch provides Rover Planners a simple sketching capability to drop and modify waypoints that define a driving path. These waypoints can later be imported into the rest of the Rover Planner's system as localized waypoints   other parts of the Rover Planner system then generate low-level rover commands from the exported path in RSketch. This export feature allows Rover Planners the ability to integrate with the rest of their system.\nWhen sketching out a path, Rover Planners are able to visualize data along the entirety of the rover path. The data is visualized in two different forms: directly on the path and along a slideout panel. Both of these visual forms afford varying analysis modalities. The data along the path, coupled with path sketching affords the ability to make informed decisions on how a modification affects the rover's planned traversal. The slide-out graphs allow Rover Planners to conduct summative analysis at different chronological points of the path planning process by visualizing all data parameters at once.\n"
   },
   {  
      "link":"/research/labs/information-interfaces-group",
      "name":"Safe Passage ",
      "lab":"Information Interfaces Group",
      "description":"Spatio-temporal data is often displayed using regional aggregation or heatmaps, which are useful for exploring large distributed trends or working to unearth the cause of more localized behavior. For individual users that live and work in the region, however, these representations are inaccessible and difficult to put into practice. We present a new technique for exploring spatio-temporal data as personal routes through a geographic area. With this technique, users are able to examine the details of a subset of event records that are contextually relevant to a trip taken through the area of consideration. Our technique can be applied to any spatio-temporal data that consists of point events, and is demonstrated through a visualization system, Safe Passage, that displays crime data from an urban area in the context of pedestrian routes that users take through the city. Several cases are used to explore the range of potential routes and the variety of crimes that occur along those routes.\n"
   },
   {  
      "link":"/research/labs/synaesthethic-media-lab",
      "name":"SayWhyPoll & Tangible Anchoring",
      "lab":"Synaesthethic Media Lab",
      "description":"Recently featured in Georgia County Government magazine, the SayWhyPoll mobile app enables elected officials, civic leaders, and media producers to engage with constituents and audiences either remotely or face-to-face using surveys that tightly couple close-ended survey items with rich media, such as video. The SayWhyPoll is designed to increase opportunities for public debate on civic issues, but is also suitable for pure entertainment topics, such as sports and lifestyle. Once people contribute their viewpoints, Tangible Anchoring enables the results of this experimental survey technique to be easily explored and discussed via interactive tabletops using information visualizations designed for television programs and public meetings.\nLocation: Synlab, TSRB 209\n"
   },
   {  
      "link":"/research/labs/visual-analytics-lab",
      "name":"SCADE - Supportive Computational Analysis, Discovery and Exploration",
      "lab":"Visual Analytics Lab",
      "description":"SCADE is a visual text analytic tool. The goal of the project is to help analysts make sense of a larger number of text document while tracking the analyst's provenance.\n"
   },
   {  
      "link":"/research/labs/entertainment-intelligence-lab",
      "name":"Scheherazade Story Generator",
      "lab":"Entertainment Intelligence Lab",
      "description":"Story generation is the problem of automatically selecting a sequence of events that meet a set of criteria and can be told as a story. Story generation is knowledge-intensive; traditional story generators rely on a priori defined domain models about fictional worlds, including characters, places, and actions that can be performed. Manually authoring the domain models is costly and thus not scalable.\nWe present a novel class of story generation system--called an Open Story Generator--that can generate stories about any topic. Our system, Scheherazade, generates plausbile sounding, but fictional stories about real world situations. It automatically learns a domain model by crowdsourcing a corpus of narrative examples and generates stories by sampling from the space defined by the domain model.\nScheherazade can also be used to create interactive narratives in which a player gets to choose the actions for a particular character in the crowdsourced story world. See a video of the system in action: https://www.youtube.com/v/znqw17aOrCs\n"
   },
   {  
      "link":"/research/labs/synaesthethic-media-lab",
      "name":"SciSketch",
      "lab":"Synaesthethic Media Lab",
      "description":"Sketching plays an important role in learning in the sciences. The process of sketching can help students think about and better understand scientific concepts. By sketching collaboratively, students can also compare their mental models with each other and share them with instructors in order to further enhance their understanding. What if these sketches could come to life so that students could experimentally test out and iteratively refine their models of natural phenomena and systems? We are designing SciSketch, a tabletop tool for sketch-based problem-driven collaborative learning in the sciences. The system tracks multiple pen inputs on a tabletop display surface and can transmit sketch data to a remote computer. The first prototype provides basic functionality of digital sketching tools, such as copy, paste, and playback. We study how such a tool could be incorporated into the classroom environment for undergraduate courses in biomedical engineering.\n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"Scraping big data without API",
      "lab":"Comp.Social Lab",
      "description":"Using scrapy a python framework to scrape Sino Weibo without the API. \n"
   },
   {  
      "link":"/research/labs/research-network-operations-center-rnoc",
      "name":"SDN orchestrator driven traffic engineering for adaptive bit rate video streaming",
      "lab":"Research Network Operations Center (RNOC)",
      "description":"We will demonstrate a Software-defined networking (SDN) controller that orchestrates traffic engineering for adaptive bit rate video streaming. An OpenFlow-enabled SDN architecture in combination with MPEG-DASH constitutes an optimized and seamless video streaming platform. \nThe GENI infrastructure was utilized to evaluate video traffic over current network architecture and SDN architecture.\n"
   },
   {  
      "link":"/research/labs/interactive-products-design-lab",
      "name":"Seed: Sensors and electronics educational database",
      "lab":"Interactive Products Design Lab",
      "description":"http://ipdl.gatech.edu/seed/\nSeed is a sensor and electronics educational database developed for use at the Interactive Product Design Lab. The lab teaches designers electronic prototyping skills-- Seed assists in this mission my providing information on electronic components through an online database, physical RFID card library, and RFID sensing unit. Parts are categorized into 6 groups: logic, power, input, output, tools, and projects. When a student needs information about a component, they can select a card and place it on the RFID reader. This brings up an information sheet on that component, complete with step-by-step start guides, wiring diagrams, sample code, and even past projects. \n"
   },
   {  
      "link":"/research/labs/information-interfaces-group",
      "name":"SentenTree: visualizing large-scale social media text",
      "lab":"Information Interfaces Group",
      "description":"The growing popularity of social media makes it increasingly difficult to keep up with the huge volumes of information they produce. We present SentenTree, a novel visualization technique that helps people gain a quick understanding of the key concepts and opinions expressed in a given social media text set. SentenTree can be used by both casual social media users and professional analysts.\n"
   },
   {  
      "link":"/research/labs/contextual-computing-group",
      "name":"Silent Speech Recognition ",
      "lab":"Contextual Computing Group",
      "description":"In this study, we address the problem of performing continuous speech recognition where audio is not available (e.g.,due to a medical condition) or is highly noisy (e.g. during ?re?ghting or combat). Our Tongue Magnet Interface (TMI) uses 3-axis magnetometers to measure the movement of a small magnet glued to the user's tongue. Tongue movement corresponding to speech is isolated from the continuous data by comparing the variance of a sliding window of data to the variance of signal corresponding to silence. Recognition relied on hidden Markov model (HMM) based techniques. Using a custom headset with four magnetometers placed close to the cheeks of the participant, a maximum user dependent recognition rate of 99.8% is achieved for a ?xed phrase set of 12 sentences spoken by able-bodied participants. The average accuracy across four users is 95.9%. Using the single magnetometer aboard Google Glass, a commercial wearable computing device worn at eye level, one of 12 phrases could be selected with 93.8% average accuracy. To improve the latter recognition result we introduced a new interface, known as the Outer Ear Interface (OEI), which captures the lower jaw movements by measuring the deformation it causes in the ear canal. This measurement is done using a pair of infrared proximity sensors, one in each ear. We hypothesize that combining features from both interfaces will improve accuracy results significantly.\n"
   },
   {  
      "link":"/research/labs/interactive-products-design-lab",
      "name":"Smart Ballet Shoe: Transforming adult ballet learning with wearable tech",
      "lab":"Interactive Products Design Lab",
      "description":"The project seeks to improve the current model of ballet training with wearable technology integrated into existing dance garments-- socks, soft ballet shoes, and legwarmers that sense movement and give real-time feedback to the dancer.Long term goals of this project include 1) preventing injury by using garment calibration to teach dancers about their body's natural limits, and give feedback when they are not dancing safely, 2) speeding the development of ballet technique basics by monitoring proper weight distribution, balance, and pointing of the toes, and 3) providing more individual guidance than encouraging students to return to class, answering questions, and building confidence. To date, the sock is the sensing layer- embedded with pressure sensors and an IMU to detect balance and positioning of the leg. The ballet shoes provide feedback- directing the dancer's movement with lights and haptics.. The legwarmer provides unobtrusive mounting of the microcontroller and battery while connecting all parts of the system through I2C connections.\n"
   },
   {  
      "link":"/research/labs/contextual-computing-group",
      "name":"SmartSign",
      "lab":"Contextual Computing Group",
      "description":"This project involves the development and evaluation of a mobile content\ndelivery system. Using small, unplanned moments throughout the day, we endeavor to increase the ability of hearing parents with deaf children to recognize and produce American Sign Language vocabulary.\n"
   },
   {  
      "link":"/research/labs/brainlab",
      "name":"SMILE (Systems Using the Mind for Latent Expression)",
      "lab":"BrainLab",
      "description":"SMILE (Systems using the Mind for Latent Expression) is developing BCI-controlled wearable technology for expressing emotion\n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"SMSPress: An SMS Research Study Management System",
      "lab":"Ubiquitous Computing Group",
      "description":"Text messaging is a functionality that has been widely used in user studies due to its presence in smart phones and feature phones alike. However the ability to use cell phones for data collection has been limited to researchers that have programming abilities. We present SMSPress, a web-based SMS management system that allows non-technical users to configure SMS studies, and schedule text messages for delivery to participants via a web-interface. We establish the requirements for such a system, and present the results from two case studies. One is a four month mhealth deployment with cardiac patients; the other is a usability evaluation of a study to help parents keep track of their child's development.\n"
   },
   {  
      "link":"/research/labs/technologies-and-international-development-lab",
      "name":"Social Media Civic Engagement",
      "lab":"Technologies and International Development Lab",
      "description":"We are developing technological platforms, human and social processes, and the underlying creative abilities to leverage social media and digital networks to enhance democracies especially in Africa. Our current work has focused on participation in and monitoring of elections while future work will expand that frame seeking to foster broader and deeper civic engagement especially among youth, the promotion of government accountability and efficacy, and the constructive creative ability to hack democracy. The Social Media Tracking Center (SMTC) encompasses a process to monitor and respond in real-time to reports from systems such as Twitter, Facebook, Google+ and Ushahidi. The technological platform facilitating the SMTC is Aggie, our social media tracking software, which allows the aggregation and integration of social media data streams along with real-time trend analysis and visualizations.\n"
   },
   {  
      "link":"/research/labs/electronic-learning-communities",
      "name":"Social Media in Cuba: Who is speaking, and who is listening?",
      "lab":"Electronic Learning Communities",
      "description":"Social Media is changing our world. Traditional narratives paint a picture of many-to-many democratization of information--making ideas, opinions, education, and knowledge available to many people in many places at any time. This research examines whether this is&nbsp;actually the case, especially in countries with a totalitarian government. Through an interview-based study of Cuban participants on social media, this project explores both the limitations and opportunities of cyber networks as tools for individuals to create collaborative narratives and affect social change. By shedding light on the situation in Cuba, this research seeks to&nbsp;illuminate the role of online social networks as tools of persuasion and influence in a global setting.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Social TV",
      "lab":"Experimental Television Lab",
      "description":"Social TV is a mobile application that works in conjunction with watching TV. It is targeted to users who may be living in a new location and watch TV alone, or to users who want to increase the social aspect of watching TV. Through integration with Facebook, the mobile app presents a TV Feed where users can share information, such as screenshots, quotes and recommendations with other individuals in their network. The app has a TV chat feature, where users can engage in both synchronous and asynchronous chatting about what is occurring in the show of their choosing. Users have the option to add friends to their TV watching experience, expanding their social network. Other aspects of the app include the ability to keep track of your own and friends' progress on TV shows, scheduling time to watch TV with others, and discovering new TV shows they may be interested in.\n"
   },
   {  
      "link":"/research/labs/research-network-operations-center-rnoc",
      "name":"Software Defined Exchange (SDX)",
      "lab":"Research Network Operations Center (RNOC)",
      "description":"The SDX project is applying the principles of Software Defined Networking and Infrastructure to the problems of peering between network operators and service providers. This work seeks to overcome the traditional limitations of peering protocols such as BGP to enable operators and their customers to express rich, application specific policies that facilitate the integration of cloud computing and virtualization into numerous applications.\n"
   },
   {  
      "link":"/research/labs/acme-lab",
      "name":"Solid Sketch",
      "lab":"ACME Lab",
      "description":"SolidSketch is a solid modeling program that enables users to rapidly construct 3D models through sketch and multi-touch input. The interaction design principles of SolidSketch are based on the cognitive science theory of enaction. This paper uses the enaction theory as a lens to describe why the interaction designs of conventional CAD tools often fail to support early stages of the design process.  We argue enactive interactions would support design creativity by enabling rapid iteration and continuous feedback throughout a flexible design exploration. SolidSketch is a unique sketch-modeling program that analyzes and interprets freehand sketch gestures to execute commands. The system infers the intention of the user by continuously analyzing the surrounding context and user's behavior.  The program only provides a minimum set of GUI components to encourage the user to focus more on the canvas area rather than navigating intricate interface elements.\n"
   },
   {  
      "link":"/research/labs/sonification-lab",
      "name":"Sonified Fantasy Sports",
      "lab":"Sonification Lab",
      "description":"The Sonified Fantasy Sports project has been exploring various ways to add sounds to online (web or mobile apps) fantasy sports in an attempt to make a more immersive user experience while also adding to the accessibility of fantasy sports for visually impaired or print disabled users. After identifying information needs and various strategies employed by users (who ranged from beginners to power users) we were able to identify a hierarchy in which to present information about &#39;my team&#39; and &#39;players&#39; using sound. Ongoing investigation is exploring additional ways to employ optimal soundscapes that will result in the most seamlessly integrated audio-visual experience while offering as much accessibility as possible\n"
   },
   {  
      "link":"/research/labs/adam-lab",
      "name":"Sound Happening",
      "lab":"ADAM Lab",
      "description":"Sound Happening is a playful installation space in which participants generate improvisational music by interacting with colorful foam balls. \n"
   },
   {  
      "link":"/research/labs/adam-lab",
      "name":"Space Table: The life of a star",
      "lab":"ADAM Lab",
      "description":"The Space Table is an interactive informal experience to teach children about the formation of solar systems and how gravity, and mass play a role in their creation. Additionally, the project will explore the concepts of different celestial bodies such as stars, planets, asteroids, neutron stars, black holes and others.\nThe installation will make use of three tangibles, one for a different star size. Interactors will use the tangibles to stamp a star on the table, which will spawn a digital star. After the star is created, interactors will be able to create asteroids and other space debris by sliding their fingers on the screen, which will in turn create bigger objects (such as moons or planets) when they collide with other small celestial bodies. Once the system is created, the expectation is for interactors to experiment with the celestial bodies, leading them to the discovery of cosmological concepts.\n"
   },
   {  
      "link":"/research/labs/information-interfaces-group",
      "name":"SpaceSketch - Multitouch Exploration of Urban Public Safety Data",
      "lab":"Information Interfaces Group",
      "description":"Visualization tools for spatio-temporal data utilize map-based representations to help a user understand trends and outliers within a given region over time. Multitouch visualization tools allow us to recreate many of the capabilities of sketching directly on maps while still taking advantage of computational models of public safety. We will be demonstrating SpaceSketch, a multitouch approach to spatio-temporal visualization. Visitors will be allowed to explore crime and transit data in the city of Atlanta using our high-resolution Perceptive Pixel Interface.\n"
   },
   {  
      "link":"/research/labs/interactive-media-technology-center-imtc",
      "name":"SPAN: Increasing Social Participation of Teens w/ Brain Injury via App-based Peer Coaching and Training",
      "lab":"Interactive Media Technology Center (IMTC)",
      "description":"Social Participation and Navigation (SPAN) is an intervention that integrates mobile app-based training and peer coach support around key aspects of social participation, including social communication and problem-solving skills, identification and remediation of barriers to participation, and establishment of social connections with others.\nSPAN will focus on social participation as our core outcome, working with teens with TBI to identify and prioritize their own social participation goals and supports and barriers to participation, and teach strategies that teens can use to achieve their participation goals. Training of peer coaches and use of smartphone and web-based technology ensures that teens with TBI are directly supported in everyday life (school, community, and work), according to their own preferences and schedules, rather than in clinical settings where opportunities for social participation are limited.\nThis project is a collaboration with Cincinatti Children's Hospital Medical Center, Tufts University, University of Wisconsin-Madison and Children's Health Care of Atlanta.\n"
   },
   {  
      "link":"/research/labs/synaesthethic-media-lab",
      "name":"Sparse Tangibles",
      "lab":"Synaesthethic Media Lab",
      "description":"Sparse Tangibles investigates the use of novel tangible and gestural interactions for making sense of large biological datasets. Our current prototype employs active tangibles in combination with a large multi-touch tabletop displays to navigate and visualize gene regulatory network data from the BioGrid database.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Story Map",
      "lab":"Experimental Television Lab",
      "description":"A second-screen companion app to support viewers in following a densely populated storyworld, with prototype based on the FX Series Justified.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"StrangVR Things",
      "lab":"Experimental Television Lab",
      "description":"StrangVR Things is a VR prototype that crafts an immersive and engaging experience within the narrative world of Netflix's original series, Stranger Things. The user takes on the role of Eleven and must escape a hostile environment by leveraging her telekinetic powers. Our design aims to allow show viewers to explore the dangers of the Stranger Things world through Eleven's eyes and endow viewers with the same mysterious powers.\n"
   },
   {  
      "link":"/research/labs/research-network-operations-center-rnoc",
      "name":"Streetcar Sensors",
      "lab":"Research Network Operations Center (RNOC)",
      "description":"Starting this summer, the Atlanta Streetcar began using a real-time dispatching method developed at Georgia Tech that eliminates the need for schedules and cuts down on passenger wait times. School of Civil and Environmental Engineering Assistant Professor Kari Watkins and Ph.D student Simon Berrebi developed an algorithm that ensures each vehicle is spaced evenly along the 2.7 mile route in downtown Atlanta, maximizing the frequency of service. Unlike the previous method, the Georgia Tech algorithm uses real-time information.\nOne problem the researchers faced was the urban canyon effect where the GPS reception reverberates on buildings, or is blocked entirely, creating an error in the signal and causing the apparent GPS location of the vehicles to wander. Watkins and Berrebi worked with Research Scientist Bill Eason of IPaT and the Georgia Tech Research Network Operations Center (GT-RNOC), and GT-RNOC Co-director Russ Clark to use a barometric pressure sensor. They found that the newest sensors, designed to be built into next-generation cell phones, are sensitive enough to detect changes in elevation of under a meter (3.3 feet). The sensor measures changes in elevation and allows for more accuracy in pinpointing the location of a streetcar in real-time.\n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"Supporting in-home collection and sharing of behavior evidence for diagnostic assessment of children with autism",
      "lab":"Ubiquitous Computing Group",
      "description":"We have designed and evaluated a Clinician-directed Capture and Access system that can enable (1) parents to easily collect clinician-prescribed in-home behavior specimens(video evidence of behaviors) that have clinical utility, and (2) clinical experts to conduct diagnostic assessment for autism based on parent-collected in-home behavior specimens.\nCurrently, in collaboration with an autism center, a clinical trial is being conducted to validate this remote autism diagnostic model on a larger scale.\n"
   },
   {  
      "link":"/research/labs/design-and-social-interaction-studio",
      "name":"Sweet Auburn Digital Media Initiative",
      "lab":"Design and Social Interaction Studio",
      "description":"Can locative media (Augmented and Mixed Reality, web applications, and social networking) serve as a platform for preservation of cultural heritage, informal education, and civic engagement?\nThis is the question at the heart of the Auburn Avenue Research Project, a project that brings together researchers from variety of disciplines   including media theory, design studies, and human-computer interaction   to engage the above question in theory and practice. Through the creation of a tiered media strategy, the Auburn Avenue Research Project takes advantage of real world development project (e.g., new physical signage, street car) and potentials of digital technology to raise awareness of Auburn Avenue's history an future trajectory, to increase the number of visitors to the neighborhood, and to support community preservation and revitalization efforts. Project objectives include:\nTo explore the usage of locative media forms for their potential to increase civic engagement among visitors and residents.\nTo make the rich cultural heritage and history of Auburn accessible to people by integrating new and old representational media.\n"
   },
   {  
      "link":"/research/labs/sonification-lab",
      "name":"System for Wearable Audio Navigation (SWAN)",
      "lab":"Sonification Lab",
      "description":"The System for Wearable Audio Navigation (SWAN) serves as a navigation and orientation aid for persons temporarily or permanently visually impaired. SWAN is in the early stages of a software rewrite and technology upgrade. Interaction techniques are being prototyped in Virtual Reality (VR) to support preliminary user studies of new features.\n"
   },
   {  
      "link":"/research/labs/acme-lab",
      "name":"Tactile Teacher",
      "lab":"ACME Lab",
      "description":"In a piano lesson, a student often imitates the teacher's playing in terms of speed, dynamics, and fingering. While this learning model leverages one's visual and even audial perception for emulation, it still lacks an important component of piano playing   the tactile sensation. We seek to convey the tactile sensations of the teacher's keystrokes and then signal the student's corresponding fingers. We implemented an instrumented fingerless glove called Tactile Teacher to detect finger taps on hard surfaces. Since finger taps generate acoustic signals and cause vibrations, we embedded three vibration sensors on the glove and use machine learning algorithms to analyze the data from the sensors. After a brief training procedure, this prototype can accurately identify single finger tap in a very good performance at above 89% accuracy, and two finger taps resulted in accuracy around 85%.\n \n \n"
   },
   {  
      "link":"/research/labs/adam-lab",
      "name":"Tangible Program Learning Table",
      "lab":"ADAM Lab",
      "description":"This project is a responsive tabletop application with a tangible user interface. The intention is to teach basic computer programming concepts to middle school-aged to high school-aged children (9-15 years old) using physical blocks that work as snippets of code. Each block has a unique design on the bottom that when placed on the acrylic surface of the table is identified by the software using cameras mounted underneath the acrylic surface of the table. When the arrangement of blocks is recognized, the application outputs musical and visual feedback. Users compose short songs by building chains of blocks that represent code. \n \n \n \n"
   },
   {  
      "link":"/research/labs/synaesthethic-media-lab",
      "name":"TASC: Tangibles for Augmenting Spatial Cognition",
      "lab":"Synaesthethic Media Lab",
      "description":"Spatial ability has been shown to be significantly correlated with interest and success in STEM fields. It also has been linked to embodiment in different ways. Tangible and embodied interfaces have been shown to support embodiment, including linking embodiment to changes in spatial ability. However, little research has linked the interaction design elements of tangible and embodied interfaces to specific effects on spatial cognition. Our research aims to gain a deeper understanding of the effects of tangible and embodied interfaces on spatial cognition and to develop interface protocols that enhance spatial ability training. Our current prototype employs tangible interaction with physical/digital blocks in a virtual reality environment to support perspective-taking spatial abilities.\n"
   },
   {  
      "link":"/research/labs/culture-and-technology-lab-cat",
      "name":"Tech Hustle: Understanding and Supporting Technology Learning and Employment",
      "lab":"Culture And Technology Lab (CAT)",
      "description":"Tech Hustle is a project to build upon indications from earlier project, Glitch. Glitch found that many low-income African American male high school students were more willing and able to engage in computer education when it was situated in an authentic work environments. The high school students in this previous work exhibited pride and excitement in being responsible workers, making their own money, and used work as a way to justify time spent on learning computer science and other more academic pursuits. We are researching programs to help young people set up their own side businesses (side hustles) providing tech support, web development, and computational and physical prototyping.\n"
   },
   {  
      "link":"/research/labs/culture-and-technology-lab-cat",
      "name":"Technology in museums: Avenues for personalized parent-child conversations ",
      "lab":"Culture And Technology Lab (CAT)",
      "description":"Parents and children work together in museums and other informal learning settings to make meaning of the world around them. The parent-child conversations, the child's interests (islands of expertise) and the surrounding technology influence the overall informal learning experience. We conducted two studies at the Children's museum of Atlanta to better understand the interplay amongst those conversations, child's interest and technology. Drawing on the insights from the field studies and participatory design activities conducted with parent-child dyads, we created a prototype of a companion mobile app which may create avenues for having in-depth, contextualized and personalized parent-child conversations, which may, in turn, improve the informal learning experience.\n \n"
   },
   {  
      "link":"/research/labs/compsocial-lab",
      "name":"The Bag of Communities Approach: Identifying Abusive Behavior Online with Preexisting Internet Data",
      "lab":"Comp.Social Lab",
      "description":"Since its earliest days, harassment and abuse have plagued the Internet. Recent research has focused on in-domain methods to detect abusive content and faces several challenges, most notably the need to obtain large training corpora. In this paper, we introduce a novel computational approach to ad- dress this problem called Bag of Communities (BoC)\u2014a technique that leverages large-scale, preexisting data from other Internet communities. We then apply BoC toward identifying abusive behavior within a major Internet community. Specifically, we compute a post's similarity to 9 other communities from 4chan, Reddit, Voat and MetaFilter. We show that a BoC model can be used on communities off the shelf with roughly 75% accuracy\u2014no training examples are needed from the target community. A dynamic BoC model achieves 91.18% accuracy after seeing 100,000 human-moderated posts, and uniformly outperforms in-domain methods. Using this conceptual and empirical work, we argue that the BoC approach may allow communities to deal with a range of common problems, like abusive behavior, faster and with fewer engineering resources.\n"
   },
   {  
      "link":"/research/labs/mobile-robot-laboratory",
      "name":"The Benefits of Robot Deception",
      "lab":"Mobile Robot Laboratory",
      "description":"Deception is a common behavior not only in humans but also in animals. We focus on deceptive behavior in robotics because the appropriate use of deception is beneficial in several domains ranging from the military to a more everyday context. In this project, we proposed a taxonomy of robot deception and developed novel algorithms for robots' deceptive behaviors inspired by biological findings. In more recent work, we are developing computational models and conducting human-subject studies for a robot's other-oriented deception in the context of Human-Robot Interactions (HRI).\n"
   },
   {  
      "link":"/research/labs/electronic-learning-communities",
      "name":"The Internet in Cuba",
      "lab":"Electronic Learning Communities",
      "description":"With nearly four billion people still lacking access to the internet, efforts to expand internet access are growing rapidly across the world. Cuba remains one of few emerging nations where this access is still affected by historical trade embargoes and restrictions. Since the 2014 announcement of the normalization of relations between Cuba and the U.S., however, internet access in Cuba is increasing. This work is situated during this time of transition to explore the impacts of increasing internet access on individuals and communities living in Havana.  The internet in Cuba is currently made up of four separate components: slow access at places of work, content sold on USB thumb drives (El Paquete), an intranet custom designed by citizens (StreetNet), and public wifi hotspots available at exorbitant prices (opened in March 2015).  In this work, we seek to understand the particularity of each of these parts, and the bigger whole that emerges during this time of transition. The Cuban context provides for a compelling study on how on how a highly literate population with a history of state-controlled information, and thriving offline practices transitions to deriving meaning out of an online, global, networked infrastructure. Through ethnographic, qualitative research methods, this project aims to develop a ground-up, holistic understanding of the information infrastructures that have evolved in Cuba as a response to individual values and ongoing constraints. These findings will inform the design of technologies that are context-appropriate but also flexible enough for users to modify and appropriate them in meaningful ways.\n \n \n"
   },
   {  
      "link":"/research/labs/local-data-design-lab",
      "name":"The Life and Death of Metadata",
      "lab":"Local Data Design Lab",
      "description":"In collections of scientific and cultural history that are too big to see, metadata act as virtual handles for rare and delicate artifacts from the past. At the Arnold Arboretum, a collection of long-lived trees, vines and shrubs managed by Harvard University, landscapes from around the world and across time are stitched together by metadata. However, metadata are worthy of study themselves. Created in varied social and technological eras, they register the organizational structures and values of their time. Through a combination of data visualization and interviews with Arboretum staff, this essay illuminates what metadata can teach us about their own social and material histories, as well as how to study collections digitally.\n"
   },
   {  
      "link":"/research/labs/augmented-environments-lab",
      "name":"The Lights of St. Etienne: An AR/MR experience in the cathedral in Metz, France",
      "lab":"Augmented Environments Lab",
      "description":"The Augmented Reality experience, The Lights of St. Etienne, uses the AR-browser Argon as a platform for an embodied, location-based experience in St Eti\u00e8nne Cath\u00e9dral in Metz. The experience takes into account the cultural heritage and hidden stories embedded in its architecture, windows, and ornamentations. Lights focuses on five separate sites (geo-spots) in and around the cathedral to explore various dimensions of the cathedral, its history, and its place in Metz. \nThe five spots are inside the cathedral, working with historical narratives relating the history of the cathedral and citizens' experience of Metz at various points in time. 3D panoramas will be used to give the visitor a sense of the changing architecture of the vast church over the centuries. Photographic images, presented on the screen, will permit the visitor to examine more closely some of the stained glass located high overhead. Sound and music is prominent in the experience, changing as the visitor moves to the various sites. Ranging from the sounds of fire (cf. Bill Viola's Fire Woman video work 2005 serves as example), to spoken narratives in 1st person point-of-view narratives of people telling personal stories relating to a particular moment.  Favoring a situated personalized narrative, inspired by historical events and drawn from contemporaneous sources, the narratives present one view on the complexity of history that is centered on the cathedral. Music is also used in the application, underscoring contemplation or the sacral experience of being in the cathedral.\nArgon permits us to design using a variety of Augmented and Mixed reality techniques, as well as multimedia presented on the mobile device's screen. This prototype was designed and produced by AEL researchers, students at the Metz campus of Georgia Tech (GT Lorraine), and students at Georgia Tech in Atlanta (US).\n"
   },
   {  
      "link":"/research/labs/public-design-workshop",
      "name":"The Object Ecology: designing edge cases for the Internet of Things",
      "lab":"Public Design Workshop",
      "description":"Usually, objects are considered to be discrete instantiations of something unique and unitary, comprising one individual thing and not another. Some technological developments are making that assumption murkier. Ubiquitous computing and mobile devices have begun to shift how objects operate. As examples, clothing is being instrumented with computational capabilities, creating the fields of wearables. Networked appliances in the home become members of the Internet of Things. From bit players in the world, electronics and computation have augmented everyday objects into viable actors in their own right, active participants in the world that sense, report, and scheme to their own ends. \nBy revealing these multiple obligations in more explicit ways, computational communication underscores the idea that objects in the world have always been members of multiple networks, involving themselves in social arrangements both subtly and dramatically. This simultaneous involvement in various networks\u2014information, electronic, legal, cultural, material, and more\u2014is what I call Object Ecology. What this ecological understanding of objects reveals is that objects cannot and should not be treated discretely. Instead, they must be considered as component members of an assemblage of actants. \nOne ecosystem of objects that resonates deeply for most people is the home. \u2018Domesticity' is comprised of all sorts of objects: plates, furniture, heating vents, entertainment systems, family members, rugs and much more. By providing computational capabilities to materials in the home, the Internet of Things has entered this domain\u2014brashly, but also intriguingly. It proffers a greater control of their environment to residents of smart homes, but access to this kind of technology is asymmetrical. Many communities and styles of living are excluded from the usual residential understanding of the Internet of Things. These outliers\u2014cohousing communities, tiny homes, combination live/work spaces, homes with multiple adult roommates, and so on\u2014offer a vantage to both critique contemporary IoT practices and provide a provocative set of sites to do design work from an ecological perspective. \n"
   },
   {  
      "link":"/research/labs/digital-world-and-image-group",
      "name":"Thinking Outside the Brick: Lifelong Learning Through Digital Play",
      "lab":"Digital World and Image Group",
      "description":"This MS project applies approaches from DIY and maker culture to lifelong learning principles. It aims to introduce practical workshop settings and guidelines for the use of rapid prototyping technology to continuous education of senior citizens.\n"
   },
   {  
      "link":"/research/labs/emergent-game-group",
      "name":"Tiamat Media ARG",
      "lab":"Emergent Game Group",
      "description":"Tiamat Media is an ARG that was specifically designed for Dragon Con 2013, the largest multimedia fan conventions in the country. It was designed to fit within the socio-cultural context of the convention, appropriating established convention actions into the design.\nOur narrative revolved around the fictional company we created called Tiamat Media. Tiamat Media is a publishing company that specializes in publishing fan artwork. It operates under the guise of helping fans spread their artwork and encouraging fan empowerment. Unbeknownst to the outside, however, Tiamat's true intentions are to steal these works and publish them as their own.\nThe goal of the players is to peel back the facade of Tiamat Media and discover the sordid truth about the company. Players must then team up with those fighting against the company in order to turn the company from its evil ways.\nThe game had three main game mechanic modules for players to solve: a casual picture tag game, a hide and seek game, and a artifact puzzle game. Each of these connected to each other through rabbit holes and once players unlocked the mysteries, they would receive information from characters that would help them take down Tiamat Media.\n"
   },
   {  
      "link":"/research/labs/public-design-workshop",
      "name":"Tiny Tinkering Platforms",
      "lab":"Public Design Workshop",
      "description":"We are creating platforms that help people solve small-scale problems in their everyday lives. Here, gratification comes not from making something new and remarkable to show off to the world, but in making something unremarkable that nevertheless feels important to an individual or small community. When to water a particular plant, when hot coffee has reached a preferred temperature, when the mail has been delivered, and so on.\nWe aim for an ecosystem that reduces hardware engineering complexity for small-scale, ubiquitous problems like these. It allows novices to prototype solutions quickly and straightforwardly. Today's \"maker\" platforms are priced for enthusiasts rather than ordinary people. Our platform needs to be very inexpensive to encourage applications that are never meant to be cherished. A focus on getting something done rather than on doing it.\n"
   },
   {  
      "link":"/research/labs/augmented-environments-lab",
      "name":"Transmedia Storyscape: An ecology of transmedia storytelling",
      "lab":"Augmented Environments Lab",
      "description":"TRANSMEDIA STORYSCAPE\nThe story of The Ghost Club is bigger than just a feature film   it inhabits a complex world with a deep history and mythology that engages its audience members, inviting them into the Ghost Club storyscape.\nThe concept of the Club, its team members, and the reality and rules of this world are introduced through a variety of non-traditional media channels   web series, social networks, online games, augmented reality mobile applications, and more.\nThe Ghost Club transmedia storyscape generates a cohesive alternate reality that engages fans, encouraging them to discover, explore, and even participate in the world of ghosts and hunters.\nStoryscape components include:\nTHE GHOST CLUB WEBISODES introduce viewers to the team and the show, and highlight story elements only hinted at in the feature film   including Noreen being a reporter who is secretly investigating the Club.\nTEAM FACEBOOK PROFILES & TWITTER FEEDS are where The Ghost Club team members post and tweet about the other investigations taking place during their final season. This establishes the rules of the show, the personalities of the investigators, and expands on team member relationships only hinted at during the feature film   such as Austin and Caitlin's flirtations.\nTHE GHOST CLUB WEBSITE serves as the official site for The Ghost Club, including the club genealogy, current team member bios, findings from past investigations, ghost tech diagrams, investigative techniques, and how-to tips.\nGHOST-PEDIA is a wiki allowing fans and amateur investigators to enter information about hauntings, ghosts, and investigation techniques.\nTHE GHOST CLUB AUGMENTED REALITY APP: GHOST vs. CLUB is a mobile game that allows our viewers to either become ghost hunters and search for geo-tagged spirits or to become spiritualists who summon ghosts for the hunters to find.\nTHE GHOST CLUB FLASH GAMES are a variety of online games that let fans try their hand at investigating ghosts. The flash games introduce the different techniques and equipment of ghost hunting.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Twitch Plays Improv",
      "lab":"Experimental Television Lab",
      "description":"Twitch Plays Improv is an experiment in participatory narrative creation that utilizes the live streaming video platform Twitch.tv as an arena for broadcasting improvisational theatre games. Drawing on the structures and implications of the Twitch Plays Pokemon phenomenon, Twitch Plays Improv digitizes the performative and participatory conventions of improv, allowing actors and audience members to collaboratively develop dynamic scenes and stories.\n"
   },
   {  
      "link":"/research/labs/center-assistive-technology-and-environmental-access-catea",
      "name":"Universal Design for Wayfinding",
      "lab":"Center for Assistive Technology and Environmental Access (CATEA)",
      "description":"Wayfinding in unfamiliar place has been challenging for everybody, including older adults and people with disabilities. This project investigates the barriers and difficulties people have with wayfinding systems, including environments, technology and their interaction with human. With understanding of the existing barriers and difficulties, this project also aims to provide design solutions from a universal design perspective. \n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Universal Threshold Object",
      "lab":"Experimental Television Lab",
      "description":"This project explores the possibilities, challenges, and benefits of using a tangible object as a controller and feedback device in an interactive television show. The Universal Threshold Object (UTO) enables interactors to realize emotional choices in a narrative world through physical action with objects in a way that emphasizes dramatic immersion rather than gamelike skill mastery. Research methods include prototyping based on real television content and iterative design and testing in a demonstration environment. Design strategies for interaction include mapping gesture to dramatic expectations and reinforcing physical presence in the virtual world. The project is in collaboration with the SynLab and was supported by Intel Corporation.\n"
   },
   {  
      "link":"/research/labs/experimental-television-lab",
      "name":"Universe United",
      "lab":"Experimental Television Lab",
      "description":"Universe United is a second screen experience designed to bring transparency to transmedia storytelling, focused on connections between storytelling conventions such as items, characters, events, and locations. With this approach, we hope to enlighten both newcomers and veterans of a particular cinematic and/or television universe.\n"
   },
   {  
      "link":"/research/labs/tandem",
      "name":"Unpacking Informal Volunteerism: WhatsApp Use for Crisis Relief in Ecuador",
      "lab":"TanDEm",
      "description":"When Ecuador was hit by a 7.8 intensity earthquake on April 16, 2016, the coordination efforts that unfolded relied heavily on the use and appropriation of social media such as WhatsApp, Facebook, and Twitter. While studies on informal volunteers in crisis situations have largely examined digital volunteerism and visible online activities, behind-the-scenes interactions among informal volunteers on the ground remain understudied. We present a qualitative interview study of how Ecuadorian informal volunteers self-organized to provide relief efforts in response to the earthquake. We found that informal groups of volunteers appropriated WhatsApp to articulate relief efforts within their groups and beyond. Drawing on our findings, we emphasize that the design of technologies for crisis response must consider how informal volunteers on the ground harness existing technology practices and situated expertise to address the ever-changing demands of the crisis relief environment.\n"
   },
   {  
      "link":"/research/labs/everyday-computing-lab",
      "name":"User Centered Design of a Patient Monitoring Dashboard",
      "lab":"Everyday Computing Lab",
      "description":"Patient care happens in homes as well as away from them. Care providers spend a significant amount of time in trying to piece these different pieces together and come upto speed with the patient's current status. This user centered design of dashboard will provide them with a means for patient monitoring and help them get all the information that they need in that moment at a glance.\nAt this time, this project focuses on achieving its goals in the context of Breast Cancer, specifically for Cancer Navigators.\n"
   },
   {  
      "link":"/research/labs/digital-world-and-image-group",
      "name":"Using AR in Comic Art: Attention as a Commodity",
      "lab":"Digital World and Image Group",
      "description":"How can we use AR in combination with Comic Artwork to shift attention from the page to the screen and back? The project combines HCI with the nineth art: comics. It applies design criteria from comic scholars and pracitioners such as Will Eisner and Scott McCloud to develop effective AR designs for hybrid comic pieces. We will present a prototype sample of this project at work.\n"
   },
   {  
      "link":"/research/labs/social-dynamics-and-wellbeing-lab",
      "name":"Using Facebook Ad Audience Estimates to Study Psychosis Awareness in the US",
      "lab":"Social Dynamics and Wellbeing Lab",
      "description":"The objective of the study was to explore how the awareness of psychotic disorders varies with different demographics, like gender, age, education and ethnic affinity on social media across each of the states of United States. The facebook ad audience api, which returns an estimate of reach, when queried with demographic parameters like gender, age, education level, region, ethnic affinity and target interest was used in this study. The target interest in our study was Psychosis and psychotic disorders like Schizoaffective Disorder, Hallucination, Schizophrenia Awareness and Paranoid Schizophrenia. The api-returned statistic was roughly validated against the Pew tally of adult facebook users in United States. In addition, we used Government's Mental Health Services Administration data for the count of state-wise mental health institutions, Census data for population and Human Development Index data. We did descriptive statistical analysis on the data, computed correlation metrics and fit regression models for the psychosis-related interest counts with the above parameters. The variation and quantitative association of awareness of psychotic disorders on facebook, with different demographic parameters was an interesting outcome of the study.  \n"
   },
   {  
      "link":"/research/labs/information-interfaces-group",
      "name":"Using Visualization to Explore Social and Communicative Behaviors",
      "lab":"Information Interfaces Group",
      "description":"Psychology researchers use basic statistical visualizations such as bar charts, line charts, and box plots to explore their datasets. These charts are useful for visualizing one- or two-dimensional data but too simple to capture more complex data such as social and communicative behaviors. To more deeply explore temporal behavioral patterns, especially among a large group of subjects, researchers could use better visualization tools.\nWe developed visualization tools to help developmental psychology researchers explore social and communicative behaviors. Based on our conversations with researchers, we learned that they need tools to find groups of children that exhibit commonalities in their behaviors.\nOur sample dataset consists of dyadic social interactions between a child and an examiner. Many behaviors from four modes of communication: gaze, speech, gesture and vocal affect from the children were coded by human annotators and visualized. We designed two visualization tools. One explicitly group children by their behaviors and the other implicitly suggests groups of children with commonalities in their behaviors.\n"
   },
   {  
      "link":"/research/labs/ubiquitous-computing-group",
      "name":"Using Visualization to Explore Social and Communicative Behaviors",
      "lab":"Ubiquitous Computing Group",
      "description":"Psychology researchers use basic statistical visualizations such as bar charts, line charts, and box plots to explore their datasets. These charts are useful for visualizing one- or two-dimensional data but too simple to capture more complex data such as social and communicative behaviors. To more deeply explore temporal behavioral patterns, especially among a large group of subjects, researchers could use better visualization tools.\nWe developed visualization tools to help developmental psychology researchers explore social and communicative behaviors. Based on our conversations with researchers, we learned that they need tools to find groups of children that exhibit commonalities in their behaviors.\nOur sample dataset consists of dyadic social interactions between a child and an examiner. Many behaviors from four modes of communication: gaze, speech, gesture and vocal affect from the children were coded by human annotators and visualized. We designed two visualization tools. One explicitly group children by their behaviors and the other implicitly suggests groups of children with commonalities in their behaviors.\n"
   },
   {  
      "link":"/research/labs/interactive-media-technology-center-imtc",
      "name":"Virtual Medical Assistant",
      "lab":"Interactive Media Technology Center (IMTC)",
      "description":"Sensiotec, an ATDC startup, has developed Virtual Medical Assistant\u00ae, the world's first FDA-cleared, truly remote, totally non-contact, real-time cardiorespiratory and patient motion monitor   an invisible, non-wearable, contact-free system that provides scalable, high value, low cost, location-agnostic patient care. VMA measures heart and lung function as well as body movement, streaming critical spot and trend data to a nurse's station, tablet device, or smartphone   all without electrodes, sensors or pads ever touching the patient directly or indirectly, thereby providing convenience, comfort and compliance. A key aspect of  the technology platform is proprietary sensor technology that resides within a thin sensor panel. The panel simply slides under the mattress, bed or chair, providing convenience, comfort, and compliance with no electrodes or leads attached to, or anything required of, the patient. The Virtual Medical Assistant Workstation application was developed at the Interactive Media Technology Center.\n"
   },
   {  
      "link":"/research/labs/tandem",
      "name":"Virtual Reality for Learning",
      "lab":"TanDEm",
      "description":"Our research examines the role that low-cost virtual reality technology could play in supporting learning in low-resource contexts. Specifically, we propose to study the potential of creating affordable virtual reality-based learning experiences for children in these contexts. There has been a rising penetration of low-cost mobile technologies and internet connectivity in under-resourced communities, and this motivates us to explore the feasibility of virtual reality as a medium to enhance learning experiences for low-resource contexts. We use the Google Expeditions Kit, which is an example initiative that does not require a quality internet connection, runs on low-cost Cardboard VR viewers, and uses smartphones that are becoming widely prevalent in low-resource regions.\n"
   },
   {  
      "link":"/research/labs/sonification-lab",
      "name":"Virtually spatialized audio over bone conduction to support auditory situation awareness and increase pedestrian safety",
      "lab":"Sonification Lab",
      "description":"Most sound comes through our ears. However, it is also possible to pass vibrations through the bones of the head, and bypass much of   the normal hearing pathway. This is called bone conduction audio, and can be used in situations where the ears need to be plugged, or where you need to leave the ears open to hear ambient sounds. We are studying the psychoacoustics as well as the applied aspects of bone conduction audio. A current application being investigated is the scenario of the distracted cyclist or pedestrian. This research is aimed at determining additional ways of further improving awareness of ambient sounds, in addition to using bone conduction devices, through techniques such as virtual spatialization or audio filters. This research will improve the safety of the many pedestrians and cyclists who currently wear headphones while going about their daily lives.\n"
   },
   {  
      "link":"/research/labs/design-and-social-interaction-studio",
      "name":"Visual Policy Initiative",
      "lab":"Design and Social Interaction Studio",
      "description":"The Visual Policy Initiative aims to transform complex policy issues into easy to understand data visualizations using empirically-derived evidence. The Visual Policy team is comprised of a group of researchers from both public policy and digital media. Through this collaborative effort, we aim to transform complex policy issues into easy to understand data visualizations using empirically-derived evidence. In our current endeavor, our team is focused on showing the economic and societal costs of autism spectrum disorder (ASD), and how those costs vary depending on age of diagnosis and age of intervention.\nAutism prevalence rates in the United States have more than doubled since 2000 (from 1 in 150 to 1 in 68 children being identified). Despite this trend as the nation's fastest growing developmental disability, many insurance providers, including Medicaid, do not cover autism services or early intervention services for Autism Spectrum Disorders (ASD). Our research project draws on policy research and human-centered design research to build communication tools and strategies (digital boundary objects) that aid the public and legislators in understanding the negative economic impact of late intervention and present the existing evidence that justifies the passage and implementation of early intervention services in ASD. The first set of these communication tools is aimed at policymakers to improve the continuum of care and interagency system of supports for children with autism. We foresee variations of the developed communication strategies to be used by the public for raising awareness and enabling collective action.\n \n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"Visual Supply Chain Management",
      "lab":"Computational Enterprise Science Lab",
      "description":null
   },
   {  
      "link":"/research/labs/local-data-design-lab",
      "name":"Visualization Journalism",
      "lab":"Local Data Design Lab",
      "description":"Visualization Journalism is focused on developing an interface and graphical metalanguage for massive multimodal news datasets. Such datasets are increasingly available, but for copyright reasons they cannot be made entirely open to the public. The project seeks to offer an abstracted and legal representation of news data, to enable comparative, cooperative and computer-supported analysis of trends across news events and networks. Combining quantitative methods from computational linguistics with opportunities for qualitative analysis, the project will help pundits and publics deliberate the structural characteristics that shape emergent news narratives and points of view on topics of broad social import. Existing platforms (i.e. InArticle, NewsMap, Archive.org) have only begun to demonstrate the potential for alternative forms of criticism that can handle the increased scale\u2014and constraints\u2014of news access. Our project makes use of UCLA's NewsScape, a growing collection of video for more than 300,000 broadcast news programs, extending back to Watergate.\n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"Visualization of Innovation in Global Supply Chain Networks",
      "lab":"Computational Enterprise Science Lab",
      "description":"This study describes a data-driven visualization approach to the systemic study of innovations in global supply chain networks. We demonstrate its applicability with illustrative examples of real-world supply chain in the electronics industry. Our visualization approach enhances the hypothesis-generating process as it can reveal important clusters, patterns, trends, and outliers in the networks.\n"
   },
   {  
      "link":"/research/labs/computational-enterprise-science-lab",
      "name":"Visualization Support for Early-Phase Complex Engineered System Design",
      "lab":"Computational Enterprise Science Lab",
      "description":"The design and production of complex engineered systems (CES) requires analysis of massive amounts of detailed information, including data on products and materials, engineering designs, manufacturing specifications, supply chain and delivery data, and changing customer needs. Visual analytics promises to offer tools and methods that will help stakeholders interactively explore, discover, and make sense of the underlying data. Our work focuses on the early design phase during which a large design space is explored, inconsistencies are identified, poor alternatives are pruned, and valuable alternatives are considered further. We demonstrate our ideas through an example of a two-degree-of-freedom robot and look at opportunities for future work for visualization in manufacturing design.\n"
   },
   {  
      "link":"/research/labs/information-interfaces-group",
      "name":"Visualizing PGA Tour golf shot data",
      "lab":"Information Interfaces Group",
      "description":"The PGA Tour provides an extensive data collection of information about players' performance and individual shots over the past few years.  This collection is called ShotLink data. In this project we are building an interactive visualization system that will allow the viewer to easily browse and explore the golf shot data to learn more about the performance of all the players on tour.  The system presents a variety of different statistics including scoring, driving accuracy, greens in regulation, putting, and so on. We are now working to integrate visual representations of shot patterns on specific holes and players' summary performances when hitting shots from different distances.\n"
   },
   {  
      "link":"/research/labs/synaesthethic-media-lab",
      "name":"VPorter",
      "lab":"Synaesthethic Media Lab",
      "description":"Face-to-face video communication technologies have grown tremendously in recent years, however they are not designed to provide a persistent sense of remote presence. More recently, telepresence robots give single users the ability to have a remote and mobile physical presence in another space. Combining telepresence robotics with persistent large-scale displays and multiple viewports, VPorter creates a telepresence ecology to support team collaboration across remote but connected lab spaces.\n"
   },
   {  
      "link":"/research/labs/public-design-workshop",
      "name":"Westside Atlanta Land Trust: A Community Mapping and Design Collaboration ",
      "lab":"Public Design Workshop",
      "description":"A few fridays ago the Public Design Workshop (PDW) led a Design and Policy Jam with the Westside Atlanta Land Trust (WALT) Program. WALT's mission is to organize the community's power for self-determination; to serve and preserve in-place residents, small business owners, and their successive generations in redeveloping areas. The jam session supported this mission by tasking participants with researching and producing an argument for a city-wide community land trust (CLT) policy. This argument would take the shape of maps, infographics, draft policy texts, and a powerpoint presentation to be presented to the City of Atlanta's Community Development and Human Resources Committee.\nPDW lab members Andy Nelson (Master's HCI) and Amanda Meng (PhD INTA) work on a weekly basis with WALT to continue supporting data collection and mapping efforts. The team will also implement an online document editing platform to crowdsource policy texts that support a city wide Community Land Trust model. \n"
   },
   {  
      "link":"/research/labs/participatory-publics-lab",
      "name":"Westside Soul",
      "lab":"Participatory Publics Lab",
      "description":"Westside Soul is an interactive installation that was displayed at the Historic Westside Cultural Arts Council's Black History Month Celebration. The installation displays videos of westside residents discussing issues in their community and allows viewers to add new responses through text and video. The installation is part of on ongoing partnership with the westside to explore the use of mobile and social computing and digital media to connect community members and instigate alternate forms of civic engagement.\nYou can explore the installation at http://westsidesoul.net\n"
   },
   {  
      "link":"/research/labs/tandem",
      "name":"When the Internet Goes Down in Bangladesh",
      "lab":"TanDEm",
      "description":"We present a study of Internet use and its forced non-use in Bangladesh. In light of current initiatives on state and industry actors to improve Internet access and bridge the 'digital divide' for underserved, under-resourced, and under-represented communities across the world, we offer a situated, qualitative perspective on what the current state of Internet use looks like for select social groups in Bangladesh. We analyze how a state-imposed ban attempted to effect the non-use of particular web-based services and how the affected populations found or did not find workarounds in response. We also discuss takeaways for researchers as well as industry and state actors studying and working towards more equitable access to the Internet in the 'developing' world.\n \n"
   },
   {  
      "link":"/research/labs/design-and-social-interaction-studio",
      "name":"Who Told it How",
      "lab":"Design and Social Interaction Studio",
      "description":"The news is the source citizens turn to in order to gain accurate information about the current events of the world. Unfortunately, a large number of trusted news sources are the worst perpetrators of bias; effectively skewing the public's perception of important material. Who Told it How is a web-based interactive visualization that displays various elements of the Wendy Davis abortion filibuster, as written in articles by four major news syndicates, in order to expose bias and provide perspective.\n"
   },
   {  
      "link":"/research/labs/tandem",
      "name":"Women's Safety in Public Spaces: The Efficacy of Panic Buttons in New Delhi",
      "lab":"TanDEm",
      "description":"We present a qualitative inquiry through the lens of feminist human computer interaction (HCI) into women's perceptions of personal safety in New Delhi, India. Since a brutal gang-rape incident in December 2012 that received global attention, the Indian government has issued a mandate to implement a panic button on every new phone by 2017. We draw on interview and survey data to examine women's reactions to the mandate as well as what factors influence their perceptions of safety, both positively and negatively. Our findings indicate that women's sense of safety may be deconstructed into a multitude of factors--personal, public, social, technological--that must be aligned for this sense of safety to be preserved. We then discuss the implications these factors have for the success and design of the panic button.\n"
   },
   {  
      "link":"/research/labs/problem-solving-and-educational-technology-pset",
      "name":"Worked Examples and Subgoal Labeling: Impacts on Learning",
      "lab":"Problem Solving and Educational Technology (PSET)",
      "description":"Procedural instructions and worked examples have been shown to be effective learning aids in science, technology, engineering, and mathematic (STEM) learning materials. Procedural instructions are texts that describe a general method to reach a goal, while worked examples demonstrate how to apply this method to a specific instance. Research supporting the use of advanced organizers predicts that if learners see the worked example first, they can develop a basis for the problem solving procedure. Learners can then use the procedural text to abstract their understanding, increasing both the initial and transfer performance.\n     Subgoals have been shown to increase novice performance when included in procedural text and worked examples.  A subgoal groups a set of solution steps by their purpose, which allows novice learners to create a framework for problem solving. The proposed research investigates the potential interactions of instructional order and subgoal labeling on performance.\n"
   }
]